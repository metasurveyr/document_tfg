---
bibliography: references.bib
---

```{css}
#| echo: false
p {
  text-align: justify
}
```

```{r}
#| echo: false
#| label: setup
source("../_common.R")
```

```{r}
#| results: "asis"
#| echo: false
#| label: status-chapter

status(
    "validacion"
)
```

# Introducción {#sec-Chapter1}

El presente trabajo tiene como objetivo presentar e investigar el procesamiento y obtención de indicadores a partir de encuestas por muestreo. En general, las encuestas por muestreo son una herramienta fundamental para la obtención de información sobre la población de interés, ya que permiten obtener información a partir de una muestra representativa de la misma. Cada encuesta por muestreo tiene una estructura y un proceso generador de datos que permite obtener estimaciones puntuales y sus errores asociados. En general, el procesamiento de encuestas puede ser tedioso y propenso a errores o difíciles de brindar transparencia y reproducibilidad, especialmente si se quiere obtener indicadores que requieren varios pasos como tasas de mercado laboral, ingreso salarial, índices de pobreza, entre otros [@vilhuber2020]. En general, el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general.

Al trabajar con encuestas es importante tener presente la incertidumbre y errores asociados a las estimaciones producidas, en general esto no es considerado por los usuarios no expertos en metodología de muestreo. Esto puede llevar a conclusiones erróneas ya que en algunos casos el estimador asociado a la estimación cuenta con una alta variabilidad o fue calculado sin tener en cuenta el diseño muestral correcto. Es importante distinguir dentro de la teoría de la estimación el enfoque **model-based inference** y **desing-based inference** [@lumley2011]. En el primer enfoque, se asume que la población de interés se puede modelar mediante un modelo probabilístico y se pueden obtener estimaciones de los parámetros del modelo mediante técnicas de inferencia estadística. En el segundo enfoque, se asume que la población de interés es finita y se puede obtener estimaciones de los parámetros de la población mediante técnicas de muestreo.

Dentro de la estadística existen diferentes conceptos referidos a ponderadores o pesos, entre ellos (en base [@lumley2011]):

-   **Pesos muestrales**: Los pesos muestrales refiere a la cantidad de veces que un individuo de la población de interés está representado en la muestra. Estos pesos muestrales son los que provienen del diseño muestral, ya sea por el inverso de las probabilidades de selección, ajustes por no respuesta, entre otros.

-   **Pesos de precisión**: El concepto de precisión puede relacionarse con la variabilidad que tiene una observación sobre la estimación de un parámetro.

-   **Pesos de frecuencia**: Refire a la cantidad de veces que aparece un individuo en una muestra y este es resumido para incluir en un único registro.

Es importante hacer esta distinción ya que tomando en cuenta los pesos en cualquiera de sus definiciones o consideraciones, en la mayoría de los casos se puede obtener estimaciones puntuales correctas, sin embargo como se mencionó anteriormente llegar a medidas de incertidumbre como errores estándar, intervalos de confianza totalmente incorrectos.

Además de considerar el proceso de inferencia también es importante tener en cuenta el proceso de transformación de los microdatos a indicadores ya que es crucial para interpretar los indicadores de manera correcta además de poder realizar comparaciones a lo largo del tiempo y formalizar la metodología de su construcción. Muchas veces, diferentes usuarios hacen el mismo esfuerzo de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.

En este sentido, es importante construir una herramienta que permita al usuarios tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, además de brindar una herramienta común libre de estilos de programación y definiendo con simples pasos el proceso de construcción de variables sintéticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodología rigurosa y fácil de referenciar en la implementación. Es crucial que este proceso sea transparente y entendible para el usuario y esto sera plasmado en el paquete `metasurvey`, disponible en R [@rcoreteam2023].

```{r}
# TODO: En base a los comentarios de NDS incluir una referencia sobre el uso de R en la comunidad científica
```

R es un lenguaje de programación de código abierto ampliamente utilizado en la comunidad científica para el análisis de datos, estadística y aprendizaje automático, y en general se utiliza el concepto *paquete* para referirse a una colección de funciones, métodos y clases que extienden las funcionalidades de R propuestas por la misma comunidad de usuarios.

Es importante definir el concepto de Estadística Computacional y su diferencia con Computación Estadística [@cook2014]. La Estadística Computacional se refiere a la implementación de algoritmos y métodos estadísticos en un lenguaje de programación, mientras que la Computación Estadística se refiere a la utilización de herramientas computacionales para resolver problemas estadísticos. En este sentido, R es un lenguaje de programación que permite realizar Estadística Computacional y Computación Estadística, ya que cuenta con una amplia variedad de paquetes que permiten implementar algoritmos y métodos estadísticos y realizar análisis de datos de manera eficiente y reproducible.

Actualmente existen varios esfuerzos para facilitar el procesamiento de encuestas, entre ellos existen principalmente dos tipos de paquetes, aquellos que implementan la metodología de inferencia en muestreo de poblaciones finitas como puede ser el paquete `survey` [@lumley2024], `gustave` [@chevalier2023], `vardpoor` [@breidaks2020], `svrep` [@schneider2023], `weights` y aquellos que permiten acceder y manipular encuestas específicas como `ech` [@detomasi2020], `eph` [@kozlowski2020], `tidycensus` [@walker2024], `casen` [@vargas2024] entre otros. Sin embargo, estos últimos tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés, como puede ser el indice de pobreza, tasas del mercado laboral, ingreso salarial, etc. En general, sus implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica. Además en las implementaciones actuales, el usuario cuenta con una función de alto nivel que actúa como una caja negra, donde no se permite modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin tener que leer el código fuente o la documentación adjunta.

Este tipo de problemas puede verse en `ech` [@detomasi2020], donde existen funciones para crear variables de mercado laboral, educación o ingresos, pero estas funciones dependen de la existencia de ciertas variables en la encuesta, cuya estructura puede cambiar de una versión a otra de la encuesta. Sin revisar el cuerpo de la función, no se conoce el proceso de construcción de variables. Algo similar ocurre con `eph` [@kozlowski2020], donde se tienen funciones de alto nivel que no permiten modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin inspeccionar a fondo cómo se construyen las funciones del paquete. Esta inspección del código fuente, como consultar el repositorio de GitHub del paquete o revisar la definición de la función, puede ser una tarea tediosa y no garantiza que el usuario pueda entender el proceso de construcción de variables. Esto se debe a que el código puede ser muy extenso o que el usuario no tenga el conocimiento suficiente para entender el código o se empleen ciertos frameworks que el usuario no conozca, como el uso de las librerías `dplyr` [@wickham2023] o `tidyr` [@wickham2024], muy populares en R para el manejo de datos. También puede ser difícil aislar el proceso de manipulación de la encuesta de la implementación específica de la función para manejar la forma de presentación, estructura del objeto a devolver, etc. Un claro ejemplo de esto puede verse en `tidycensus` [@walker2024], donde existe una función para obtener datos sobre la migración de la comunidad estadounidense, y en la misma implementación se encuentran pasos para mejorar la estructura del conjunto de datos a devolver. En este sentido, el usuario no puede aislar el proceso de re-codificación/construcción de variables sobre variables originales y la obtención de datos geográficos y presentación.

Para científicos sociales, es importante tener en cuenta que el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Es de interés obtener información histórica de indicadores y en general es un proceso tedioso y propenso a errores, especialmente si proviene de encuestas donde su estructura y/o forma de preguntar o su codificación puede cambiar con el tiempo. Esto resulta en un proceso extenso y difícil de entender hasta llegar a la construcción de esta serie de indicadores. Muchas veces, diferentes usuarios hacen el mismo proceso de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.

En este sentido, es importante que el usuario pueda tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, además de brindar una herramienta común libre de estilos de programación y definiendo con simples pasos el proceso de construcción de variables sintéticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodología rigurosa y fácil de referenciar en la implementación. Es crucial que este proceso sea transparente y entendible para el usuario. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete `metasurvey` y su implementación de *recetas* para la construcción de indicadores mediante la meta-programación.

Al trabajar con encuestas por muestreo, es importante tener en cuenta la forma en la que se obtuvieron los datos y su proceso generador para poder realizar inferencias sobre la población de interés. En general, obtener estimaciones puntuales de estadísticos de totales, promedios o proporciones es relativamente sencillo, pero puede ser que se reporte una estimación donde no exista un tamaño de muestra suficiente para obtener una estimación confiable y/o que la variabilidad de la estimación sea alta y no sea recomendable su uso. En este sentido, es importante que el usuario no experto tenga de forma nativa una forma de obtener estimaciones puntuales y sus errores asociados de manera sencilla. Es común utilizar estimaciones puntuales sin tener una medida de incertidumbre o aún peor incluir una estimación del error estándar sin tener en cuenta el diseño muestral correcto, lo que puede llevar a conclusiones erróneas sobre la variabilidad de la estimación. `metaSurvey` permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de forma nativa y con estos resultados hacer recomendaciones sobre la utilidad y confianza de la estimación mediante coeficientes de variación, intervalos de confianza, tamaño de muestra efectivo, entre otros sin tener que ser un experto en metodología de estimación de varianzas y remuestreo. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete `metasurvey` y su implementación de estimaciones puntuales y sus errores asociados.

El desarrollo de un paquete en R es un proceso que requiere contar con una idea bien formada y los medios para llevarla a cabo es por esto que es importante contar con una metodología de trabajo ordenada, heredada del desarrollo de software convencional ya que para la publicación y difusión del paquete se tiene que cumplir con ciertos estándares de calidad y documentación para que otros usuarios puedan utilizarlo. En este sentido, es importante tener en cuenta que el desarrollo de un paquete en R puede llevar tiempo y esfuerzo, a consecuencia de esto, en el documento se presentarán diferentes conceptos sobre metodología para el desarrollo de paquetes en R y se abordaran ejemplos con la implementación de `metasurvey`.

En este sentido, `metasurvey` pretende ser una herramienta relevante para el trabajo con encuestas por muestreo en general ya sea en las ciencias sociales o el uso genérico para otras disciplinas, buscando solucionar las limitaciones anteriormente mencionadas. Todo el proceso de transformación de los microdatos a indicadores se realiza a través de una serie de funciones que permiten al usuario tener un control total y transparente sobre el proceso de transformación de los microdatos a indicadores. Además, `metasurvey` permite que el usuario pueda realizar el proceso de transformación de los microdatos a indicadores de manera reproducible y transparente. El usuario puede compartir el código de una forma entendible, casi como un "recetario de cocina". El procedimiento aplicado a los datos utilizados para obtener los indicadores se realiza mediante lo que denominamos steps y recipes, conformando así una especie de camino transparente para la construcción de indicadores. Esto permite compartir en forma visual un DAG (Directed Acyclic Graph) que permite visualizar el proceso de construcción de indicadores sin tener que abrir un script de R. En complemento al proceso de creación de variables, `metasurvey` permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de manera sencilla y brindar recomendaciones sobre la utilidad de la estimación en el caso de que se cuente con una variabilidad alta en la estimación, en base a recomendaciones a su coeficiente de variación o métricas similares.

El enfoque que permite la flexibilidad a la hora de construir los indicadores es la meta-programación. La meta-programación es un paradigma de programación que permite que un programa pueda modificar su estructura interna en tiempo de ejecución. En R, la meta-programación se realiza a través de las funciones `eval`, `parse`, `substitute`, `do.call` y `quote`, que permiten evaluar y parsear código de manera dinámica. En este sentido, `metasurvey` utiliza la meta-programación para permitir que el usuario pueda modificar el código que se utiliza para transformar los microdatos a indicadores, teniendo funciones de alto nivel similares a las que se utilizan en el paquete recipes de la librería `tidymodels` [@kuhn2024].

En el siguiente capitulo se presentara un marco conceptual básico sobre el muestreo de poblaciones finitas, diferentes paradigmas de programación como puede ser la programación orientada a objetos, programación funcional y la meta-programación y como se utilizan en el desarrollo del paquete. Luego, se ahondara en antecedentes previos tanto en la parte de metodología de estimación de varianzas y paquetes e ideas similares donde se basa el desarrollo del paquete. Finalmente, se presentarán ejemplos de cómo utilizar el paquete `metasurvey` para construir indicadores de mercado laboral a partir de los microdatos de la **ECH** y para mostrar su flexibilidad, se incluirá un ejemplo con la **EPH**