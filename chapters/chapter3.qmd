---
bibliography: [references.bib]
---

```{css}
#| echo: false
p {
  text-align: justify
}
```

# Marco teórico {#sec-Chapter3}

```{r}
#| echo: false

source("../_common.R")
```

```{r}
#| results: "asis"
#| echo: false

status(
  "validacion"
)
```

En este capítulo se presentan los antecedentes y conceptos aplicados en el desarrollo de `metasurvey`. Se abordan conceptos de investigación reproducible, la importancia de R como herramienta, la revisión de paquetes para el procesamiento de encuestas por muestreo y la relevancia del diseño muestral. También se analiza la importancia de la estimación de las varianzas en la generación de indicadores y los trabajos previos en los que se basa el paquete. Estos conceptos son fundamentales para comprender el desarrollo y la importancia de establecer un flujo de trabajo sistemático en la generación de indicadores sociales.

En la actualidad, la generación de indicadores sociales se ha convertido en una tarea fundamental tanto para la toma de decisiones como para la investigación. Sin embargo, este proceso puede resultar complejo, ya que requiere conocimiento específico sobre el formulario de la encuesta y formas de construir ciertos índices o variables auxiliares que no necesariamente son triviales y dependen de la experiencia del usuario.

<<<<<<< HEAD
Este proceso de generación de indicadores frecuentemente carece de transparencia o documentación adecuada, en parte por la ausencia de herramientas apropiadas y en parte por la falta de una cultura de reproducibilidad, ya que generalmente solo se hace referencia a los datos y no al proceso completo de generación de los indicadores.
=======
Este proceso de generación de indicadores en algunos casos no es transparente o no se documenta de manera adecuada, en parte por la falta de herramientas que lo permitan y en otra parte por la falta de cultura de la reproducibilidad ya que en la mayoría de los casos se hace referencia a los datos y no al proceso de generación de los indicadores.
>>>>>>> a0bb8c2 (Update chapters)

## Orden Lógico de la Reproducibilidad en el Análisis de Encuestas

El concepto de investigación reproducible ha cobrado relevancia en los últimos años, tanto en la academia como en la industria y esto se debe a la fricción que puede llegar a existir al momento de presentar resultados de investigación o generación indicadores relevantes para la toma de decisiones debido al proceso de generación de los mismos. Dentro de las diferentes disciplinas generar ambientes de trabajo reproducibles puede llegar a ser un desafío, ya que en la mayoría de los casos se utilizan diferentes herramientas, lenguajes de programación y bases de datos.

En la actualidad existen diferentes revistas científicas que promueven la investigación reproducible, herramientas, guías para buenas prácticas para trabajar con datos y código fuente como Sumatra [@davison2012], implementaciones de programación literal [@knuth1984] como RMarkdown [@allaire2024] o Jupyter Notebook [@kluyver2024] y diferentes implementaciones para gestionar dependencias de software como Anaconda [@anaconda2024], aunque algunas de ellas se han vuelto herramientas de pago o ya no existen en la actualidad, mas referencias y casos de uso pueden encontrarse en [@stodden2014].

Antes de continuar es necesario definir conceptos fundamentales en el ámbito de la investigación reproducible, tales como la *Reproducibilidad* que refiere a la capacidad de poder repetir los resultados de un estudio, experimento o la obtención de un indicador. Si bien la reproducibilidad es considerada en un artículo de investigación científica al utilizar indicadores tanto en contextos académicos como en aplicaciones de monitoreo o divulgación de información, rara vez se documenta o se menciona de que manera se generó ese resultado haciendo referencia únicamente a los datos y rara vez al código fuente. Aún compartiendo el código fuente, esto aún no suficiente para poder reproducir un estudio o un indicador por incompatibilidades de versiones de software, cambios en la estructura de los datos interpretaciones de los datos, estilos de programación, entre otros pudiendo llevar mucho tiempo y esfuerzo para poder replicar un resultado.

El proceso de tratamiento de datos y limpieza forma parte de lo que se conoce como *publicaciones grises* [@vilhuber2020]. Este concepto se refiere a la publicación de datos, código y reportes que no son publicaciones formales, pero son esenciales para generar conocimiento científico. En su mayoría al no tener una revisión por pares o una forma estandarizada esto se incluye de forma muy dispar o sin ningún tipo de documentación para poder ser reproducido y esto forma una gran parte de la investigación científica que no se encuentra aprovechada.

Existen diversas iniciativas destinadas a fomentar la reproducibilidad en la ciencia, lo que ha llevado a las revistas a establecer políticas de datos y código abierto. Sin embargo, persisten desafíos en la generación de indicadores sociales, ya que como se menciono anteriormente no basta con hacer referencia a los datos, como se señala en [@bechhofer2013]; además de publicar el artículo junto a los datos, es necesario vincular los objetos de investigación (Research Objects **RO**), existen diferentes plataformas que permiten la publicación de estos objetos como [**Zenodo**](https://zenodo.org/) y [**Figshare**](https://figshare.com/) o [**OSF**](https://osf.io/) que permiten la integración de datos, código e interacción con repositorios con control de versiones como GitHub o GitLab.

De conceptos generales sobre reproducibilidad es importante contar con un flujo de trabajo (*Workflow managment System* [@prabhu2020]) para la obtención de estimadores en el procesamiento de encuestas por muestreo ya que el indicador final es el resultado de una serie de pasos que se deben seguir de manera ordenada y documentada para poder ser auditados y replicados en diferentes contextos, inspirado en [@sandve2013] se pueden considerar algunas buenas prácticas para la generación de indicadores:

-   **Para cada resultado, se debe tener un respaldo de como fue construido**: Al trabajar con lenguajes de programación como R, los script de código fuente son un respaldo de como obtener cierto resultado, sin embargo, esto puede estar ligado a tu estilo de programación y la versión de los paquetes que se utilizan.

-   **Crear manuales en la manipulación de datos**: Es importante resumir cada paso por mas mínimo que sea en la transformación de variables, esto permite entender todo el proceso de generación de un indicador.

-   **Guardar las versiones de los paquetes utilizados**: Al trabajar con R, es importante guardar las versiones de los paquetes que se utilizan, esto permite que en un futuro se pueda replicar el proceso de generación de indicadores, para esto puede utilizarse herramientas como `renv` [@ushey2023] un paquete que permite crear ambientes locales con versiones especificas de paquetes de R, `venv` [@pythonsoftwarefoundation2024] que son ambientes virtuales en python o Docker [@merkel2014] para poder emular un ambiente de trabajo en diferentes sistemas operativos.

-   **Guardar pasos intermedios, en un formato estándar**: Al trabajar con encuestas por muestreo y para crear indicadores sencillos se realizan dos grandes tipos de operaciones: crear grupos o categorías o realizar operaciones matemáticas, es importante guardar estos pasos en un formato estándar para poder ser reutilizados en diferentes contextos.

-   **Compartir las ejecuciones y scripts**: Es importante que los scripts de código fuente estén disponibles para que puedan ser auditados y replicados en diferentes contextos.

### Conceptos clave

`metasurvey` se basa en las buenas prácticas mencionadas anteriormente y permite crear herramientas de flujo de trabajo siguiendo los siguientes principios:

-   **Reusable**: Se separa el proceso de transformación de variables en `Steps` que refiere a transformaciones de columnas, estos procedimientos pueden ser comunes tanto en diferentes encuestas como en diferentes indicadores. Estos `Steps` pueden ser reutilizados en diferentes `Recipes` para calcular indicadores de mercados de trabajo, pobreza, e incluso aplicarlos en varias encuestas simultáneamente mediante un `Workflow`.

-   **Repetible**: Al tener un proceso definido en un `Workflow`, es posible repetir el proceso de generación de indicadores de la misma manera y automatizar la generación de reportes.

-   **Referenciable** y **Acreditable**: Al contar con un `Workflow`, es posible hacer referencia al proceso de generación de indicadores indicando todos los pasos seguidos y el autor o equipo que lo realizó. Además, se puede acreditar a los autores de los `Steps` y `Recipes` que se utilizaron en el proceso.

### Workflow reproducible

El concepto de *Workflow* no es nuevo y exclusivo en la comunidad científica, en la actualidad en la industria de la ciencia de datos se han desarrollado diferentes herramientas para la gestión de flujos de trabajo para el procesamiento de datos, con diferentes enfoques y objetivos. `metasurvey` se inspira en diferentes herramientas como [**Apache AirFlow**](https://github.com/apache/airflow) [@apachea] que es una plataforma de orquestación de flujos de trabajo de código abierto, [**Great Expectations**](https://greatexpectations.io/) [@expectations2024] que es una biblioteca de validación de datos para la generación de reportes de calidad de datos y [**Make**](https://www.gnu.org/software/make/) que es una herramienta de automatización de flujos de trabajo que se basa en la definición de reglas y dependencias.

En el ámbito del aprendizaje automático existe un gran esfuerzo para poder desgranar y documentar los modelos conocido como **Model Cards** [@mitchell2019] donde se hace un detalle de los algoritmos utilizados, las métricas de evaluación, los datos utilizados y su procesamiento, siendo esto el análogo a los `Steps` y `Recipes` de `metasurvey`. Este concepto se ha extendido siendo un estándar en la industria y siendo adoptado por diferentes organizaciones como [**Google**](https://modelcards.withgoogle.com/) y [**Hugging Face**](https://huggingface.co/docs/hub/en/model-cards).

Tomando en cuenta estos conceptos, `metasurvey` tiene disponible la posibilidad de generar, compartir y visualizar los flujos de trabajo de manera gráfica permitiendo la transparencia y auditabilidad de los procesos de generación de indicadores.

## Investigación reproducible en R

Dentro de CRAN existe una guía sobre conjunto de paquetes y herramientas con objetivos comunes denominado **Task Views** que agrupa paquetes de R que se utilizan para un propósito específico. En el Task View de [Reproducible Research](https://cran.r-project.org/web/views/ReproducibleResearch.html) se encuentran diferentes paquetes que permiten la generación de reportes dinámicos, la gestión de flujos de trabajo y la generación de documentos interactivos aunque también existen herramientas para la gestión de flujos de trabajo generales como `targets` [@landau2021] y `drake` [@landau2018], `metasurvey` fue inspirado en los conceptos y la forma de trabajo de estos paquetes.

Los conceptos de meta-programación y programación orientada a objetos fue inspirado en el paquete `mlr3pipelines` [@binder2021] que permite la creación de flujos de trabajo para el preprocesamiento de datos y la generación de modelos de aprendizaje automático, aquí se definen `PipeOps` que son operaciones que se pueden aplicar a los datos y se pueden combinar en un `Graph` que define el flujo de trabajo para ello se definen clases y métodos que permiten una fácil extensión por parte del usuario y la creación de flujos de trabajo complejos.

Dentro de la comunidad existen organizaciones como [rOpenSci](https://ropensci.org/) que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R. Esta organización promueve la creación de paquetes donde además de la guías sobre el desarrollo de paquetes y la revisión de los mismos, se promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación. Para formar parte de rOpenSci, se sigue una evaluación entre pares y una revisión de la calidad del paquete, además de la documentación y la calidad del código complementado con tests automatizados.

### Herramientas para el procesamiento de encuestas

En el ámbito de las encuestas por muestreo, existen diferentes paquetes que permiten el procesamiento de encuestas por muestreo o la generación de estadísticas oficiales, esto se puede ver en el Task View de [Official Statistics & Survey Methodology](https://cran.r-project.org/web/views/OfficialStatistics.html) donde se encuentran diferentes tipos de paquetes desde la preparación de formularios, calibración, análisis de datos, acceso a datos oficiales, entre otros.

Para el procesamiento de encuestas por muestreo, existe una serie de paquetes que permiten implementar la metodología de encuestas por muestreo como puede ser el caso de `survey` [@lumley2024] que permite el análisis de encuestas complejas, `srvyr` [@ellis2023] aunque estos son utilizados en el proceso final o de inferencia y no en el proceso de la construcción y limpieza de los datos como si lo hace `ech` [@detomasi2020] que tiene diferentes funciones para la ECH y permite al usuario crear variables referidas a Vivienda, Educación, Mercado de Trabajo, Ingresos y Pobreza algo similar con `eph` [@kozlowski2020] que permite la descarga de datos de la EPH y la creación de variables para analizar la pobreza y el mercado de trabajo.

Este ultimo grupo de paquetes o **caja de herramientas** tienen la limitación que no permiten la reutilización de los pasos de limpieza y transformación de los datos de forma sencilla y nativa, además de no poder visualizar el flujo de trabajo de manera gráfica, lo que dificulta la auditoría y la replicabilidad de los procesos de generación indicadores, `metasurvey` busca llenar este vacío permitiendo la reutilización de los pasos de limpieza y transformación de los datos, la visualización del flujo de trabajo y la generación de reportes de manera sencilla.

<<<<<<< HEAD
## Comparación de Paquetes para el Análisis de Encuestas
=======
## Diseño de encuestas y estimación de varianza

Como fue introducido en el capitulo anterior y en la sección de antecedentes es sencillo obtener estimaciones puntuales, sin embargo, es necesario presentar una medida de precisión de la estimación ya que en algunos casos puede ser que el tamaño de la muestra no sea suficiente para obtener estimaciones precisas. En el caso de las encuestas por muestreo, es necesario tener en cuenta el diseño de la encuesta, la estratificación, la ponderación y el efecto de conglomerados, ya que estos factores influyen en la precisión de la estimación. Para ello, es necesario contar con alguna metodología que permita estimar varianzas ya que para diseños complejos o estadísticos no lineales, la estimación de varianzas no es trivial.

En la actualidad, existen diferentes métodos para la estimación de varianzas, aunque en la mayoría de los casos se utilizan métodos de remuestreo como el Boostrap o el Jackknife, sin embargo existen diferentes ideas o propuestas como se menciona en [@deville1998] y [@deville2005] que demuestran con resultados numéricos estimadores del tipo **H-T** bajo un diseño balanceado puede aproximarse desde el enfoque de regresión o calibración. Además existen estimadores alternativos donde complementan métodos de remuestreo para aproximar probabilidades de inclusión de segundo orden [@escobar2013] utilizando ciertas aproximaciones límites [@hajek1964].

Cada metodología depende de cada diseño y variables a estimar, por esto es que existen diferentes metodologías y paquetes como `gustave` [@chevalier2023] , `vardpoor` [@breidaks2020], `svrep` [@schneider2023] y `samplingVarEst` [@escobar2023], aunque existen similitudes entre implementaciones y métodos es difícil encontrar una implementación que permita la estimación de varianzas de manera sencilla y que permita la reutilización de los pasos de limpieza y transformación de los datos, esto puede ser complicado para usuarios que no tienen experiencia en el procesamiento de encuestas por muestreo y que buscan una herramienta que les permita realizar este tipo de análisis de manera sencilla y visual.
>>>>>>> a0bb8c2 (Update chapters)

### Resumen de las implementaciones {.unnumbered}

En la [@tbl-comparacion-paquetes] a continuación se presenta un resumen de las implementaciones de los paquetes mencionados anteriormente:

```{r}
library(gt)
library(gh)

get_repo_info <- function(owner, repo) {
  # Obtener la última versión (tag)
  releases <- gh::gh(
    "/repos/{owner}/{repo}/releases",
    owner = owner,
    repo = repo
  )
  latest_release <- if (length(releases) > 0) {
    releases[[1]]$tag_name
  } else {
    "No release"
  }

  # Obtener el último commit
  commits <- gh::gh(
    "/repos/{owner}/{repo}/commits",
    owner = owner,
    repo = repo
  )
  latest_commit_date <- if (length(commits) > 0) {
    commits[[1]]$commit$author$date
  } else {
    "No commit"
  }

  list(
    version = latest_release,
    commit = latest_commit_date
  )
}

# Obtener información de cada repositorio
survey_info <- get_repo_info("cran", "survey")
srvyr_info <- get_repo_info("gergness", "srvyr")
gustave_info <- get_repo_info("inseeFr", "gustave")
vardpoor_info <- get_repo_info("CSBLatvia", "vardpoor")
convey_info <- get_repo_info("ajdamico", "convey")
svrep_info <- get_repo_info("cran", "svrep")

# Definir los datos para la tabla
data <- data.frame(
  Paquete = c(
    "[survey](https://github.com/cran/survey)",
    "[srvyr](https://github.com/gergness/srvyr)",
    "[gustave](https://github.com/InseeFr/gustave)",
    "[vardpoor](https://github.com/CSBLatvia/vardpoor)",
    "[convey](https://github.com/AnthonyChristidis/convey)",
    "[svrep](https://github.com/cran/svrep)"
  ),
  Descripción = c(
    "Permite el análisis de encuestas complejas, aquí se pueden definir los estratos, los conglomerados y las ponderaciones, además tiene implementaciones de los estimadores más comunes como el estimador de Horvitz-Thompson, el estimador de regresión y el estimador de calibración. Sin embargo, dentro de este mismo paquete no existe una forma de integrar los pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo. Este paquete es utilizado como dependencia **clave** para ocupar los principales estimadores poblacionales y diseño muestral.",
    "Es una interfaz para el paquete `survey` que permite trabajar con `dplyr` y `tidyverse`, sin embargo, no permite de forma nativa la reutilización de los pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo aunque permite la integración con `dplyr` y `tidyverse`. Este paquete cuenta con muchas dependencias debido al uso de `tidyverse` y va en contra de la filosofía de `metasurvey` de tener la menor cantidad de dependencias posibles. Además metasurvey tiene su propia capa de abstracción para trabajar con `survey`.",
    "Cuenta con una función principal `qvar` que no utiliza el diseño muestral como argumento sino que se deben de ingresar las probabilidades de inclusión y no queda del todo claro los estadísticos que se pueden obtener. Además, no permite la reutilización de los pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo. Si bien tiene diferentes implementaciones de aproximación de varianzas como la de Deville y Tillé, no es la forma de estimación que utiliza `metasurvey` por defecto aunque puede ser una alternativa para futuras implementaciones.",
    "Este paquete utiliza la estimación de varianzas por el método de último conglomerado, otras métricas como el efecto diseño, linealización del estimador de razón, coeficiente de Gini y diferentes estadísticos enfocados en la desigualdad. Si bien es una implementación interesante, su sintaxis es particular y ajena a la del paquete `survey`, tiene muy pocas dependencias pero puede ser implementado como motor de estimación de varianzas en futuras implementaciones.",
    "Este paquete sí utiliza el diseño muestral como argumento e implementa algunos estadísticos que se incluyen en `vardpoor`, sin embargo, no permite la reutilización de pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo. Sin embargo, al tener una implementación del diseño muestral, se sincroniza muy bien con `metasurvey`. Los estadísticos pueden ser utilizados de forma nativa en `metasurvey`.",
    "Extensión del paquete `survey` para trabajar con réplicas sobre los pesos muestrales, permite la estimación de varianzas por el método de Bootstrap, Jackknife y replicación de balanceo. La integración con el diseño del tipo `bootstrap` y `jackknife`. Este paquete es utilizado como dependencia **clave** para ocupar los principales estimadores poblacionales y diseño muestral y es utilizado en `metasurvey` para la estimación de varianzas."
  ),
  ultimo_Commit = c(
    survey_info$commit,
    srvyr_info$commit,
    gustave_info$commit,
    vardpoor_info$commit,
    convey_info$commit,
    svrep_info$commit
  )
)

# Crear la tabla gt con renderizado de Markdown y un tema personalizado
gt_table <- data |>
  gt() |>
  tab_header(
    title = "Comparación de Paquetes para Análisis de Encuestas",
    subtitle = "Información actualizada sobre versiones y últimos commits"
  ) |>
  cols_label(
    Paquete = "Paquete",
    Descripción = "Descripción",
    ultimo_Commit = "Último Commit"
  ) |>
  tab_source_note(
    source_note = "Datos extraídos desde GitHub a través de la API."
  ) |>
  fmt_markdown(columns = c(Descripción)) |>
  fmt_markdown(columns = c(Paquete)) |>
  cols_align(
    align = "left",
    columns = c(Paquete, Descripción, ultimo_Commit)
  ) |>
  opt_table_font(
    font = list(google_font("Roboto"), default_fonts())
  ) |>
  tab_options(
    table.font.size = px(12),
    data_row.padding = px(8),
    table.border.top.color = "black",
    table.border.bottom.color = "black",
    heading.background.color = "#f5f5f5",
    row.striping.background_color = "#f0f0f0"
  ) |>
  opt_row_striping()

gtsave(gt_table, "Figures/tabla.pdf")
```

```{r}
#| tbl-cap: Comparación de paquetes para análisis de encuestas
#| label: tbl-comparacion-paquetes
library(reactable)
library(htmltools)

if (knitr::is_html_output()) {
  reactable_table <- reactable(
    data,
    columns = list(
      Paquete = colDef(
        name = "Paquete",
        cell = function(value) {
          shiny::markdown(value)
        },
        html = TRUE
      ),
      Descripción = colDef(
        name = "Descripción",
        cell = function(value) {
          shiny::markdown(value)
        },
        html = TRUE
      ),
      ultimo_Commit = colDef(name = "Último Commit")
    ),
    striped = TRUE,
    highlight = TRUE
  )
  reactable_table
} else {
  knitr::include_graphics("Figures/tabla.pdf")
}
```

Como se puede observar en la [@tbl-comparacion-paquetes], `metasurvey` busca llenar el vacío de la reutilización de los pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo, aprovechando como dependencia `survey` y `svrep` para la estimación de varianzas y la generación de indicadores sociales, permitiendo la generación de reportes de manera sencilla y visualizar el flujo de trabajo de manera gráfica.

<<<<<<< HEAD
## Diseño de encuestas y estimación de varianza

Como fue introducido en el capitulo anterior y en la sección de antecedentes es sencillo obtener estimaciones puntuales, sin embargo, es necesario presentar una medida de precisión de la estimación ya que en algunos casos puede ser que el tamaño de la muestra no sea suficiente para obtener estimaciones precisas. En el caso de las encuestas por muestreo, es necesario tener en cuenta el diseño de la encuesta, la estratificación, la ponderación y el efecto de conglomerados, ya que estos factores influyen en la precisión de la estimación. Para ello, es necesario contar con alguna metodología que permita estimar varianzas ya que para diseños complejos o estadísticos no lineales, la estimación de varianzas no es trivial.

En la actualidad, existen diferentes métodos para la estimación de varianzas, aunque en la mayoría de los casos se utilizan métodos de remuestreo como el Boostrap o el Jackknife, sin embargo existen diferentes ideas o propuestas como se menciona en [@deville1998] y [@deville2005] que demuestran con resultados numéricos estimadores del tipo **H-T** bajo un diseño balanceado puede aproximarse desde el enfoque de regresión o calibración. Además existen estimadores alternativos donde complementan métodos de remuestreo para aproximar probabilidades de inclusión de segundo orden [@escobar2013] utilizando ciertas aproximaciones límites [@hajek1964].

Cada metodología depende de cada diseño y variables a estimar, por esto es que existen diferentes metodologías y paquetes como `gustave` [@chevalier2023] , `vardpoor` [@breidaks2020], `svrep` [@schneider2023] y `samplingVarEst` [@escobar2023], aunque existen similitudes entre implementaciones y métodos es difícil encontrar una implementación que permita la estimación de varianzas de manera sencilla y que permita la reutilización de los pasos de limpieza y transformación de los datos, esto puede ser complicado para usuarios que no tienen experiencia en el procesamiento de encuestas por muestreo y que buscan una herramienta que les permita realizar este tipo de análisis de manera sencilla y visual.

## Herramientas para el desarrollo de paquetes en R

Cualquier usuario puede desarrollar un paquete en R, aunque existen diferentes guías y estándares para el desarrollo de paquetes en R, como se menciona en [@rpackag] , además de la guía de rOpenSci [@ropensci_2024_10797633] que promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación.
=======
## Desarrollos de paquetes en R

Actualmente R es uno de los lenguajes de programación más utilizados en la comunidad científica y parte de la industria cuando se realizan análisis de datos, esto se debe a la gran comunidad de desarrolladores y la cantidad de paquetes que se encuentran disponibles en CRAN y GitHub. En la actualidad, existen diferentes organizaciones que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R.

Sin embargo cualquier usuario puede desarrollar un paquete en R, aunque existen diferentes guías y estándares para el desarrollo de paquetes en R, como se menciona en [@rpackag] , además de la guía de ROpenSci [@ropensci_2024_10797633] que promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación.
>>>>>>> a0bb8c2 (Update chapters)

Para el desarrollo de `metasurvey` se utilizaron paquetes como `usethis` [@usethis] que permite la creación de paquetes en R, `roxygen2` [@roxygen2] que permite la documentación de funciones y la creación de manuales, `testthat` [@testthat] que permite la creación de tests automatizados, `pkgdown` [@pkgdown] que permite la creación de sitios web para paquetes de R, `devtools` [@devtools] que permite la instalación y la carga de paquetes en R, `renv` [@ushey2023] que permite la creación de ambientes locales con versiones especificas de paquetes de R junto a herramientas herramientas como pre-commit [@pre_commit] que permite la ejecución de scripts antes de realizar un commit en un repositorio de git esto con el fin de mantener la calidad del código y la documentación antes de realizar un cambio en el repositorio. De forma conjunta se utilizó GitFlow [@nvie_gitflow] que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git. Para la automatización de los tests en diferentes sistemas operativos se utilizó GitHub Actions [@github_actions] que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov [@codecov].

Todo estas herramientas permiten que la creación de paquetes sea sencilla y permita a los usuarios enfocarse en la implementación con cierto grado de calidad y documentación, además de permitir la colaboración y la integración continua de los cambios en un repositorio de git.

### Implementación de tests automatizados {.unnumbered}

El paquete incluye tests automatizados creados con `testthat`, lo que asegura la robustez del código fuente al ser utilizado en diversos contextos. Un ejemplo es el test de la función `extract_time_pattern`, que analiza el nombre de una encuesta y retorna su tipo, año y periodicidad. Esta función clave utiliza expresiones regulares para manejar distintos formatos de tiempo y es fundamental para tareas como definir la edición de encuestas o emparejar réplicas bootstrap. Su implementación completa puede encontrarse aquí: [extract_time_pattern](https://github.com/metasurveyr/metasurvey/blob/018608ef7a88a8afc703be0ae123a2af950ee496/R/utils.R#L306).

::: {#lst-test-extract-time-pattern}
```{r}
#| eval: false
#| echo: true
#| code-fold: show
test_that(
  "Probar extraer time pattern anual",
  {
    testthat::expect_equal(
      metasurvey:::extract_time_pattern("ECH_2023"),
      list(
        type = "ECH",
        year = 2023,
        periodicity = "Annual"
      )
    )
  }
)

```

Ejemplo de un test automatizado para verificar el correcto funcionamiento de la función extract_time_pattern.
:::

<<<<<<< HEAD
Al tener una serie de test automatizados como el presentado en el [código @lst-test-extract-time-pattern] se realice antes de realizar cambios en el código fuente pueda el desarrollador ejecutar los tests y verificar que no existan problemas ante un cambio o una refactorización del código fuente. Para el envió a CRAN se realizan estos test automático y una serie de pruebas de calidad y documentación para que el paquete sea aceptado en CRAN. Actualmente `metasurvey` no tiene errores, mensajes de advertencia o notas en CRAN, la cobertura del código es baste baja ya que realizar test para todas las funciones es un trabajo arduo y que requiere tiempo, sin embargo en futuras versiones se espera tener una cobertura del código mayor al 80%. La cobertura puede ser verificada en el siguiente enlace: [codecov](https://codecov.io/gh/metasurveyr/metasurvey).
=======
Al tener una serie de test automatizados como el presentado en el [@lst-test-extract-time-pattern] se realice antes de realizar cambios en el código fuente pueda el desarrollador ejecutar los tests y verificar que no existan problemas ante un cambio o una refactorización del código fuente. Para el envió a CRAN se realizan estos test automático y una serie de pruebas de calidad y documentación para que el paquete sea aceptado en CRAN. Actualmente `metasurvey` no tiene errores, mensajes de advertencia o notas en CRAN, la cobertura del código es baste baja ya que realizar test para todas las funciones es un trabajo arduo y que requiere tiempo, sin embargo en futuras versiones se espera tener una cobertura del código mayor al 80%. La cobertura puede ser verificada en el siguiente enlace: [codecov](https://codecov.io/gh/metasurveyr/metasurvey).
>>>>>>> a0bb8c2 (Update chapters)

### Documentación {.unnumbered}

Para la documentación se utilizó `roxygen2` que permite la documentación de funciones y la creación de manuales, además de `pkgdown` que permite la creación de sitios web para paquetes de R, esto permite que los usuarios puedan tener una guía de referencia para utilizar el paquete y que los desarrolladores puedan tener una guía de referencia para la implementación de nuevas funciones o la modificación de las existentes.

::: {#lst-roxygen2}
```{r}
#| eval: false
#| echo: true
#| code-fold: show
#' @title Load survey
#' @param path Path to the survey file
#' @param svy_type Type of survey
#' @param svy_edition Edition of the survey
#' @param svy_weight Weight of the survey
#' @param svy_psu Primary sampling unit
#' @param ... Additional arguments
#' @param bake Logical
#' @return Survey object
#' @keywords preprocessing
#' @export
load_survey <- function(
    path = NULL,
    svy_type = NULL,
    svy_edition = NULL,
    svy_weight = NULL,
    svy_psu = NULL,
    ..., bake = FALSE) {
      # Ejemplo no mostrado debido a la extensión del
      # código puede ser consultado en 
      # el repositorio de GitHub
}
```

Extracto de la documentación de la función `load_survey` con las etiquetas necesarias para la generación de la documentación.
:::

Como se puede observar en el [código @lst-roxygen2], la documentación de las funciones se realiza con comentarios en el código fuente, esto permite que `roxygen2` pueda generar la documentación de las funciones y los manuales de manera automática, simplemente hay que añadir comentarios con ciertas etiquetas que dependiendo si la función es exportada o no, es un requisito para la aceptación en CRAN que las funciones que se exporten estén documentadas y que la documentación sea clara y concisa. La documentación puede ser consultada en el siguiente enlace: [Documentación de metasurvey](https://metasurveyr.github.io/metasurvey/) o en la ayuda de R con `?load_survey`.

\newpage

### Pruebas en diferentes sistemas operativos y versiones de R junto a GitHub Actions {.unnumbered}

En muchos casos, los paquetes de R pueden tener problemas de compatibilidad con diferentes versiones de R o con diferentes sistemas operativos, para evitar estos problemas se utilizó GitHub Actions que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov. En el caso de `metasurvey` se realizan pruebas en diferentes versiones de R y en diferentes sistemas operativos como Windows, MacOS y Linux, esto permite que el paquete sea compatible con diferentes versiones de R y sistemas operativos.

Todo esto fue realizado en GitHub Actions donde se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R. En este caso al utilizar GitFlow que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git, se puede tener una rama de desarrollo y una rama de producción, donde en la rama de desarrollo se realizan los cambios y se ejecutan los test y en la rama de producción se realiza la publicación en CRAN. Todo esto permite que el paquete sea robusto y que los cambios sean integrados de manera continua en el repositorio. Para la integración de una nueva versión se realizan pull request que son un pedido de integración de cambios en la rama de desarrollo, esto permite que los cambios sean revisados y auditados antes de ser integrados en la rama principal.

::: {#lst-github-actions}
```{YAML}
#| eval: false
#| echo: true
#| code-fold: show
on:
  push:
    branches: 
      - main
      - develop
  pull_request:
    branches: [develop]

name: R-CMD-check

jobs:
  R-CMD-check:
    runs-on: ${{ matrix.config.os }}

    name: ${{ matrix.config.os }} (${{ matrix.config.r }})

    strategy:
      fail-fast: false
      matrix:
        config:
          - {os: macos-latest,   r: 'release'}
          - {os: windows-latest, r: 'release'}
          - {os: ubuntu-latest,   r: 'devel', http-user-agent: 'release'}
          - {os: ubuntu-latest,   r: 'release'}
          - {os: ubuntu-latest,   r: 'oldrel-1'}

    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
      R_KEEP_PKG_SOURCE: yes

    steps:
      - uses: actions/checkout@v4

      - uses: r-lib/actions/setup-pandoc@v2

      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: ${{ matrix.config.r }}
          http-user-agent: ${{ matrix.config.http-user-agent }}
          use-public-rspm: true

      - uses: r-lib/actions/setup-r-dependencies@v2
        with:
          extra-packages: any::rcmdcheck
          needs: check

      - uses: r-lib/actions/check-r-package@v2
        with:
          upload-snapshots: true
```

Archivo de configuración de GitHub Actions para la ejecución de tests en diferentes sistemas operativos y versiones de R.
:::

Como se puede observar en el [código @lst-github-actions], se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R, esto es lanzado automáticamente cuando se hace un cambio en la rama de desarrollo o en la rama de producción puede aquí verse el historial y ejemplos del mismo [paquete](https://github.com/metasurveyr/metasurvey/actions).

En capítulos posteriores se presentará la implementación de conceptos de workflows, meta-programación y metodologías de estimación de varianzas en `metasurvey` para la generación de indicadores sociales.
