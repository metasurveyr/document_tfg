[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metasurvey",
    "section": "",
    "text": "Descripción del proyecto metasurvey\n\n\nEste paquete proporciona un conjunto de funciones para facilitar el análisis de datos de encuestas con diseño muestral utilizando técnicas de metaprogramación. En el paquete puedes crear pipelines de análisis reproducibles, y generar fácilmente informes y tablas. El paquete está diseñado para trabajar con el paquete survey, y es particularmente útil para diseños de encuestas complejos. El mismo fue desarrolado en el contexto del un trabajo final de grado de la Licenciatura en Estadística de la Facultad de Ciencias Económicas de la Universidad de la República.\n\n\nLa idea inicial fue motivada en base a lo dificil que resulta trabajar con microdatos de encuestas donde sus formularios son muy extensos y complejos, cambiando de un año a otro. Esto hace que sea muy dificil mantener actualizados los códigos de análisis de los datos o es necesario consultar a los expertos en cada tematica para entender la forma en que se codifican las variables y puede llevar a errores en la interpretación de los resultados.\n\n\nAdemás en algunos casos se requiere analizar una serie de resultados de encuestas de diferentes años, lo que hace que sea necesario unificar los códigos de análisis de los datos para poder comparar los resultados a lo largo del tiempo y poder realizar análisis longitudinales, esto puede llegar a ser caotico mas que nada cuando se tienen muchos años de encuestas. Esto puede llegar a ser muy manual obteniendo indicadores de forma independiente para cada año y luego guardando los resultados en alguna tabla de Excel o en un archivo de texto.\n\n\nEn el caso de necesitar entender la forma en que se codifican las variables de las encuestas puede ser muy dificil, ya que dentro de cada programa estadístico la manipulación de los datos es diferente así como también el estilo de programación de cada usuario. A su vez puede ser que sea necesario contar con un software específico para poder analizar los datos de la encuesta, lo que puede ser un problema si no se cuenta con el mismo.\n\n\nPor lo tanto, la idea de este paquete es poder facilitar el análisis de datos de encuestas con diseño muestral complejo, permitiendo la creación de pipelines de análisis reproducibles, y la generación de informes y tablas de forma sencilla. El paquete está diseñado para trabajar con el paquete survey, y es particularmente útil para diseños de encuestas complejos.\n\n\nAdemás, el paquete proporciona un conjunto de funciones para facilitar la estimación de la varianza de diseños de encuestas complejos, y para facilitar el análisis de diseños de encuestas complejos utilizando el paquete survey.\n\n\nSu desarrollo fue motivado en el desarrollo del portal PRISMA que es un portal de datos abiertos de la Agencia Nacional de Investigación e Innovación (ANII) de Uruguay. En el portal se encuentran diferentes secciones donde la sección de Innovación y Género cuenta con una serie de indicadores que provienen de encuestas por muestreo. Construir estos indicadores en forma histórica y poder compararlos a lo largo del tiempo es un desafío, ya que las encuestas cambian de un año a otro y los códigos de análisis de los datos deben ser actualizados donde también puede ser transparente al usuario final la forma en que se codifican las variables.\n\n\nEn 2022 se fue presentado en el LatinR 2022 en su versión previa srvyuRu. Esta versión era demasiado lenta tanto al momento de realizar cálculos como al momento de poder transparentar la forma en que se codifican las variables. Por lo tanto, en 2023 se decidió reescribir el paquete en su totalidad y se decidió cambiar el nombre del paquete a metasurvey haciendo referencia a la meta-programación que se utiliza en el paquete en conjunto con el paquete survey.\n\n\nEn el paquete se pueden encontrar funciones para facilitar la carga de datos de encuestas, la recodificación de variables, la estimación de la varianza de diseños de encuestas complejos, la generación de tablas y gráficos, y la generación de informes. Además, se pueden encontrar funciones para facilitar la creación de pipelines de análisis reproducibles, y para facilitar la generación de informes y tablas de forma sencilla.\n\n\nLa documentación del paquete se encuentra en metasurveyr.github.io/metasurvey y el código fuente del paquete se encuentra en github.com/metasurveyr/metasurvey, donde se puede participar en el desarrollo del paquete y reportar errores.\n\n\nA lo largo del proyecto fueron utilizadas diferentes herramientas tanto dentro de R como fuera de R. Dentro de R se utilizó el paquete devtools para la creación del paquete, el paquete roxygen2 para la documentación del paquete, el paquete testthat para la creación de tests unitarios, el paquete pkgdown para la creación de la página web del paquete, el paquete usethis para la creación de issues y pull requests, y el paquete covr para la cobertura de los tests unitarios. Fuera de R se utilizó el paquete pre-commit para la creación de hooks de pre-commit, el paquete codecov para la cobertura de los tests unitarios, y el paquete GitHub Actions para la creación de workflows de GitHub Actions.\n\n\nEn el futuro se espera poder contar con más colaboradores para poder avanzar en el desarrollo del paquete y poder publicarlo en CRAN para que pueda ser utilizado por toda la comunidad de R. El paquete está abierto a la comunidad de R y en especial a estudiantes de la licenciatura en estadística con un enfoque en herramientas computacionales que quieran colaborar en el desarrollo del paquete.\n\n\nPara revisar el estado actual del proyecto puede consultar el siguiente cronograma donde puede ver las tareas que se han realizado y las tareas que se tienen planificadas para el futuro del proyecto. También se encuentra una lista de issues donde se pueden encontrar los problemas que se han reportado y se pueden reportar nuevos problemas\n\n\nA diciembre del 2024 el paquete no se encuentra disponible en CRAN pero se espera que en el 2025 este publicado en CRAN para que pueda ser utilizado por toda la comunidad de R. Mientras tanto, se puede instalar la versión de desarrollo desde el repositorio de Github con el siguiente código:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"metasurveyR/metasurvey\")",
    "crumbs": [
      "Descripción del proyecto"
    ]
  },
  {
    "objectID": "chapters/chapter1.html",
    "href": "chapters/chapter1.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Motivación\nLas encuestas por muestreo son una herramienta fundamental para la obtención de información sobre cierta población de interés, ya que permiten obtener información a partir de una muestra representativa de la misma. Cada encuesta por muestreo tiene una estructura y un proceso generador de datos que permite obtener estimaciones puntuales y sus errores asociados. En general, el procesamiento de encuestas puede ser tedioso y propenso a errores o difíciles de brindar transparencia y reproducibilidad, especialmente si se quiere obtener indicadores que requieren varios pasos como tasas de mercado laboral, ingreso salarial, índices de pobreza, entre otros (Vilhuber 2020).\nEn general, el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Si bien existen diferentes esfuerzos para facilitar el procesamiento de encuestas, en general estos paquetes tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés. Estas implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica.\nEn este sentido, es importante construir una herramienta que permita al usuarios tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, de una forma totalmente desacoplada dentro de las implementaciones de cada función.\nDentro de este documento se detalla el desarrollo de una herramienta que permita al usuario con simples pasos poder construir indicadores junto a una forma de obtener metodologías brindadas por la comunidad científica pudiendo reproducir los resultados o incluir de forma sencilla la metodología en su propio código. Esta herramienta debe permitir al usuario tener un control total sobre el proceso de transformación de los microdatos a indicadores, permitiendo que el usuario pueda validar y entender el proceso de construcción de indicadores, todo esto estará disponible en forma de paquete en R (R Core Team 2023).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#contexto",
    "href": "chapters/chapter1.html#contexto",
    "title": "1  Introducción",
    "section": "1.2 Contexto",
    "text": "1.2 Contexto\nA lo que refire a la teoría de la inferencia de poblaciones en muestreo de poblaciones finitas, es importante tener en cuenta la incertidumbre y errores asociados a las estimaciones producidas, en general esto no es considerado por los usuarios no expertos en metodología de muestreo. Esto puede llevar a conclusiones erróneas ya que en algunos casos el estimador asociado a la estimación cuenta con una alta variabilidad o fue calculado sin tener en cuenta el diseño muestral correcto.\nAntes de continuar, es importante distinguir dentro de la inferencia estadística el enfoque model-based inference y desing-based inference (Lumley 2011). En el primer enfoque, se asume que la población de interés se puede modelar mediante un modelo probabilístico y se pueden obtener estimaciones de los parámetros del modelo mediante técnicas de inferencia estadística. En el segundo enfoque, se asume que la población de interés es finita y se puede obtener estimaciones de los parámetros de la población mediante técnicas de muestreo.\nDentro de este trabajo se mencionara de forma intensiva el concepto de peso o ponderador y su importancia en la estimación de varianzas y errores asociados a las estimaciones. Dentro de la estadística existen diferentes conceptos referidos a ponderadores o pesos, entre ellos (en base (Lumley 2011)):\n\nPesos muestrales: Los pesos muestrales refiere a la cantidad de veces que un individuo de la población de interés está representado en la muestra. Estos pesos muestrales son los que provienen del diseño muestral, ya sea por el inverso de las probabilidades de selección, ajustes por no respuesta, entre otros.\nPesos de precisión: El concepto de precisión puede relacionarse con la variabilidad que tiene una observación sobre la estimación de un parámetro.\nPesos de frecuencia: Refire a la cantidad de veces que aparece un individuo en una muestra y este es resumido para incluir en un único registro.\n\nEs importante hacer esta distinción ya que tomando en cuenta los pesos en cualquiera de sus definiciones o consideraciones, en la mayoría de los casos se puede obtener estimaciones puntuales correctas, sin embargo como se mencionó anteriormente llegar a medidas de incertidumbre como errores estándar, intervalos de confianza totalmente incorrectos.\nUna vez considerado el proceso de inferencia también es crucial tener en cuenta el proceso de transformación de los microdatos a indicadores ya que es importante para interpretar los indicadores de manera correcta y realizar comparaciones a lo largo del tiempo para formalizar la metodología de su construcción. Muchas veces, diferentes usuarios hacen el mismo esfuerzo de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.\nEn los últimos años, el uso de R (R Core Team 2023) ha crecido exponencialmente en la comunidad científica, en especial en el área de la estadística y la ciencia de datos. R es un lenguaje de programación de código abierto ampliamente utilizado en la comunidad científica para el análisis de datos, estadística y aprendizaje automático, y en general se utiliza el concepto paquete para referirse a una colección de funciones, métodos y clases que extienden las funcionalidades de R propuestas por la misma comunidad de usuarios. En este sentido, metasurvey busca ser una herramienta relevante para el trabajo con encuestas por muestreo en general ya sea en las ciencias sociales o el uso genérico para otras disciplinas, buscando solucionar las limitaciones anteriormente mencionadas.\nAntes de continuar es importante definir el concepto de Estadística Computacional y su diferencia con Computación Estadística (Cook 2014), siendo este trabajo un aporte a la Estadística Computacional. La Estadística Computacional se refiere a la implementación de algoritmos y métodos estadísticos en un lenguaje de programación, mientras que la Computación Estadística se refiere a la utilización de herramientas computacionales para resolver problemas estadísticos. En este sentido, R es un lenguaje de programación que permite realizar Estadística Computacional y Computación Estadística, ya que cuenta con una amplia variedad de paquetes que permiten implementar algoritmos y métodos estadísticos y realizar análisis de datos de manera eficiente y reproducible.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#antecedentes-e-implementaciones-similares",
    "href": "chapters/chapter1.html#antecedentes-e-implementaciones-similares",
    "title": "1  Introducción",
    "section": "1.3 Antecedentes e implementaciones similares",
    "text": "1.3 Antecedentes e implementaciones similares\nActualmente existen varios esfuerzos para facilitar el procesamiento de encuestas, entre ellos existen principalmente dos tipos de paquetes, aquellos que implementan la metodología de inferencia en muestreo de poblaciones finitas como puede ser el paquete survey (Lumley 2024), gustave (Chevalier 2023), vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023), weights y aquellos que permiten acceder y manipular encuestas específicas como ech (Detomasi 2020), eph (Kozlowski et al. 2020), tidycensus (Walker y Herman 2024), casen (Vargas 2024) entre otros. Sin embargo, estos últimos tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés, como puede ser el indice de pobreza, tasas del mercado laboral, ingreso salarial, etc. En general, sus implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica. Además en las implementaciones actuales, el usuario cuenta con una función de alto nivel que actúa como una caja negra, donde no se permite modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin tener que leer el código fuente o la documentación adjunta.\nEste tipo de problemas puede verse en ech (Detomasi 2020), donde existen funciones para crear variables de mercado laboral, educación o ingresos, pero estas funciones dependen de la existencia de ciertas variables en la encuesta, cuya estructura puede cambiar de una versión a otra de la encuesta. Sin revisar el cuerpo de la función, no se conoce el proceso de construcción de variables. Algo similar ocurre con eph (Kozlowski et al. 2020), donde se tienen funciones de alto nivel que no permiten modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin inspeccionar a fondo cómo se construyen las funciones del paquete. Esta inspección del código fuente, como consultar el repositorio de GitHub del paquete o revisar la definición de la función, puede ser una tarea tediosa y no garantiza que el usuario pueda entender el proceso de construcción de variables. Esto se debe a que el código puede ser muy extenso o que el usuario no tenga el conocimiento suficiente para entender el código o se empleen ciertos frameworks que el usuario no conozca, como el uso de las librerías dplyr (Wickham et al. 2023) o tidyr (Wickham, Vaughan, y Girlich 2024), muy populares en R para el manejo de datos. También puede ser difícil aislar el proceso de manipulación de la encuesta de la implementación específica de la función para manejar la forma de presentación, estructura del objeto a devolver, etc. Un claro ejemplo de esto puede verse en tidycensus (Walker y Herman 2024), donde existe una función para obtener datos sobre la migración de la comunidad estadounidense, y en la misma implementación se encuentran pasos para mejorar la estructura del conjunto de datos a devolver. En este sentido, el usuario no puede aislar el proceso de re-codificación/construcción de variables sobre variables originales y la obtención de datos geográficos y presentación.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#propuesta",
    "href": "chapters/chapter1.html#propuesta",
    "title": "1  Introducción",
    "section": "1.4 Propuesta",
    "text": "1.4 Propuesta\nPara científicos sociales, es importante tener en cuenta que el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Es de interés obtener información histórica de indicadores y en general es un proceso tedioso y propenso a errores, especialmente si proviene de encuestas donde su estructura y/o forma de preguntar o su codificación puede cambiar con el tiempo. Esto resulta en un proceso extenso y difícil de entender hasta llegar a la construcción de esta serie de indicadores. Muchas veces, diferentes usuarios hacen el mismo proceso de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.\nEn este sentido, es importante que el usuario pueda tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, además de brindar una herramienta común libre de estilos de programación y definiendo con simples pasos el proceso de construcción de variables sintéticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodología rigurosa y fácil de referenciar en la implementación. Es crucial que este proceso sea transparente y entendible para el usuario. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metasurvey y su implementación de recetas para la construcción de indicadores mediante la meta-programación.\nAl trabajar con encuestas por muestreo, es importante tener en cuenta la forma en la que se obtuvieron los datos y su proceso generador para poder realizar inferencias sobre la población de interés. En general, obtener estimaciones puntuales de estadísticos de totales, promedios o proporciones es relativamente sencillo, pero puede ser que se reporte una estimación donde no exista un tamaño de muestra suficiente para obtener una estimación confiable y/o que la variabilidad de la estimación sea alta y no sea recomendable su uso. En este sentido, es importante que el usuario no experto tenga de forma nativa una forma de obtener estimaciones puntuales y sus errores asociados de manera sencilla. Es común utilizar estimaciones puntuales sin tener una medida de incertidumbre o aún peor incluir una estimación del error estándar sin tener en cuenta el diseño muestral correcto, lo que puede llevar a conclusiones erróneas sobre la variabilidad de la estimación. metasurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de forma nativa y con estos resultados hacer recomendaciones sobre la utilidad y confianza de la estimación mediante coeficientes de variación, intervalos de confianza, tamaño de muestra efectivo, entre otros sin tener que ser un experto en metodología de estimación de varianzas y remuestreo. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metasurvey y su implementación de estimaciones puntuales y sus errores asociados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#desarrollo-del-paquete-metasurvey",
    "href": "chapters/chapter1.html#desarrollo-del-paquete-metasurvey",
    "title": "1  Introducción",
    "section": "1.5 Desarrollo del paquete metasurvey",
    "text": "1.5 Desarrollo del paquete metasurvey\nEl desarrollo de un paquete en R es un proceso que requiere contar con una idea bien formada y los medios para llevarla a cabo es por esto que es importante contar con una metodología de trabajo ordenada, heredada del desarrollo de software convencional ya que para la publicación y difusión del paquete se tiene que cumplir con ciertos estándares de calidad y documentación para que otros usuarios puedan utilizarlo. En este sentido, es importante tener en cuenta que el desarrollo de un paquete en R puede llevar tiempo y esfuerzo, a consecuencia de esto, en el documento se presentarán diferentes conceptos sobre metodología para el desarrollo de paquetes en R y se abordaran ejemplos con la implementación de metasurvey.\nEn este sentido, metasurvey pretende ser una herramienta relevante para el trabajo con encuestas por muestreo en general ya sea en las ciencias sociales o el uso genérico para otras disciplinas, buscando solucionar las limitaciones anteriormente mencionadas. Todo el proceso de transformación de los microdatos a indicadores se realiza a través de una serie de funciones que permiten al usuario tener un control total y transparente sobre el proceso de transformación de los microdatos a indicadores. Además, metasurvey permite que el usuario pueda realizar el proceso de transformación de los microdatos a indicadores de manera reproducible y transparente. El usuario puede compartir el código de una forma entendible, casi como un “recetario de cocina”. El procedimiento aplicado a los datos utilizados para obtener los indicadores se realiza mediante lo que denominamos steps y recipes, conformando así una especie de camino transparente para la construcción de indicadores. Esto permite compartir en forma visual un DAG (Directed Acyclic Graph) que permite visualizar el proceso de construcción de indicadores sin tener que abrir un script de R. En complemento al proceso de creación de variables, metasurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de manera sencilla y brindar recomendaciones sobre la utilidad de la estimación en el caso de que se cuente con una variabilidad alta en la estimación, en base a recomendaciones a su coeficiente de variación o métricas similares.\nEl enfoque que permite la flexibilidad a la hora de construir los indicadores es la meta-programación. La meta-programación es un paradigma de programación que permite que un programa pueda modificar su estructura interna en tiempo de ejecución. En R, la meta-programación se realiza a través de las funciones eval, parse, substitute, do.call y quote, que permiten evaluar y parsear código de manera dinámica. En este sentido, metasurvey utiliza la meta-programación para permitir que el usuario pueda modificar el código que se utiliza para transformar los microdatos a indicadores, teniendo funciones de alto nivel similares a las que se utilizan en el paquete recipes de la librería tidymodels (Kuhn, Wickham, y Hvitfeldt 2024).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#esquema-del-documento",
    "href": "chapters/chapter1.html#esquema-del-documento",
    "title": "1  Introducción",
    "section": "1.6 Esquema del documento",
    "text": "1.6 Esquema del documento\nEl documento se estructura de la siguiente manera: en el siguiente capítulo se presentará un marco conceptual básico sobre el muestreo de poblaciones finitas, diferentes paradigmas de programación como puede ser la programación orientada a objetos, programación funcional y la meta-programación y como se utilizan en el desarrollo del paquete. Luego, se ahondará en antecedentes previos tanto en la parte de metodología de estimación de varianzas y paquetes e ideas similares donde se basa el desarrollo del paquete. Finalmente, se presentarán ejemplos de cómo utilizar el paquete metasurvey para construir indicadores de mercado laboral a partir de los microdatos de la ECH y para mostrar su flexibilidad, se incluirá un ejemplo con la EPH.\nEste documento puede leerse en su formato de pagina web o en su formato de documento PDF. Tanto el código fuente del paquete se encuentran disponibles de forma pública en el repositorio de Github y el código fuente de este documento se encuentra disponible en el repositorio. Para la realización de este documento se utilizó quarto (Publishing 2024) para la generación de documentos dinámicos que permiten escribir texto junto con código R.\nPara finalizar, es importante mencionar que el paquete metasurvey es un proyecto en desarrollo y se encuentra en una etapa temprana de desarrollo, por lo que se espera que en el futuro se realicen mejoras y se agreguen nuevas funcionalidades, por lo que se invita a la comunidad a colaborar en el desarrollo del paquete a través de la creación de issues en el repositorio de GitHub o mediante pull requests con mejoras o nuevas funcionalidades.\nPara poder continuar con el documento, se recomienda instalar metasurvey en su versión de desarrollo, para ello se puede ejecutar el siguiente Código 1.1\n\n\n\nCódigo 1.1: Instalación de metasurvey\n\n\n\n\nbranch &lt;- \"develop\"\n\nis_available &lt;- \"metasurvey\" %in% rownames(\n  available.packages(\n    repos = \"https://cloud.r-project.org/\"\n  )\n)\n\nif (is_available) {\n  install.packages(\"metasurvey\")\n} else {\n  remotes::install_github(\n    \"metasurveyr/metasurvey\",\n    ref = branch,\n    force = TRUE\n  )\n  message(\"Se instalo la versión de desarrollo de metasurvey\")\n}\n\n\n\n\n\n\n\n\nBreidaks, Juris, Martins Liberts, y Santa Ivanova. 2020. vardpoor: Estimation of indicators on social exclusion and poverty and its linearization, variance estimation. Riga, Latvia: Central Statistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChevalier, Martin. 2023. gustave: A User-Oriented Statistical Toolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCook, Di. 2014. «Statistical Computing Research |». http://dicook.org/2014/10/05/content/post/2014-10-5-statistical-computing/.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. «ech: Caja de herramientas para procesar la Encuesta Continua de Hogares». https://github.com/calcita/ech.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, y Natsumi Shokida. 2020. eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, y Emil Hvitfeldt. 2024. recipes: Preprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLumley, Thomas. 2011. Complex Surveys: A Guide to Analysis Using R. John Wiley & Sons.\n\n\n———. 2024. «survey: analysis of complex survey samples».\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nSchneider, Benjamin. 2023. «svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights». https://CRAN.R-project.org/package=svrep.\n\n\nVargas, Mauricio. 2024. casen: Metodos De Estimacion Con Disenio Probabilistico y Estratificado en Encuesta CASEN (Estimation Methods with Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, y Matt Herman. 2024. tidycensus: Load US Census Boundary and Attribute Data as ’tidyverse’ and ’sf’-Ready Data Frames. https://walker-data.com/tidycensus/.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, y Davis Vaughan. 2023. dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org.\n\n\nWickham, Hadley, Davis Vaughan, y Maximilian Girlich. 2024. tidyr: Tidy Messy Data. https://tidyr.tidyverse.org.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html",
    "href": "chapters/chapter2.html",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1 Inferencia en muestreo de poblaciones finitas\nComo fue mencionado anteriormente las encuestas por muestreo son la principal fuente de información para la construcción de indicadores socio-demográficos y económicos, en este sentido, es importante tener en cuenta un marco teórico para realizar estas inferencias. Es sumamente sencillo obtener estimaciones puntuales de un determinado estadístico aunque es importante considerar la variabilidad de los estimadores, tanto para poder realizar un proceso de inferencia completo así como también para poder cuantificar la confiabilidad de la estimación.\nA continuación, se definen los conceptos básicos de inferencia en muestreo de poblaciones finitas como son el diseño muestral, probabilidades de inclusión basadas en el diseño, estimadores de Horvitz-Thompson HT, ponderación, medidas de incertidumbre y errores estándar basados en (Särndal, Swensson, y Wretman 2003).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "href": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1.1 Diseño muestral\nEl concepto de diseño muestral refiere al mecanismo mediante el cual se selecciona una muestra e inducen propiedades estadísticas claves como puede ser la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. En diseños sencillos es posible calcular la función de diseño o encontrar una expresión analítica con facilidad mientras que en diseños mas complejos como pueden ser los multietapicos es necesario abordar el problema de otra forma y asumir ciertas hipótesis para poder construir probabilidades de inclusión tanto de primer orden como segundo orden el cual sera abordado en la sección 2.1.2\nLa definición matemática se basa en que dado un universo \\(U\\) de \\(N\\) elementos (puede ser conocido o no) \\(\\{u_{1},u_{2}, \\cdots, u_{N}\\}\\) y se considera un conjunto de tamaño \\(n\\) de elementos de \\(U\\) que se denota como \\(s = \\{u_{1},u_{2}, \\cdots, u_{n}\\}\\) al cual comúnmente denominamos muestra, el diseño muestral puede definirse de la siguiente forma:\n\\[\nPr(S = s) = p(s)\n\\]\nRealizando un poco de inspección en la definición anterior se puede observar que el diseño muestral es una función de probabilidad que asigna una probabilidad a cada subconjunto de \\(U\\) de tamaño \\(n\\). En este sentido, es posible definir diferentes tipos de diseño, entre ellos los mas comunes:.\n\nDiseño Aleatorio Simple (SI)\n\nEl diseño aleatorio simple es el diseño más sencillo y se define de la siguiente forma:\n\\[\np(s) = \\frac{1}{\\binom{N}{n}}\n\\]\nDonde \\(\\binom{N}{n}\\) es el número de subconjuntos posibles de \\(U\\) de tamaño \\(n\\).\n\nDiseño Bernoulli (BE)\n\nEl (BE) es un diseño sencillo que se utiliza cuando se desea seleccionar una muestra de un universo de tamaño \\(N\\) además de considerar una una probabilidad de inclusión \\(\\pi\\) para cada elemento de \\(U\\). Se define el diseño Bernoulli de la siguiente forma:\n\\[\np(s) = \\underbrace{\\pi \\times \\pi \\times \\cdots \\times \\pi}_{n_{s}} \\times \\underbrace{(1-\\pi) \\times (1-\\pi) \\times \\cdots \\times (1-\\pi)}_{N-n_{s}} = \\pi ^{n_{s}} (1-\\pi)^{N-n_{s}}\n\\]\nUna diferencia fundamental entre el diseño (BE) y el diseño SI es que en el BE el tamaño de muestra es aleatorio y su distribución es binomial, mientras que en el diseño SI el tamaño de muestra es fijo.\n\nDiseño Estratificado (ST)\n\nEl diseño estratificado es un diseño que se utiliza cuando se desea seleccionar una muestra de tamaño \\(n\\) de un universo de tamaño \\(N\\) donde además se quiere dividir el universo en \\(H\\) estratos \\(U_{1}, U_{2}, \\cdots, U_{H}\\). Dentro de cada estrato se selecciona una muestra de tamaño \\(n_{h}\\) y se define el diseño estratificado de la siguiente forma:\n\\[\np(s) = \\prod_{l=1}^{H} p(s_{H})\n\\]\nEn cada estrato se puede utilizar un diseño diferente pero en general se utiliza el diseño SI, mas conocido STSI (Stratified Simple Random Sampling). En este caso cada \\(p_{h}(s_{h})\\) es el diseño aleatorio simple en el estrato \\(h\\).\n\n\n2.1.2 Probabilidades de inclusión y estimador de Horvitz-Thompson\nUna vez definido el concepto de diseño muestral es posible definir la probabilidad de que un elemento de la población sea seleccionado en la muestra, esta probabilidad se conoce como probabilidad de inclusión y se define de la siguiente forma:\n\nProbabilidad de inclusión de primer orden\n\n\\[\n\\pi_{k} = Pr(u_{k} \\in s) = Pr(I_{k} = 1)\n\\]\nDonde \\(I_{k}\\) es una variable aleatoria que toma el valor de 1 si el elemento \\(u_{k}\\) es seleccionado en la muestra y 0 en caso contrario. Definir estas variables indicadoras son de utilizada para entender el comportamiento de los estimadores bajo el diseño muestral y nos permite definir los estimadores en \\(U\\) y no en \\(S\\). Es claro que \\(I_{k} \\sim Bernoulli(\\pi_{k})\\) y \\(E(I_{k}) = Pr(I_{k}) = \\pi_{k}\\).\nEsta probabilidad es importante ya que es la la base para la construcción de estimadores insesgados y eficientes, en este sentido, es posible definir el estimador de Horvitz-Thompson (HT) para estimar un total \\(t = \\sum_{U} {t_{k}}\\) de la siguiente forma:\n\\[\n\\hat{t}_{y} = \\sum_{k=1}^{N} \\frac{y_{k}}{\\pi_{k}} \\times I_{k}\n\\]\nEste estimador es propuesto por Horvitz y Thompson en 1952 y es un estimador insesgado en el diseño, en el sentido de que \\(E(\\hat{t}_{y}) = t\\) y es eficiente en el sentido de que \\(Var(\\hat{t}_{y})\\) es el menor posible entre los estimadores insesgados. Este estimador es muy utilizado en la práctica y es la base para la construcción de otros estadísticos,como medias, proporciones, varianzas, entre otros. Para mas detalles sobre las propiedades de Horvitz-Thompson (HT) se puede consultar en (Särndal, Swensson, y Wretman 2003) y (Horvitz y Thompson 1952).\n\n\n2.1.3 Ponderación basada en el diseño y estimadores más comunes\nEn general es utilizado el concepto de ponderador para realizar estimaciones de totales, medias, proporciones, varianzas, entre otros. En este sentido, es posible definir el ponderador inducido por el diseño muestral de la siguiente forma:\n\\[\nw_{k} = \\frac{1}{\\pi_{k}}\n\\]\nEste ponderador puede interpretarse como el número individuos que representa el individuo \\(k\\) en la población. Este valor es el que comúnmente se publica junto a los microdatos y el estándar en los diferentes softwares para procesar encuestas. Junto al estimador de un total es posible definir el estimador de un promedio, proporción o razón en el contexto de la $-expansión.\n\nEstimador de un promedio\n\\[\n\\hat{\\bar{y}} = \\frac{\\sum_{k=1}^{N} w_{k} I_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}}\n\\]\nEste estimador puede ser utilizados en encuestas de hogares, donde se desea estimar el ingreso promedio de los hogares de una región de forma anual, o mensual.\n\n\nEstimador de una proporción\n\\[\n\\hat{p} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\hat{N}}\n\\]\nPuede ser de interés estimar la proporción de hogares que tienen acceso a internet en una región, en este caso se puede utilizar el estimador de proporción.\n\n\nEstimador de una razón\nSe quiere estimar la razón \\(R = \\frac{\\sum_{k=1}^{N} y_{k}}{\\sum_{k=1}^{N} z_{k}}\\). En este caso se puede definir el estimador de la razón de la siguiente forma:\n\\[\n\\hat{R} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k}z_{k}} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\hat{N}}\n\\]\nEl estimador de razón es utilizado para construir variables de mercado de trabajo como la tasa de desempleo, tasa de ocupación, entre otros.\n\n\nInferencia sobre el tamaño de la población\nUna vez definidos los estimadores, podemos ver que los estimadores de medias y proporciones son un caso particular del estimador de razón. Un detalle no menor es que asumimos \\(N\\) fijo pero desconocido, por esto al realizar proporciones se ajusta el total sobre un estimador del tamaño de la población:\n\\[\n\\hat{N} = \\sum_{k=1}^{N} I_{k}w_{k}\n\\]\nExisten diseños denominados auto-ponderados donde por definición \\(\\sum_{k=1}^{N} w_{k} = N\\), en este caso particular el estimador de medidas y proporciones es un caso particular del estimador de total, ya que el estadístico puede definirse de la siguiente forma:\n\\[\n\\hat{\\bar{y}}_{s} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{N} = \\frac{1}{N} \\times \\sum_{k=1}^{N} I_{k} w_{k} y_{k} = a \\times \\hat{t}_{y}\n\\]\n\n\n\n2.1.4 Medidas de incertidumbre y errores estándar\nSe puede medir la variabilidad de los estimadores y calcular su varianza. Esto es útil para entender cuán confiables son estos estimadores. Veamos cómo se calcula la varianza de diferentes tipos de estimadores, como el total, promedio, proporción o razón.\n\n2.1.4.1 Momentos muéstrales y estimadores de varianza\nPara un estadístico \\(\\theta\\), su varianza bajo un diseño muestral \\(p(s)\\) se define como:\n\\[\nV(\\hat{\\theta}) = E((\\theta - E(\\hat{\\theta}))^{2}) = \\sum_{s \\in S}{p(s)\\left(\\hat{\\theta}_{s} - E(\\hat{\\theta}_{s})\\right)}\n\\]\nLa forma de calcular la varianza depende del estimador \\(\\hat{\\theta}\\). Por ejemplo, para el estimador de varianza de un total, se utiliza la siguiente fórmula:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k} \\times y_{k} \\times w_{k})} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k} \\times y_{k} \\times w_{k}, I_{l} \\times y_{l} \\times w_{l})}}\n\\]\nDespués de simplificar, obtenemos:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k}) \\times w_{k} \\times y_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k}, I_{l}) \\times y_{k} \\times w_{k} \\times y_{l}  \\times w_{l} }}\n\\]\nDonde definimos las siguientes identidades para simplificar cálculos:\n\\[\nCov(I_{k}, I_{l}) = \\Delta_{kl} = \\pi_{kl} - \\pi_{k} \\times \\pi_{l}\n\\]\n\\[\n\\check{y}_{k} = y_{k} \\times w_{k}\n\\]\n\\[\n\\check{\\Delta}_{kl} = \\Delta_{kl} \\times \\frac{1}{\\pi_{kl}} = \\Delta_{kl} \\times w_{kl}\n\\]\nUna vez definida la varianza del estimador, necesitamos estimar su varianza. Para esto, utilizamos la técnica de \\(\\pi\\)-expansión. Después de algunas manipulaciones algebraicas, obtenemos la varianza del estimador:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{\\check{y}_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} } = \\sum_{U}{\\sum{\\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }}\n\\]\nPodemos verificar que este estimador de varianza es insesgado con la definiciones de \\(E(I_{k}I_{l})\\) y tomando esperanzas. Es decir, se verifica que \\(E(\\hat{V}(\\hat{t}_{y})) = V(\\hat{t}_{y})\\). Al ser un estimador insesgado, su eficiencia depende del diseño muestral y de la varianza de los ponderadores, es decir, de la varianza de las probabilidades de inclusión. En algunos casos es donde entra en juego dividir grupos heterogéneos en estratos o realizar muestreos en varias etapas.\nPara el caso de un estimador de un promedio, la varianza se define de la siguiente forma: \\[\nV(\\hat{\\bar{y}}) = \\frac{1}{N^{2}} \\times \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }\n\\]\nEsto es válido en el caso de contar con un tamaño de población conocido, en otro caso el estimador de la media no es un estimador lineal y para calcular su varianza deben optar por métodos de estimación de varianzas más complejos como el de linealización de Taylor.\nEs importante considerar que en esta sección se presenta un caso ideal donde la muestra es obtenida de un listado perfecto de la población objetivo denominado marco de muestreo. En la práctica, el marco de muestreo es imperfecto y se debe considerar la no respuesta, la cobertura y la falta de actualización del marco de muestreo. En general para la publicación de microdatos se publican ciertos ponderadores que no son precisamente los ponderadores originales definidos en la sección anterior sino que son sometidos a un proceso de calibración donde se intenta ajustar a ciertas variables de control y mejorar problemas causados por la no respuesta. Al realizar el proceso de calibración los ponderadores calibrados son lo mas cercano posible a los ponderadores originales, de forma que si los ponderadores originales son insesgados, los ponderadores calibrados serán próximos a ser insesgados.\nEn la practica para diseños complejos no se dispone de las probabilidades de selección de segundo orden insumo principal para calcular los errores estándar, por esto es que se requiere optar con metodologías alternativas como el método del ultimo conglomerado, método de replicación jackknife, método de bootstrap, entre otros. En este sentido, es importante tener en cuenta que la varianza de los estimadores es un componente fundamental para realizar inferencias y cuantificar la confiabilidad de los resultados.\nEn resumen, para realizar estimaciones puntuales ya sean totales, medias, proporciones o razones, simplemente debemos ponderar los datos con los estadísticos anteriormente mencionadas pero para realizar un proceso de inferencia completo se requiere calcular sus errores estándar, construir intervalos de confianza y/o poder medir estabilidad de nuestros resultados. En este sentido, es importante tener al alcance herramientas que permitan realizar este tipo de cálculos, ya que si bien en diferentes softwares estadísticos junto a la estimación puntual se presentan los errores estándar aunque por defecto se asumen diseños sencillos como por ejemplo, el diseño BE donde la probabilidad de inclusión de segundo orden es sencilla de calcular y unicamente es necesario las probabilidades de inclusión de primer orden para computar estimadores del error estándar, siendo un valor completamente erróneo.\nUna vez presentado conceptos básicos de muestreo es importante entender como esto estará disponible en el paquete metasurvey, en este sentido, se presentarán los conceptos básicos de programación funcional y orientada a objetos en R para luego enfocarnos en la meta-programación.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#sec-developmentR",
    "href": "chapters/chapter2.html#sec-developmentR",
    "title": "2  Marco conceptual",
    "section": "2.2 Desarrollo de paquetes en R",
    "text": "2.2 Desarrollo de paquetes en R\nR es un lenguaje de código abierto y además cuenta con una gran comunidad de usuarios, en diferentes áreas de investigación, esto ha permitido que se desarrollen una gran cantidad de paquetes que permiten realizar diferentes tareas de análisis de datos, visualización, bioinformática, aprendizaje automático y ramas afines a la estadística. Dentro de la comunidad existen diferentes organizaciones que se encargan de mantener la calidad de los paquetes y de asegurar que los paquetes cumplan con ciertos estándares de calidad, una de estas organizaciones es el Comprehensive R Archive Network (CRAN), que es un repositorio de paquetes de R que contiene versiones estables de los paquetes de R, bioconductor, que es un repositorio de paquetes de R que contiene paquetes para el análisis de datos biológicos, y rOpenSci que Para casi cualquier disciplina científica o en la industria se puede encontrar una comunidad de usuarios que desarrollan paquetes en R, en este sentido, el desarrollo de paquetes en R es una tarea que se ha vuelto muy común entre los usuarios de R y es muy sencillo de realizar. A continuación, se presentan los conceptos básicos para el desarrollo de paquetes en R.\n\n2.2.1 ¿Por qué desarrollar un paquete en R?\nDesarrollar un paquete en R tiene varias ventajas, entre las cuales se pueden mencionar las siguientes:\n\nReutilización de código: Es importante tener en cuenta que existe una comunidad que hace cosas similares a las que uno hace, por lo que es posible que alguien ya haya escrito una función que uno necesita. Por lo tanto, siempre es buena buscar si existe algún paquete que ya tenga las funcionalidades que se requieren.\nCompartir código: La comunidad de R es muy activa y siempre está dispuesta a compartir código, por esta razón es que se mantienen en constante desarrollo de paquetes.\nColaboración: El trabajo colaborativo es esencial en el desarrollo de paquetes en R, ya que permite que diferentes personas puedan aportar con nuevas funcionalidades, correcciones de errores, entre otros.\n\n\n\n2.2.2 Elementos básicos de un paquete en R\nPara que nuestro conjunto de funciones, datos y documentación sea considerado un paquete en R, es necesario que cumpla con ciertos requisitos mínimos. A continuación, se presentan los componentes mínimos que debe tener un paquete en R para ser publicado en CRAN.\n\nDirectorio: Un paquete en R debe estar contenido en un directorio que contenga al menos los siguientes archivos y directorios:\n\nR/: Directorio que contiene los archivos con las funciones que se desean incluir en el paquete.\nman/: Directorio que contiene los archivos con la documentación de las funciones que se encuentran en el directorio R/. En general se utiliza Roxygen2 (Wickham et al. 2024) para generar la documentación de las funciones.\nDESCRIPTION: Archivo que contiene la descripción del paquete, incluyendo el nombre, versión, descripción, autor, entre otros.\nNAMESPACE: Archivo que contiene la información sobre las funciones que se exportan y las dependencias del paquete.\nLICENSE: Archivo que contiene la licencia bajo la cual se distribuye el paquete.\nREADME.md: Archivo que contiene información general sobre el paquete.\n\nDocumentación: La documentación de las funciones es un componente esencial de un paquete en R, ya que permite que los usuarios puedan entender el funcionamiento de las funciones que se encuentran en el paquete. La documentación de las funciones se realiza utilizando el sistema de documentación de R, que se basa en el uso de comentarios en el código fuente de las funciones.\nPruebas: Es importante que el paquete tenga pruebas que permitan verificar que las funciones se comportan de la manera esperada. Las pruebas se realizan utilizando el paquete testthat (Wickham 2011) que permite realizar pruebas unitarias.\nControl de versiones: Es importante que el paquete tenga un sistema de control de versiones que permita llevar un registro de los cambios que se realizan en el paquete. El sistema de control de versiones más utilizado en la comunidad de R es git.\nLicencia: Es importante que el paquete tenga una licencia que permita a los usuarios utilizar, modificar y distribuir el paquete. La licencia más utilizada en la comunidad de R es la licencia MIT.\n\nEl proceso de subir un paquete a CRAN es un proceso que puede ser tedioso, ya que se deben cumplir con ciertos requisitos que son revisados por los mantenedores de CRAN, no es trivial y puede tomar tiempo, sin embargo, es un proceso que vale la pena ya que permite que el paquete sea utilizado por una gran cantidad de usuarios.\nEl proceso de chequeo fue automatizado con GitHub actions, por lo que cada vez que se realiza un cambio en el repositorio, se ejecutan los chequeos de CRAN y se notifica si el paquete cumple con los requisitos para ser publicado en caso de que no cumpla con los requisitos se notifica el error y no puede ser incluido en la rama principal del repositorio hasta que se corrija el error.\nTodo el proceso y código fuente del paquete se encuentra disponible en el repositorio de github del paquete. En el caso que este interesado en colaborar con el desarrollo del paquete puede consultar la guía de contribución.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "href": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "title": "2  Marco conceptual",
    "section": "2.3 Paradigmas de programación en R",
    "text": "2.3 Paradigmas de programación en R\nR es un lenguaje de programación que permite realizar programación funcional y orientada a objetos (Chambers 2014), lo que permite que los usuarios puedan utilizar diferentes paradigmas de programación para resolver problemas. A continuación, se presentan los conceptos básicos de la programación funcional y orientada a objetos en R.\n\n2.3.1 Programación funcional\nLa programación funcional es un paradigma de programación que se basa en el uso de funciones para resolver problemas. En R, las funciones son objetos de primera clase, lo que significa que se pueden utilizar como argumentos de otras funciones, se pueden asignar a variables, entre otros (Wickham 2019, 204-81). A continuación, se presentan los conceptos básicos de la programación funcional en R.\n\nFunciones de orden superior: En R, las funciones de orden superior son funciones que toman como argumento una o más funciones y/o retornan una función. Un ejemplo de una función de orden superior en R es la función lapply que toma como argumento una lista y una función y retorna una lista con los resultados de aplicar la función a cada elemento de la lista.\nFunciones anónimas: En R, las funciones anónimas son funciones que no tienen nombre y se crean utilizando la función function. Un ejemplo de una función anónima en R es la función function(x) x^2 que toma como argumento x y retorna x^2.\nFunciones puras: En R, las funciones puras son funciones que no tienen efectos secundarios y retornan el mismo resultado para los mismos argumentos. Un ejemplo de una función pura en R es la función sqrt que toma como argumento un número y retorna la raíz cuadrada de ese número.\n\nEste paradigma de programación es muy útil para realizar análisis de datos, ya que permite que los usuarios puedan utilizar funciones para realizar operaciones sobre los datos de manera sencilla y eficiente, dentro de metasurvey no existe una presencia fuerte de programación funcional, sin embargo, se utilizan algunas funciones de orden superior para realizar operaciones sobre los datos.\n\n\n2.3.2 Programación orientada a objetos\nLa programación orientada a objetos es un paradigma de programación que se basa en el uso de objetos para resolver problemas. En R, los objetos son instancias de clases que tienen atributos y métodos (Wickham 2019, 285-370; Mailund 2017). A continuación, se presentan los conceptos básicos de la programación orientada a objetos en R.\n\nClases y objetos: En R, las clases son plantillas que definen la estructura y el comportamiento de los objetos y los objetos son instancias de clases. En R, las clases mas utilizadas provienen del sistema de programación orientada a objetos llamado S3 las definen utilizando la función setClass y los objetos se crean utilizando la función new. También se pueden utilizar las clases del sistema S4 aunque este tiene una sintaxis mas compleja y no es tan utilizado.\nAtributos y métodos: En R, los atributos son variables que almacenan información sobre el estado de un objeto y los métodos son funciones que permiten modificar el estado de un objeto. En R, los atributos se definen utilizando la función setClass y los métodos se definen utilizando la función setMethod.\n\nDentro de metasurvey se utiliza la programación orientada a objetos para definir las clases de los objetos que se utilizan para representar los datos de las encuestas mediante una creación de una clase especifica llamada Survey que permite además de almacenar los datos de la encuesta añadir atributos y métodos que permiten realizar operaciones sobre los datos de manera sencilla y eficiente.\nDe forma similar se modelan las clases Step, Recipe y Survey, entre otras, elementos cruciales en el ecosistema de metasurvey donde se definen los pasos de preprocesamiento, recetas de preprocesamiento y flujos de trabajo respectivamente. En este caso particular se utiliza el paquete R6 (Chang 2022) que permite definir clases de manera intuitiva y eficiente además de permitir la herencia de clases y la definición de métodos y atributos de manera sencilla.\n\n\n2.3.3 Meta-programación\nLa meta-programación es un paradigma de programación que se basa en el uso de código para manipular código (Wickham 2019, 373-500; Thomas Mailund 2017) . En R, la meta-programación se realiza utilizando el sistema de meta-programación de R que se basa en el uso de expresiones, llamadas y funciones. A continuación, se presentan los conceptos básicos de la meta-programación en R.\n\nExpresiones: En R, las expresiones son objetos que representan código y se crean utilizando la función quote. Un ejemplo de una expresión en R es la expresión quote(x + y) que representa el código x + y.\nLlamadas: En R, las llamadas son objetos que representan la aplicación de una función a sus argumentos y se crean utilizando la función call. Un ejemplo de una llamada en R es la llamada call(\"sum\", 1, 2, 3) que representa la aplicación de la función sum a los argumentos 1, 2 y 3.\nFunciones: En R, las funciones son objetos que representan código y se crean utilizando la función function. Un ejemplo de una función en R es la función function(x, y) x + y que representa el código x + y.\n\nEn metasurvey se utiliza la meta-programación para generar código de manera dinámica y realizar operaciones sobre los datos de manera eficiente. En particular se utiliza la función eval para evaluar expresiones y la función substitute para reemplazar variables en expresiones. Además, se utilizan las funciones lapply, sapply, mapply y do.call para aplicar funciones a listas y vectores de manera eficiente. En general, la meta-programación es una técnica muy útil para realizar operaciones sobre los datos de manera eficiente y sencilla.\nEn el capítulo 3 se presentarán los antecedentes de metodologías de estimación de varianzas, revisión de medidas de incertidumbre, paquetes similares y mejoras que son incorporadas en el paquete metasurvey. En el capítulo 4 se hablara sobre la implementación de las diferentes partes que conforman el paquete, una breve reseña del esquema de test, la API para almacenar las recetas junto a su interacción con el usuario. Posteriormente se mostrara un ejemplo de uso del paquete y se presentarán las conclusiones y trabajos futuros.\n\n\n\n\nChambers, John M. 2014. «Object-Oriented Programming, Functional Programming and R». Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nHorvitz, D. G., y D. J. Thompson. 1952. «A Generalization of Sampling Without Replacement From a Finite Universe». Journal of the American Statistical Association 47 (260): 663-85. https://doi.org/10.2307/2280784.\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in R: Statistical Programming for Data Science, Analysis and Finance. SPRINGER.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nThomas Mailund. 2017. Metaprogramming in R. 1.ª ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nWickham, Hadley. 2011. «testthat: Get Started with Testing». The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced R, Second Edition. CRC Press.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, y Manuel Eugster. 2024. roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html",
    "href": "chapters/chapter3.html",
    "title": "3  Marco teórico",
    "section": "",
    "text": "3.1 Investigación reproducible\nEl concepto de investigación reproducible ha cobrado relevancia en los últimos años, tanto en la academia como en la industria y esto se debe a la fricción que puede llegar a existir al momento de presentar resultados de investigación o generación indicadores relevantes para la toma de decisiones debido al proceso de generación de los mismos. Dentro de las diferentes disciplinas generar ambientes de trabajo reproducibles puede llegar a ser un desafío, ya que en la mayoría de los casos se utilizan diferentes herramientas, lenguajes de programación y bases de datos.\nEn la actualidad existen diferentes revistas científicas que promueven la investigación reproducible, herramientas, guías para buenas prácticas para trabajar con datos y código fuente como Sumatra (Davison y Huth 2012), implementaciones de programación literal (Knuth 1984) como RMarkdown (Allaire et al. 2024) o Jupyter Notebook (Kluyver et al. 2024) y diferentes implementaciones para gestionar dependencias de software como Anaconda (Anaconda 2024), aunque algunas de ellas se han vuelto herramientas de pago o ya no existen en la actualidad, mas referencias y casos de uso pueden encontrarse en (Stodden, Leisch, y Peng 2014).\nAntes de continuar es necesario definir conceptos fundamentales en el ámbito de la investigación reproducible, tales como la Reproducibilidad que refiere a la capacidad de poder repetir los resultados de un estudio, experimento o la obtención de un indicador. Si bien la reproducibilidad es considerada en un artículo de investigación científica al utilizar indicadores tanto en contextos académicos como en aplicaciones de monitoreo o divulgación de información, rara vez se documenta o se menciona de que manera se generó ese resultado haciendo referencia únicamente a los datos y rara vez al código fuente. Aún compartiendo el código fuente, esto aún no suficiente para poder reproducir un estudio o un indicador por incompatibilidades de versiones de software, cambios en la estructura de los datos interpretaciones de los datos, estilos de programación, entre otros pudiendo llevar mucho tiempo y esfuerzo para poder replicar un resultado.\nEl proceso de tratamiento de datos y limpieza forma parte de lo que se conoce como publicaciones grises (Vilhuber 2020). Este concepto se refiere a la publicación de datos, código y reportes que no son publicaciones formales, pero son esenciales para generar conocimiento científico. En su mayoría al no tener una revisión por pares o una forma estandarizada esto se incluye de forma muy dispar o sin ningún tipo de documentación para poder ser reproducido y esto forma una gran parte de la investigación científica que no se encuentra aprovechada.\nExisten diversas iniciativas destinadas a fomentar la reproducibilidad en la ciencia, lo que ha llevado a las revistas a establecer políticas de datos y código abierto. Sin embargo, persisten desafíos en la generación de indicadores sociales, ya que como se menciono anteriormente no basta con hacer referencia a los datos, como se señala en (Bechhofer et al. 2013); además de publicar el artículo junto a los datos, es necesario vincular los objetos de investigación (Research Objects RO), existen diferentes plataformas que permiten la publicación de estos objetos como Zenodo y Figshare o OSF que permiten la integración de datos, código e interacción con repositorios con control de versiones como GitHub o GitLab.\nDe conceptos generales sobre reproducibilidad es importante contar con un flujo de trabajo (Workflow managment System (Prabhu y Fox 2020)) para la obtención de estimadores en el procesamiento de encuestas por muestreo ya que el indicador final es el resultado de una serie de pasos que se deben seguir de manera ordenada y documentada para poder ser auditados y replicados en diferentes contextos, inspirado en (Sandve et al. 2013) se pueden considerar algunas buenas prácticas para la generación de indicadores:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#investigación-reproducible",
    "href": "chapters/chapter3.html#investigación-reproducible",
    "title": "3  Marco teórico",
    "section": "",
    "text": "Para cada resultado, se debe tener un respaldo de como fue construido: Al trabajar con lenguajes de programación como R, los script de código fuente son un respaldo de como obtener cierto resultado, sin embargo, esto puede estar ligado a tu estilo de programación y la versión de los paquetes que se utilizan.\nCrear manuales en la manipulación de datos: Es importante resumir cada paso por mas mínimo que sea en la transformación de variables, esto permite entender todo el proceso de generación de un indicador.\nGuardar las versiones de los paquetes utilizados: Al trabajar con R, es importante guardar las versiones de los paquetes que se utilizan, esto permite que en un futuro se pueda replicar el proceso de generación de indicadores, para esto puede utilizarse herramientas como renv (Ushey y Wickham 2023) un paquete que permite crear ambientes locales con versiones especificas de paquetes de R, venv (Python Software Foundation 2024) que son ambientes virtuales en python o Docker (Merkel 2014) para poder emular un ambiente de trabajo en diferentes sistemas operativos.\nGuardar pasos intermedios, en un formato estándar: Al trabajar con encuestas por muestreo y para crear indicadores sencillos se realizan dos grandes tipos de operaciones: crear grupos o categorías o realizar operaciones matemáticas, es importante guardar estos pasos en un formato estándar para poder ser reutilizados en diferentes contextos.\nCompartir las ejecuciones y scripts: Es importante que los scripts de código fuente estén disponibles para que puedan ser auditados y replicados en diferentes contextos.\n\n\n3.1.1 Conceptos clave\nmetasurvey se basa en las buenas prácticas mencionadas anteriormente y permite crear herramientas de flujo de trabajo siguiendo los siguientes principios:\n\nReusable: Se separa el proceso de transformación de variables en Steps que refiere a transformaciones de columnas, estos procedimientos pueden ser comunes tanto en diferentes encuestas como en diferentes indicadores. Estos Steps pueden ser reutilizados en diferentes Recipes para calcular indicadores de mercados de trabajo, pobreza, e incluso aplicarlos en varias encuestas simultáneamente mediante un Workflow.\nRepetible: Al tener un proceso definido en un Workflow, es posible repetir el proceso de generación de indicadores de la misma manera y automatizar la generación de reportes.\nReferenciable y Acreditable: Al contar con un Workflow, es posible hacer referencia al proceso de generación de indicadores indicando todos los pasos seguidos y el autor o equipo que lo realizó. Además, se puede acreditar a los autores de los Steps y Recipes que se utilizaron en el proceso.\n\n\n\n3.1.2 Workflow reproducible\nEl concepto de Workflow no es nuevo y exclusivo en la comunidad científica, en la actualidad en la industria de la ciencia de datos se han desarrollado diferentes herramientas para la gestión de flujos de trabajo para el procesamiento de datos, con diferentes enfoques y objetivos. metasurvey se inspira en diferentes herramientas como Apache AirFlow («Apache Airflow Documentation», s. f.) que es una plataforma de orquestación de flujos de trabajo de código abierto, Great Expectations (Expectations 2024) que es una biblioteca de validación de datos para la generación de reportes de calidad de datos y Make que es una herramienta de automatización de flujos de trabajo que se basa en la definición de reglas y dependencias.\nEn el ámbito del aprendizaje automático existe un gran esfuerzo para poder desgranar y documentar los modelos conocido como Model Cards (Mitchell et al. 2019) donde se hace un detalle de los algoritmos utilizados, las métricas de evaluación, los datos utilizados y su procesamiento, siendo esto el análogo a los Steps y Recipes de metasurvey. Este concepto se ha extendido siendo un estándar en la industria y siendo adoptado por diferentes organizaciones como Google y Hugging Face.\nTomando en cuenta estos conceptos, metasurvey tiene disponible la posibilidad de generar, compartir y visualizar los flujos de trabajo de manera gráfica permitiendo la transparencia y auditabilidad de los procesos de generación de indicadores.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#investigación-reproducible-en-r",
    "href": "chapters/chapter3.html#investigación-reproducible-en-r",
    "title": "3  Marco teórico",
    "section": "3.2 Investigación reproducible en R",
    "text": "3.2 Investigación reproducible en R\nDentro de CRAN existe una guía sobre conjunto de paquetes y herramientas con objetivos comunes denominado Task Views que agrupa paquetes de R que se utilizan para un propósito específico. En el Task View de Reproducible Research se encuentran diferentes paquetes que permiten la generación de reportes dinámicos, la gestión de flujos de trabajo y la generación de documentos interactivos aunque también existen herramientas para la gestión de flujos de trabajo generales como targets (Landau 2021) y drake (Landau 2018), metasurvey fue inspirado en los conceptos y la forma de trabajo de estos paquetes.\nLos conceptos de meta-programación y programación orientada a objetos fue inspirado en el paquete mlr3pipelines (Binder et al. 2021) que permite la creación de flujos de trabajo para el preprocesamiento de datos y la generación de modelos de aprendizaje automático, aquí se definen PipeOps que son operaciones que se pueden aplicar a los datos y se pueden combinar en un Graph que define el flujo de trabajo para ello se definen clases y métodos que permiten una fácil extensión por parte del usuario y la creación de flujos de trabajo complejos.\nDentro de la comunidad existen organizaciones como ROpenSci que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R. Esta organización promueve la creación de paquetes donde además de la guías sobre el desarrollo de paquetes y la revisión de los mismos, se promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación. Para formar parte de ROpenSci, se sigue una evaluación entre pares y una revisión de la calidad del paquete, además de la documentación y la calidad del código complementado con tests automatizados.\n\n3.2.1 Herramientas para el procesamiento de encuestas\nEn el ámbito de las encuestas por muestreo, existen diferentes paquetes que permiten el procesamiento de encuestas por muestreo o la generación de estadísticas oficiales, esto se puede ver en el Task View de Official Statistics & Survey Methodology donde se encuentran diferentes tipos de paquetes desde la preparación de formularios, calibración, análisis de datos, acceso a datos oficiales, entre otros.\nPara el procesamiento de encuestas por muestreo, existe una serie de paquetes que permiten implementar la metodología de encuestas por muestreo como puede ser el caso de survey (Lumley 2024) que permite el análisis de encuestas complejas, srvyr (Ellis y Schneider 2023) aunque estos son utilizados en el proceso final o de inferencia y no en el proceso de la construcción y limpieza de los datos como si lo hace ech (Detomasi 2020) que tiene diferentes funciones para la ECH y permite al usuario crear variables referidas a Vivienda, Educación, Mercado de Trabajo, Ingresos y Pobreza algo similar con eph (Kozlowski et al. 2020) que permite la descarga de datos de la EPH y la creación de variables para analizar la pobreza y el mercado de trabajo.\nEste ultimo grupo de paquetes o caja de herramientas tienen la limitación que no permiten la reutilización de los pasos de limpieza y transformación de los datos de forma sencilla y nativa, además de no poder visualizar el flujo de trabajo de manera gráfica, lo que dificulta la auditoría y la replicabilidad de los procesos de generación indicadores, metasurvey busca llenar este vacío permitiendo la reutilización de los pasos de limpieza y transformación de los datos, la visualización del flujo de trabajo y la generación de reportes de manera sencilla.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#diseño-de-encuestas-y-estimación-de-varianza",
    "href": "chapters/chapter3.html#diseño-de-encuestas-y-estimación-de-varianza",
    "title": "3  Marco teórico",
    "section": "3.3 Diseño de encuestas y estimación de varianza",
    "text": "3.3 Diseño de encuestas y estimación de varianza\nComo fue introducido en el capitulo anterior y en la sección de antecedentes es sencillo obtener estimaciones puntuales, sin embargo, es necesario presentar una medida de precisión de la estimación ya que en algunos casos puede ser que el tamaño de la muestra no sea suficiente para obtener estimaciones precisas. En el caso de las encuestas por muestreo, es necesario tener en cuenta el diseño de la encuesta, la estratificación, la ponderación y el efecto de conglomerados, ya que estos factores influyen en la precisión de la estimación. Para ello, es necesario contar con alguna metodología que permita estimar varianzas ya que para diseños complejos o estadísticos no lineales, la estimación de varianzas no es trivial.\nEn la actualidad, existen diferentes métodos para la estimación de varianzas, aunque en la mayoría de los casos se utilizan métodos de remuestreo como el Boostrap o el Jackknife, sin embargo existen diferentes ideas o propuestas como se menciona en (Deville y Tille 1998) y (Deville y Tillé 2005) que demuestran con resultados numéricos estimadores del tipo H-T bajo un diseño balanceado puede aproximarse desde el enfoque de regresión o calibración. Además existen estimadores alternativos donde complementan métodos de remuestreo para aproximar probabilidades de inclusión de segundo orden (Emilio L. Escobar y Berger 2013) utilizando ciertas aproximaciones límites (Hajek 1964).\nCada metodología depende de cada diseño y variables a estimar, por esto es que existen diferentes metodologías y paquetes como gustave (Chevalier 2023) , vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023) y samplingVarEst (Emilio Lopez Escobar, Zamudio, y Rosas 2023), aunque existen similitudes entre implementaciones y métodos es difícil encontrar una implementación que permita la estimación de varianzas de manera sencilla y que permita la reutilización de los pasos de limpieza y transformación de los datos, esto puede ser complicado para usuarios que no tienen experiencia en el procesamiento de encuestas por muestreo y que buscan una herramienta que les permita realizar este tipo de análisis de manera sencilla y visual.\n\nResumen de las implementaciones\nEn la Tabla 3.1 a continuación se presenta un resumen de las implementaciones de los paquetes mencionados anteriormente:\n\n\n\n\nTabla 3.1: Comparación de paquetes para análisis de encuestas\n\n\n\n\n\n\n\n\n\n\nComo se puede observar en la Tabla 3.1, metasurvey busca llenar el vacío de la reutilización de los pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo, aprovechando como dependencia survey y svrep para la estimación de varianzas y la generación de indicadores sociales, permitiendo la generación de reportes de manera sencilla y visualizar el flujo de trabajo de manera gráfica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#desarrollos-de-paquetes-en-r",
    "href": "chapters/chapter3.html#desarrollos-de-paquetes-en-r",
    "title": "3  Marco teórico",
    "section": "3.4 Desarrollos de paquetes en R",
    "text": "3.4 Desarrollos de paquetes en R\nActualmente R es uno de los lenguajes de programación más utilizados en la comunidad científica y parte de la industria cuando se realizan análisis de datos, esto se debe a la gran comunidad de desarrolladores y la cantidad de paquetes que se encuentran disponibles en CRAN y GitHub. En la actualidad, existen diferentes organizaciones que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R.\nSin embargo cualquier usuario puede desarrollar un paquete en R, aunque existen diferentes guías y estándares para el desarrollo de paquetes en R, como se menciona en («R Packages (2e)», s. f.) , además de la guía de ROpenSci (rOpenSci et al. 2024) que promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación.\nPara el desarrollo de metasurvey se utilizaron paquetes como usethis (Wickham, Bryan, et al. 2024) que permite la creación de paquetes en R, roxygen2 (Wickham, Danenberg, et al. 2024) que permite la documentación de funciones y la creación de manuales, testthat (Wickham 2011) que permite la creación de tests automatizados, pkgdown (Wickham, Hesselberth, et al. 2024) que permite la creación de sitios web para paquetes de R, devtools (Wickham et al. 2022) que permite la instalación y la carga de paquetes en R, renv (Ushey y Wickham 2023) que permite la creación de ambientes locales con versiones especificas de paquetes de R junto a herramientas herramientas como pre-commit (Sottile y Contributors 2024) que permite la ejecución de scripts antes de realizar un commit en un repositorio de git esto con el fin de mantener la calidad del código y la documentación antes de realizar un cambio en el repositorio. De forma conjunta se utilizó GitFlow (Driessen 2010) que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git. Para la automatización de los tests en diferentes sistemas operativos se utilizó GitHub Actions (GitHub Actions: Automate Your Workflow 2024) que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov (Codecov: Code Coverage Insights 2024).\nTodo estas herramientas permiten que la creación de paquetes sea sencilla y permita a los usuarios enfocarse en la implementación con cierto grado de calidad y documentación, además de permitir la colaboración y la integración continua de los cambios en un repositorio de git.\n\nImplementación de tests automatizados\nEl paquete incluye tests automatizados creados con testthat, lo que asegura la robustez del código fuente al ser utilizado en diversos contextos. Un ejemplo es el test de la función extract_time_pattern, que analiza el nombre de una encuesta y retorna su tipo, año y periodicidad. Esta función clave utiliza expresiones regulares para manejar distintos formatos de tiempo y es fundamental para tareas como definir la edición de encuestas o emparejar réplicas bootstrap. Su implementación completa puede encontrarse aquí: extract_time_pattern.\n\n\n\nCódigo 3.1: Ejemplo de un test automatizado para verificar el correcto funcionamiento de la función extract_time_pattern.\n\n\n\n\nCódigo\ntest_that(\n  \"Probar extraer time pattern anual\",\n  {\n    testthat::expect_equal(\n      metasurvey:::extract_time_pattern(\"ECH_2023\"),\n      list(\n        type = \"ECH\",\n        year = 2023,\n        periodicity = \"Annual\"\n      )\n    )\n  }\n)\n\n\n\n\n\nAl tener una serie de test automatizados como el presentado en el Código 3.1 se realice antes de realizar cambios en el código fuente pueda el desarrollador ejecutar los tests y verificar que no existan problemas ante un cambio o una refactorización del código fuente. Para el envió a CRAN se realizan estos test automático y una serie de pruebas de calidad y documentación para que el paquete sea aceptado en CRAN. Actualmente metasurvey no tiene errores, mensajes de advertencia o notas en CRAN, la cobertura del código es baste baja ya que realizar test para todas las funciones es un trabajo arduo y que requiere tiempo, sin embargo en futuras versiones se espera tener una cobertura del código mayor al 80%. La cobertura puede ser verificada en el siguiente enlace: codecov.\n\n\nDocumentación\nPara la documentación se utilizó roxygen2 que permite la documentación de funciones y la creación de manuales, además de pkgdown que permite la creación de sitios web para paquetes de R, esto permite que los usuarios puedan tener una guía de referencia para utilizar el paquete y que los desarrolladores puedan tener una guía de referencia para la implementación de nuevas funciones o la modificación de las existentes.\n\n\n\nCódigo 3.2: Extracto de la documentación de la función load_survey con las etiquetas necesarias para la generación de la documentación.\n\n\n\n\nCódigo\n#' @title Load survey\n#' @param path Path to the survey file\n#' @param svy_type Type of survey\n#' @param svy_edition Edition of the survey\n#' @param svy_weight Weight of the survey\n#' @param svy_psu Primary sampling unit\n#' @param ... Additional arguments\n#' @param bake Logical\n#' @return Survey object\n#' @keywords preprocessing\n#' @export\nload_survey &lt;- function(\n    path = NULL,\n    svy_type = NULL,\n    svy_edition = NULL,\n    svy_weight = NULL,\n    svy_psu = NULL,\n    ..., bake = FALSE) {\n      # Ejemplo no mostrado debido a la extensión del\n      # código puede ser consultado en \n      # el repositorio de GitHub\n}\n\n\n\n\n\nComo se puede observar en el código 3.2, la documentación de las funciones se realiza con comentarios en el código fuente, esto permite que roxygen2 pueda generar la documentación de las funciones y los manuales de manera automática, simplemente hay que añadir comentarios con ciertas etiquetas que dependiendo si la función es exportada o no, es un requisito para la aceptación en CRAN que las funciones que se exporten estén documentadas y que la documentación sea clara y concisa. La documentación puede ser consultada en el siguiente enlace: Documentación de metasurvey o en la ayuda de R con ?load_survey.\n\n\n\nPruebas en diferentes sistemas operativos y versiones de R junto a GitHub Actions\nEn muchos casos, los paquetes de R pueden tener problemas de compatibilidad con diferentes versiones de R o con diferentes sistemas operativos, para evitar estos problemas se utilizó GitHub Actions que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov. En el caso de metasurvey se realizan pruebas en diferentes versiones de R y en diferentes sistemas operativos como Windows, MacOS y Linux, esto permite que el paquete sea compatible con diferentes versiones de R y sistemas operativos.\nTodo esto fue realizado en GitHub Actions donde se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R. En este caso al utilizar GitFlow que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git, se puede tener una rama de desarrollo y una rama de producción, donde en la rama de desarrollo se realizan los cambios y se ejecutan los test y en la rama de producción se realiza la publicación en CRAN. Todo esto permite que el paquete sea robusto y que los cambios sean integrados de manera continua en el repositorio. Para la integración de una nueva versión se realizan pull request que son un pedido de integración de cambios en la rama de desarrollo, esto permite que los cambios sean revisados y auditados antes de ser integrados en la rama principal.\n\n\n\nCódigo 3.3: Archivo de configuración de GitHub Actions para la ejecución de tests en diferentes sistemas operativos y versiones de R.\n\n\n\n\nCódigo\non:\n  push:\n    branches: \n      - main\n      - develop\n  pull_request:\n    branches: [develop]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macos-latest,   r: 'release'}\n          - {os: windows-latest, r: 'release'}\n          - {os: ubuntu-latest,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: ubuntu-latest,   r: 'oldrel-1'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: r-lib/actions/setup-pandoc@v2\n\n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v2\n        with:\n          extra-packages: any::rcmdcheck\n          needs: check\n\n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n\n\n\nComo se puede observar en el código 3.3, se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R, esto es lanzado automáticamente cuando se hace un cambio en la rama de desarrollo o en la rama de producción puede aquí verse el historial y ejemplos del mismo paquete.\nEn capítulos posteriores se presentará la implementación de conceptos de workflows, meta-programación y metodologías de estimación de varianzas en metasurvey para la generación de indicadores sociales.\n\n\n\n\nAllaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey, y Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n«Apache Airflow Documentation». s. f. https://airflow.apache.org/docs/latest/.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John Ainsworth, Jiten Bhagat, Philip Couch, et al. 2013. «Why linked data is not enough for scientists». Future Generation Computer Systems, Special section: Recent advances en e-Science, 29 (2): 599-611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars Kotthoff, y Bernd Bischl. 2021. «mlr3pipelines - Flexible Machine Learning Pipelines in R». Journal of Machine Learning Research 22 (184): 1-7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, y Santa Ivanova. 2020. vardpoor: Estimation of indicators on social exclusion and poverty and its linearization, variance estimation. Riga, Latvia: Central Statistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChevalier, Martin. 2023. gustave: A User-Oriented Statistical Toolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCodecov: Code Coverage Insights. 2024. https://about.codecov.io.\n\n\nDavison, Andrew P, y John E Huth. 2012. «Sumatra: A toolkit for reproducible research». arXiv preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. «ech: Caja de herramientas para procesar la Encuesta Continua de Hogares». https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, y Yves Tille. 1998. «Unequal Probability Sampling Without Replacement Through a Splitting Method». Biometrika 85 (1): 89-101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, y Yves Tillé. 2005. «Variance approximation under balanced sampling». Journal of Statistical Planning and Inference 128 (2): 569-91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nDriessen, Vincent. 2010. «A Successful Git Branching Model». https://nvie.com/posts/a-successful-git-branching-model/.\n\n\nEllis, Greg Freedman, y Ben Schneider. 2023. srvyr: ’dplyr’-Like Syntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nEscobar, Emilio L., y Yves G. Berger. 2013. «A new replicate variance estimator for unequal probability sampling without replacement». The Canadian Journal of Statistics / La Revue Canadienne de Statistique 41 (3): 508-24. https://www.jstor.org/stable/43186201.\n\n\nEscobar, Emilio Lopez, Ernesto Barrios Zamudio, y Juan Francisco Munoz Rosas. 2023. samplingVarEst: Sampling Variance Estimation.\n\n\nExpectations, Great. 2024. Great Expectations Documentation. Superconductive. https://docs.greatexpectations.io.\n\n\nGitHub Actions: Automate Your Workflow. 2024. GitHub. https://github.com/features/actions.\n\n\nHajek, Jaroslav. 1964. «Asymptotic Theory of Rejective Sampling with Varying Probabilities from a Finite Population». The Annals of Mathematical Statistics 35 (4): 1491-1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024. Jupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. «Literate programming». The Computer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, y Natsumi Shokida. 2020. eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nLandau, William Michael. 2018. «The drake R package: a pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. «The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2024. «survey: analysis of complex survey samples».\n\n\nMerkel, Dirk. 2014. «Docker: lightweight linux containers for consistent development and deployment». Linux journal 2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, y Timnit Gebru. 2019. «Model Cards for Model Reporting». En, 220-29. https://doi.org/10.1145/3287560.3287596.\n\n\nPrabhu, Anirudh, y Peter Fox. 2020. «Reproducible Workflow», diciembre. http://arxiv.org/abs/2012.13427.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: venv - Creation of virtual environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\n«R Packages (2e)». s. f. https://r-pkgs.org/.\n\n\nrOpenSci, Brooke Anderson, Scott Chamberlain, Laura DeCicco, Julia Gustavsen, Anna Krystalli, Mauro Lepore, et al. 2024. «rOpenSci Packages: Development, Maintenance, and Peer Review». Zenodo. https://doi.org/10.5281/zenodo.10797633.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, y Eivind Hovig. 2013. «Ten Simple Rules for Reproducible Computational Research». PLOS Computational Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSchneider, Benjamin. 2023. «svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights». https://CRAN.R-project.org/package=svrep.\n\n\nSottile, Anthony, y Contributors. 2024. pre-commit: A framework for managing and maintaining multi-language pre-commit hooks. https://pre-commit.com.\n\n\nStodden, Victoria, Friedrich Leisch, y Roger D. Peng. 2014. Implementing Reproducible Research. CRC Press.\n\n\nUshey, Kevin, y Hadley Wickham. 2023. renv: Project Environments. https://CRAN.R-project.org/package=renv.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWickham, Hadley. 2011. «testthat: Get Started with Testing». The R Journal 3: 5-10. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, y Andy Teucher. 2024. usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, y Manuel Eugster. 2024. roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, Maëlle Salmon, Olivier Roy, y Salim Brüggemann. 2024. pkgdown: Make Static HTML Documentation for a Package. https://CRAN.R-project.org/package=pkgdown.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, y Jennifer Bryan. 2022. devtools: Tools to Make Developing R Packages Easier. https://CRAN.R-project.org/package=devtools.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html",
    "href": "chapters/chapter4.html",
    "title": "4  Desarrollo y metodología",
    "section": "",
    "text": "4.1 Estimación de de los errores estándar\nCada estimador tiene asociado un error estándar que permite cuantificar la variabilidad de la estimación, debido a que la muestra es aleatoria esta medida es una variable aleatoria. Dentro de la incertidumbre puede separarse en errores muestrales y no muestrales. Los primeros refieren a la variabilidad de la estimación debido a la selección de la muestra y los segundos refieren a la variabilidad de la estimación debido a errores de medición, errores de no respuesta, entre otros (Särndal, Swensson, y Wretman 2003).\nEn este trabajo vamos a centrarnos en la estimación de los errores muestrales, ya que los errores no muestrales son difíciles de cuantificar. Los errores muestrales se pueden cuantificar mediante la varianza de la estimación. Esta varianza depende del diseño muestral ya que como se mencionó anteriormente, el diseño muestral induce propiedades estadísticas claves como la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. El paquete survey permite estimar la varianza de la estimación de forma sencilla y eficiente, sin embargo, en algunos casos la estimación de la varianza no es correcta, ya que el paquete survey asume un muestreo simple con probabilidades de inclusión desiguales y con reposición, es decir, con una fracción de muestreo \\(f = \\frac{n}{N} \\approx 0\\) (Lumley 2004).\nPara diseños multietápicos las probabilidades de segundo órden son muy complejas de calcular por lo que una estimación directa no es muy factible además de que estos ponderadores no son exactamente los pesos muestrales definidos en los capítulos anteriores, ya que se ajustan para tener en cuenta la no respuesta y la calibración, lo cual permite una estimación más precisa de ciertas variables de interés. En el caso de que se cuente con un mecanismo para obtener las probabilidades de inclusión de segundo orden este no tendría en cuenta el proceso posterior de calibración, por lo que la estimación de la varianza no sería correcta.\nEn general para este tipo de casos se utilizan principalmente las siguientes estrategias el método del ultimo conglomerado, donde se asume que la variabilidad proviene unicamente de la selección en la primera etapa y métodos de remuestreo como el Bootstrap o Jackknife. En este trabajo se propone la implementación de forma nativa de diferentes métodos utilizando solamente un argumento al cargar la encuesta permitiendo a usuarios no expertos en metodología de muestreo obtener estimaciones de varianzas correctas y confiables.\nAdicionalmente para estimadores no lineales se utiliza el método de Linearización de Taylor que permite aproximar el estimador como función de estimadores lineales un caso típico es la tasa de desempleo que se calcula como el cociente entre la población desocupada y la población económicamente activa. En este caso se puede aproximar la tasa de desempleo como función de estimadores lineales y obtener una estimación de la varianza de la tasa de desempleo o de forma similar un estimador de medias o proporciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#estimación-de-de-los-errores-estándar",
    "href": "chapters/chapter4.html#estimación-de-de-los-errores-estándar",
    "title": "4  Desarrollo y metodología",
    "section": "",
    "text": "4.1.1 Métodos de remuestreo\nLa estimación del error estándar de una media u otros resúmenes poblacionales se basa en la desviación estándar de dicho estimador a través de múltiples muestras independientes. Sin embargo, en encuestas reales solo contamos con una muestra. El enfoque de pesos replicados ofrece una alternativa, al calcular la variabilidad del estimador a partir de múltiples subconjuntos que se comportan de manera parcialmente independiente, y luego extrapola esta variabilidad para obtener una estimación que se asemeje a la que se obtendría si tuviéramos múltiples muestras independientes.\n\n4.1.1.1 Réplicas de Mitad de Muestra\nPara entender mejor este método, consideremos un diseño estratificado en el que se seleccionan dos unidades por estrato. Si dividimos los datos en dos mitades, tomando una unidad de cada estrato, se crean subconjuntos que se pueden considerar como “mitades” independientes. Si la corrección por población finita no es relevante, la varianza de un estimador basado en una mitad de muestra es aproximadamente el doble de la varianza de la muestra completa. Dado que tenemos dos mitades, podemos usar la diferencia entre sus estimaciones para calcular la varianza:\n\\[\n\\text{Var}(\\hat{\\theta}) \\approx \\frac{1}{2} (\\hat{\\theta}_A - \\hat{\\theta}_B)^2,\n\\]\ndonde \\(\\hat{\\theta}_A\\) y \\(\\hat{\\theta}_B\\) son las estimaciones de cada mitad de la muestra. Este enfoque es sencillo pero puede ser inestable, por lo que se suelen usar múltiples conjuntos de divisiones para obtener un promedio más preciso.\n\n\n4.1.1.2 Balanced Repeated Replication (BRR)\nEl método de Balanced Repeated Replication (BRR) es una forma sistemática de elegir subconjuntos de la muestra, garantizando que cada unidad se incluya de manera equilibrada en las réplicas. Esto se logra mediante un balanceo ortogonal, donde cada observación está presente en aproximadamente la mitad de las réplicas, y cada par de unidades de diferentes estratos aparece en las réplicas de forma equilibrada. Con (K) estratos, se puede generar un conjunto de hasta (K + 4) réplicas que produzca una estimación de la varianza que es prácticamente idéntica a la que se obtendría usando todas las (2^K) combinaciones posibles.\nLa varianza utilizando BRR se calcula así:\n\\[\n\\text{Var}_{\\text{BRR}}(\\hat{\\theta}) = \\frac{1}{R} \\sum_{r=1}^R (\\hat{\\theta}_r - \\hat{\\theta})^2,\n\\]\ndonde \\(R\\) es el número de réplicas seleccionadas y \\(\\hat{\\theta}_r\\) es el estimador obtenido de cada réplica.\n\n\n4.1.1.3 Pesos Replicados en Diseños Multietápicos y Complejos\nEl enfoque de pesos replicados no solo se aplica a diseños simples, sino que también se adapta a diseños de muestreo multietápicos y diseños complejos. En estos casos, la estructura de la muestra se complica, ya que puede involucrar varias etapas de selección (por ejemplo, seleccionar primero conglomerados como municipios, luego hogares dentro de los municipios, y finalmente personas dentro de los hogares). Esto hace que la varianza deba considerar la correlación entre unidades seleccionadas en cada etapa.\nPara estos diseños, se utilizan métodos como el Jackknife y el Bootstrap, que permiten manejar la estructura multietápica. Por ejemplo:\n\nEn un diseño Jackknife, se ajustan los pesos eliminando una observación o un conglomerado completo en cada réplica, y recalculando el estimador con los datos restantes. Esto puede ajustarse para considerar la estructura de estratos y conglomerados.\n\n\\[\n\\text{Var}_{\\text{Jackknife}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\theta}_i - \\hat{\\theta})^2,\n\\]\ndonde (n) es el número de observaciones o conglomerados,\\(\\hat{\\theta}_i\\) es la estimación obtenida cuando se omite la \\(i\\)-ésima unidad, y \\(\\hat{\\theta}\\) es la estimación con todos los datos.\n\nEn el Bootstrap, se seleccionan subconjuntos con reemplazo de cada conglomerado, y se ajustan los pesos según el número de veces que cada unidad aparece en la réplica. Esto es especialmente útil cuando las unidades de muestreo tienen una estructura jerárquica, como es el caso de los diseños multietápicos.\n\n\\[\n\\text{Var}_{\\text{Bootstrap}}(\\hat{\\theta}) = \\frac{1}{B} \\sum_{b=1}^B (\\hat{\\theta}_b - \\hat{\\theta})^2,\n\\]\ndonde \\(B\\) es el número de réplicas y \\(\\hat{\\theta}_b\\) es el estimador obtenido en la \\(b\\)-ésima réplica.\n\n\n4.1.1.4 Ventajas de los Pesos Replicados\nAunque estos métodos requieren más esfuerzo computacional comparados con métodos tradicionales como el estimador de Horvitz-Thompson, son muy versátiles. Facilitan la estimación de errores estándar para diferentes tipos de estadísticas, no solo para medias o totales, y son especialmente útiles cuando se trabaja con diseños de muestreo complejos. Además, permiten obtener errores estándar precisos para estimaciones de subpoblaciones sin necesidad de ajustes adicionales. Esto los convierte en una herramienta poderosa para el análisis de encuestas complejas, especialmente con el soporte de software estadístico moderno.\nEl paquete survey con svrep proporcionan una implementación robusta de varios métodos de pesos replicados, incluyendo Balanced Repeated Replication (BRR), Jackknife, y Bootstrap. Sin embargo, el uso adecuado de estos métodos a menudo no es tan conocido por usuarios que no son expertos en muestreo. La correcta especificación del diseño y la interpretación de los resultados pueden ser complejas, especialmente en el caso de diseños de muestreo multietápicos o aquellos que requieren calibración.\nDentro de metasurvey se busca simplificar el uso de estos métodos, pudiendo especificar el tipo de réplica deseado con un solo argumento al cargar la encuesta o utilizar replicas brindadas por la institución que publica los microdatos. Además, se busca incorporar medidas de calidad de las estimaciones como el coeficiente de variación, el error relativo y el error absoluto, para facilitar la interpretación de los resultados y la comparación entre diferentes estimaciones y subpoblaciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#desarrollo-e-implementación",
    "href": "chapters/chapter4.html#desarrollo-e-implementación",
    "title": "4  Desarrollo y metodología",
    "section": "4.2 Desarrollo e Implementación",
    "text": "4.2 Desarrollo e Implementación\nEn esta sección se describen las diferentes partes del paquete metasurvey y su implementación, incluyendo la estructura del paquete, las funciones principales y la forma en que se implementan los métodos de estimación de varianzas y errores estándar. El repositorio de metasurvey está disponible en GitHub y sigue la estructura estándar de un paquete de R, tal como se menciona en lasección 2.2.\n\n4.2.1 Dependencias\nUn aspecto destacado del paquete metasurvey es su uso limitado de dependencias externas, cada una seleccionada por su propósito específico. Por ejemplo, survey (Lumley 2024) se utiliza para el procesamiento de encuestas, data.table (Barrett et al. 2024) facilita la manipulación eficiente de datos, R6 (Chang 2022) permite la programación orientada a objetos, y glue (Hester y Bryan 2024) contribuye a la interpolación de cadenas, mejorando la legibilidad del código al crear o modificar fragmentos de texto. Además, jsonlite (Ooms 2014) se encarga de la lectura y escritura de archivos JSON, lo cual resulta esencial para compartir las configuraciones obtenidas a través de la API de metasurvey, que emplea una base de datos NoSQL, mientras que httr (Wickham 2023) gestiona las peticiones HTTP.\nTambién se incluyen algunas dependencias adicionales para mejorar la experiencia del usuario, como visNetwork (V., Contributors, y Thieurmel 2022) para la visualización de recetas y pasos, y crayon para la impresión de mensajes en la consola con colores.\nLa optimización de las dependencias es un aspecto importante en el desarrollo de paquetes, ya que influye en la eficiencia y la velocidad de carga. Por lo tanto, se ha procurado mantener un equilibrio entre la funcionalidad y la eficiencia, evitando la inclusión de paquetes innecesarios que puedan ralentizar el rendimiento del paquete.\nExiste una versión previa a metasurvey llamada srvyuRu donde las dependencias eran muy amplias. El uso de dplyr (Wickham et al. 2023) y tidyverse (Wickham et al. 2019) hacía que el paquete fuera muy pesado y lento, junto al paquete rlang (Henry y Wickham 2024), que si bien es muy útil para la implementación de la metaprogramación, incrementaba las dependencias de manera innecesaria.\nDentro de srvyuRu, también se utilizaba shiny (Chang 2022) para la implementación de una interfaz gráfica. Sin embargo, se decidió no incluir esta funcionalidad en metasurvey ya que se consideró que no era esencial y que podía ser implementada en un paquete independiente.\nLa versión anterior fue motivada por la necesidad de contar con una herramienta que automatizara el proceso de recodificación de variables y cálculo de indicadores, para compatibilizar los indicadores de la EAI y ECH para el portal PRISMA en la sección de Innovación y Género respectivamente. Sin embargo, la implementación de la interfaz gráfica no fue exitosa, ya que permitía al usuario crear recetas y pasos de forma gráfica, lo cual llevaba a una complejidad innecesaria y a un paquete muy pesado debido a la inclusión de dependencias innecesarias.\n\n\n4.2.2 Ejemplos de la implementación\n\n4.2.2.1 Carga de una encuesta\nEl paquete puede dividirse en dos partes principales: la carga y procesamiento de encuestas, y la estimación de errores estándar. Dentro de lo que es la carga y procesamiento de encuestas, se incluyen funciones para cargar encuestas en diferentes formatos, como SPSS, STATA, CSV, y RDS, y para realizar operaciones básicas como la selección de variables, la recodificación de categorías, y la creación de indicadores.\nEsta implementación puede verse en load_survey.R donde aquí se define la función principal load_survey esta misma se encarga de cargar la encuesta y realizar las operaciones básicas mencionadas anteriormente. Dentro de ella podemos ver que es simplemente un wrapper de diferentes paquetes para cargar la encuesta ya sea read.spss del paquete foregin (R Core Team 2023) para cargar encuestas provenientes en formato SAV o DTA, fread de data.table (Barrett et al. 2024) para archivos CSV y por último loadWorkbook del paquete openxlsx (Schauberger y Walker 2024), todas estas funciones se encargan de cargar la encuesta en base a la extensión del archivo, el usuario puede modificar cambiando el engine como por ejemplo a tidyverse donde la lectura CSV se realiza con read_csv del paquete readr (Wickham 2023), o haven (Wickham, Miller, y Smith 2023) para cargar encuestas en formato SPSS o STATA.\nAl cargar la encuesta el usuario debe de especificar el tipo de encuesta que está cargando y la edición de la misma, estos metadatos serán cruciales para poder obtener recetas y pasos de la API de metasurvey. Además, se puede especificar el tipo de réplica que se desea utilizar, por defecto se utiliza el método de BRR, pero el usuario puede especificar el método de réplica que desee, ya sea Jackknife o Bootstrap, en el Capítulo 5 se menciona como utilizar replicas brindadas por la institución que publica los microdatos y estimadores de cambios netos compuestos.\nUna vez definida la carga de datos dentro de la misma implementación de crea un objeto de la clase Survey la cual se encuentra definida en survey.R. Esta clase es realizada con el paquete R6 (Chang 2022) y se encarga de almacenar la encuesta, los metadatos, las recetas y los pasos junto al diseño muestral, el usuario puede obtener información con wrappers de cada método para que sea más sencillo de utilizar, como por ejemplo cat_steps donde se obtiene todos los pasos que fueron aplicados a la encuesta, cat_recipes donde se obtienen todas las recetas que fueron aplicadas a la encuesta, cat_design donde se obtiene el diseño muestral, entre otros.\nEn el código Código 4.1 se muestra un ejemplo de cómo se carga una encuesta y se obtiene la información de la misma.\n\n\n\nCódigo 4.1: Lectura de la encuesta ECH 2022, fijación del ponderador y obtención de recetas.\n\n\n\n\nCódigo\nlibrary(metasurvey)\n\n# Cargar encuesta\n\n## Encuesta ECH 2022\n## Se fija el ponderador de la encuesta\n## Se obtienen las recetas de la encuesta\n\nech_2022 &lt;- load_survey(\n  metasurvey::load_survey_example(\n    \"ech\",\n    \"ech_2022\"\n  ),\n  svy_edition = \"2022\",\n  svy_type = \"ech\",\n  svy_weight = add_weight(annual = \"w_ano\"),\n  recipes = get_recipe(\n    \"ech\",\n    \"2022\"\n  )\n)\n\n\n\n\n\nDentro de este mismo ejemplo se puede ver que se fija el ponderador de la encuesta, en este caso se fija el ponderador w_ano que es el ponderador anual de la encuesta ECH 2022, este ponderador es crucial para la estimación de errores estándar y para la obtención de recetas y pasos de la encuesta.\n\n\n4.2.2.2 Clase Step\nLa clase Step es una clase que se encarga de almacenar los pasos que se aplican a la encuesta, esta clase se encuentra definida en step.R y se encarga de almacenar los pasos que se aplican a la encuesta, los pasos se aplican a través de recetas que se obtienen de la API de metasurvey, los pasos pueden ser de diferentes tipos, como por ejemplo step_compute que se encarga de calcular una variable, step_recode que se encarga de recodificar una variable, entre otros.\nEn el código Código 4.2 se muestra un ejemplo de cómo se crea un objeto de la clase Step con una clase de R6 (Chang 2022) paquete que permite la programación orientada a objetos en R donde tiene aquí se encuentran los atributos de la clase Step como name, edition, survey_type, type, new_var, exprs, call, svy_before, default_engine, depends_on, comments, bake en conjunto con el método initialize que se encarga de inicializar la clase Step con los atributos mencionados anteriormente. Los objetos Survey, Recipe, PanelRotativeSurvey y PoolSurvey son clases que se encuentran definidas en el paquete metasurvey donde modelar en una clase los diferentes objetos que se utilizan en el paquete permite una mejor organización y estructura del código y facilita la implementación de la meta-programación.\nEs importante mencionar que la clase Step es una clase que se utiliza internamente en el paquete y no es necesario que el usuario la utilice directamente, sin embargo, es importante mencionarla ya que es una parte esencial del paquete y es utilizada en la implementación de las recetas y pasos de la encuesta, además de que es un ejemplo claro de cómo se puede utilizar la programación orientada a objetos en R para modelar diferentes objetos y clases.\n\n\n\nCódigo 4.2: Definición de la clase Step con sus atributos y método initialize para inicializar la clase.\n\n\n\n\nCódigo\nstep &lt;- R6Class(\n  \"Step\",\n  public = list(\n    name = NULL,\n    edition = NULL,\n    survey_type = NULL,\n    type = NULL,\n    new_var = NULL,\n    exprs = NULL,\n    call = NULL,\n    svy_before = NULL,\n    default_engine = NULL,\n    depends_on = list(),\n    comments = NULL,\n    bake = NULL,\n    initialize = function(name, edition, survey_type, type, new_var, exprs, call, svy_before, default_engine, depends_on, comments, bake = !lazy_default()) {\n      self$name &lt;- name\n      self$edition &lt;- edition\n      self$survey_type &lt;- survey_type\n      self$type &lt;- type\n      self$new_var &lt;- new_var\n      self$exprs &lt;- exprs\n      self$call &lt;- call\n      self$svy_before &lt;- svy_before\n      self$default_engine &lt;- default_engine\n      self$depends_on &lt;- depends_on\n      self$comments &lt;- comments\n      self$bake &lt;- bake\n    }\n  )\n)\n\n\n\n\n\nEl principal uso de R6 y no de S3 o S4 es que R6 permite la creación de objetos con estado, lo cual es esencial para la implementación de la meta-programación, ya que permite almacenar el estado de los objetos y modificarlos a través de métodos, lo cual es esencial para la implementación de las recetas y pasos de la encuesta. Además se puede manejar las copias de los objetos de forma mas sencilla lo que permitió implementar el proceso perezoso de los pasos y recetas donde se aplican los pasos y recetas solo cuando se necesita y no de forma inmediata así como también el uso de referencias y no de copias de los objetos optimizando el uso de memoria. Se puede ver mas información de esto último en la sección 4.2.2.3.\n\n\n4.2.2.3 Lazy evaluation\nLa evaluación perezosa es una técnica de programación que consiste en retrasar la evaluación de una expresión hasta que sea necesaria. En el contexto de metasurvey, la evaluación perezosa se utiliza para retrasar la aplicación de recetas y pasos a la encuesta hasta que sea necesario, lo cual permite optimizar el rendimiento y la eficiencia del paquete. Esto hace que los Steps se ejecuten con una validación mínima en base a las dependencias de las variables, y se ejecuten solo cuando se necesiten o al cocinar la receta.\nEl paquete tiene por defecto la evaluación perezosa de los pasos y recetas, lo cual hace que sea más eficiente y rápido el procesamiento de las encuestas aunque puede llevar a confusiones al usuario cuando revisa los datos de forma manual ya que si bien se aplican los Step los mismos no tienen efecto hasta que se cocine la receta, el usuario puede desactivar (Código 4.3) la evaluación perezosa de los pasos y recetas si lo desea. La evaluación perezosa se implementa a través de la clase Step y de la función bake que se encarga de aplicar los pasos y recetas a la encuesta.\n\n\n\nCódigo 4.3: Forma de desactivar la evaluación perezosa de los pasos y recetas. Esto hace que los pasos y recetas se apliquen de forma inmediata.\n\n\n\n\nCódigo\nmetasurvey::set_lazy_processing(FALSE)\n\n\n\n\n\n\n\n4.2.2.4 Uso de copias y referencias\nEl paquete data.table (Barrett et al. 2024) logra una eficiencia en la manipulación de datos al utilizar referencias en lugar de copias, lo cual permite que las operaciones se realicen de forma más rápida y eficiente. Dentro de metasurvey al utilizar como motor data.table permite que sea eficiente y rápido aunque puede llevar a confusiones al usuario donde se modifican las referencias de los objetos algo que no es común en R, sin embargo, se puede utilizar la función copy para realizar copias de los objetos y no modificar las referencias de los mismos Código 4.4.\n\n\n\nCódigo 4.4: Desactivar el uso de referencias y utilizar copias de los objetos.\n\n\n\n\nCódigo\nmetasurvey::set_use_copy(TRUE)\n\n\n\n\n\n\n\n\n4.2.3 Meta-programación\nLa meta-programación fue un aspecto clave en el desarrollo de metasurvey, ya que permitió que al realizar una operación en una encuesta, se generara un registro de los pasos y recetas aplicados, lo cual es esencial para la replicabilidad y la transparencia de los análisis. La meta-programación se implementó a través de la clase Survey y de las funciones auxiliares que permiten la creación y aplicación de recetas y pasos.\n\n\n\nCódigo 4.5: Ejemplo de función para encontrar dependencias de variables en una expresión de un step. Existen otros ejemplos de meta-programación en el paquete aunque son más complejos y no se muestran en este documento. Puede ver ejemplos en la función compute y recode del paquete metasurvey funciones internas que se encargan de aplicar los pasos y recetas a la encuesta. Step.R\n\n\n\n\nCódigo\nfind_dependencies &lt;- function(call_expr, survey) {\n  dependencies &lt;- character()\n\n  if (is.call(call_expr)) {\n    for (i in seq_along(call_expr)) {\n      result &lt;- find_dependencies(call_expr[[i]], survey)\n      if (!is.null(result)) {\n        dependencies &lt;- unique(c(dependencies, result))\n      }\n    }\n  } else if (is.name(call_expr) && as.character(call_expr) %in% names(survey)) {\n    dependencies &lt;- unique(c(dependencies, as.character(call_expr)))\n  }\n\n  return(unique(dependencies))\n}\n\n\n\n\n\nEn el código Código 4.5 se muestra una función auxiliar que permite encontrar las dependencias de variables en una expresión de un Step. Esta función se utiliza para identificar las variables que se utilizan en un paso y que deben ser incluidas en el registro de recetas. La función find_dependencies recibe una expresión de un paso y un objeto de la clase Survey, y devuelve un vector con las variables que se utilizan en el paso. Esta función se utiliza de forma interna en las implementaciones de step_compute y step_recode para registrar las dependencias esto es un ejemplo claro de como con código se puede extraer información del mismo y utilizarla para otros fines.\n\n\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, Toby Hocking, y Benjamin Schwendinger. 2024. data.table: Extension of ‘data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nHenry, Lionel, y Hadley Wickham. 2024. rlang: Functions for Base Types and Core R and ’Tidyverse’ Features. https://rlang.r-lib.org.\n\n\nHester, Jim, y Jennifer Bryan. 2024. glue: Interpreted String Literals. https://CRAN.R-project.org/package=glue.\n\n\nLumley, Thomas. 2004. «Analysis of Complex Survey Samples». Journal of Statistical Software 9 (abril): 1-19. https://doi.org/10.18637/jss.v009.i08.\n\n\n———. 2024. «survey: analysis of complex survey samples».\n\n\nOoms, Jeroen. 2014. «The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects». arXiv:1403.2805 [stat.CO]. https://arxiv.org/abs/1403.2805.\n\n\nR Core Team. 2023. foreign: Read Data Stored by ’Minitab’, ’S’, ’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, y Alexander Walker. 2024. openxlsx: Read, Write and Edit xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nV., Almende B., Contributors, y Benoit Thieurmel. 2022. visNetwork: Network Visualization using ’vis.js’ Library. https://CRAN.R-project.org/package=visNetwork.\n\n\nWickham, Hadley. 2023. httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. «Welcome to the tidyverse». Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, y Davis Vaughan. 2023. dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org.\n\n\nWickham, Hadley, Evan Miller, y Danny Smith. 2023. haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html",
    "href": "chapters/chapter5.html",
    "title": "5  Casos de uso",
    "section": "",
    "text": "5.1 Encuesta Continua de Hogares\nLa Encuesta Continua de Hogares (ECH) es la principal fuente de información referida al mercado de trabajo en Uruguay. La encuesta se realiza en forma continua con periodicidad mensual desde el 1968. En sus primeros años la encuesta solo consideraba como universo de hogares a Montevideo sin embargo luego en 1980 se extendió a todo el país mediante un programa de las Naciones Unidas para el Desarrollo y el Fondo de las Naciones Unidad para Actividades de Población llegando a cubrir todo el territorio nacional.\nActualmente el INE tiene publicado en su página web microdatos de la encuesta desde el año 2006, en el portal ANDA se pueden encontrar junto a los microdatos los códigos de las variables y las definiciones de las mismas junto a la descripción del diseño de la encuesta.\nLa encuesta a lo largo de los años ha ido incorporando nuevas variables y modificando las existentes, por lo que es importante tener en cuenta la versión de la encuesta que se está utilizando para realizar los análisis y dependiendo del grupo de variables que se quiera analizar puede que sea mas o menos tedioso el proceso de re-codificación de variables y cálculo de indicadores. Con la ayuda de recetas y el paquete metasurvey se puede automatizar el proceso de re-codificación de variables y cálculo de indicadores para poder calcular los indicadores de interés.\nA continuación se presentan algunos ejemplos de como poder replicar los resultados de las tasas de mercado de trabajo tanto a nivel mensual, trimestral y anual utilizando la encuesta continua de hogares, utilizando los microdatos de la encuesta en 2023.\nEl objeto ech_2023 tiene dentro los microdatos de implantación y seguimiento en conjunto con las replicas boostrap, para asociar a cada conjunto de microdatos se extrae el patrón de tiempo de los nombres de los archivos de las replicas bootstrap y se asocia a cada conjunto de microdatos. Es importante notar que se puede extraer los microdatos para un mes en particular y poder ver el diseño que se crea utilizando el paquete survey:.\nTambién pueden agruparse los microdatos de seguimiento en un trimestre en particular:\nextract_surveys(\n  ech_2023,\n  quarterly = 1\n)\n#&gt; Type: ECH_2023\n#&gt; Periodicity: Periodicity of pool quarterly each survey monthly\n#&gt; Steps: None\n#&gt; Recipes: None\n#&gt; Group: Q1\nEl agrupar los microdatos también puede utilizarse para obtener indicadores de medias móviles como se recomienda cuando se realizan estimaciones en diferentes dominios geográficos o grupos de edad.\nPara construir las variables de interés el usuario puede descargar las recetas desde la API de metasurvey y aplicarlas a los microdatos de la encuesta continua de hogares o puede crear sus propias recetas y aplicarlas a los microdatos. A continuación se presentan algunas recetas que se pueden utilizar para calcular las tasas de mercado de trabajo a nivel mensual, trimestral y anual.\nech_2023 &lt;- ech_2023 %&gt;%\n  step_recode(\n    \"pea\",\n    POBPCOAC %in% 2:5 ~ 1,\n    .default = 0,\n    comment = \"Población Económicamente Activa\",\n    .level = \"follow_up\"\n  ) %&gt;%\n  step_recode(\n    \"pet\",\n    e27 &gt;= 14 ~ 1,\n    .default = 0,\n    comment = \"Población Empleada\",\n    .level = \"follow_up\"\n  ) %&gt;%\n  step_recode(\n    \"po\",\n    POBPCOAC == 2 ~ 1,\n    .default = 0,\n    comment = \"Población Ocupada\",\n    .level = \"follow_up\"\n  ) %&gt;%\n  step_recode(\n    \"pd\",\n    POBPCOAC %in% 3:5 ~ 1,\n    .default = 0,\n    comment = \"Población Desocupada\",\n    .level = \"follow_up\"\n  )\nDentro",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#encuesta-continua-de-hogares",
    "href": "chapters/chapter5.html#encuesta-continua-de-hogares",
    "title": "5  Casos de uso",
    "section": "",
    "text": "Mencionar más sobre los paneles que parten desde 2021\nMencionar las bases compatibilizadas del IECON\n\n\n\n\n\nCódigo 5.1: Carga de la encuesta continua de hogares en 2023, se carga la implantación y el seguimiento de la encuesta, se especifica el tipo de encuesta, el peso de la implantación y el peso del seguimiento, en este caso se utilizan pesos replicados bootstrap para el seguimiento de la encuesta.\n\n\n\npath_dir &lt;- here::here(\"example-data\", \"ech\", \"ech_2023\")\nech_2023 &lt;- load_panel_survey(\n  path_implantation = file.path(\n    path_dir,\n    \"ECH_implantacion_2023.csv\"\n  ),\n  path_follow_up = file.path(\n    path_dir,\n    \"seguimiento\"\n  ),\n  svy_type = \"ECH_2023\",\n  svy_weight_implantation = add_weight(\n    annual = \"W_ANO\"\n  ),\n  svy_weight_follow_up = add_weight(\n    monthly = add_replicate(\n      \"W\",\n      replicate_path = file.path(\n        path_dir,\n        c(\n          \"Pesos replicados Bootstrap mensuales enero_junio 2023\",\n          \"Pesos replicados Bootstrap mensuales julio_diciembre 2023\"\n        ),\n        c(\n          \"Pesos replicados mensuales enero_junio 2023\",\n          \"Pesos replicados mensuales Julio_diciembre 2023\"\n        )\n      ),\n      replicate_id = c(\"ID\" = \"ID\"),\n      replicate_pattern = \"wr[0-9]+\",\n      replicate_type = \"bootstrap\"\n    )\n  )\n)\n\n\n\n\n\n\n\n\nCódigo 5.2: Obtener los microdatos de la encuesta continua de hogares para el mes de enero de 2023 y ver el diseño de la encuesta.\n\n\n\nech_01 &lt;- get_follow_up(ech_2023, index = 1)[[1]]\nech_01$design\n#&gt; $monthly\n#&gt; Call: svrepdesign.default(id = psu, weights = as.formula(paste(\"~\", \n#&gt;     x$weight)), data = data_aux, repweights = x$replicate_pattern, \n#&gt;     type = x$replicate_type)\n#&gt; Survey bootstrap with 1000 replicates.\n\n\n\n\n\n\n\n\n\n\n\nPoner estimación a nivel mensual, trimestral y anual\nIncluir algún dominio de estimación\nDescargar recetas desde la API de metasurvey\nMultiples años",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eph",
    "href": "chapters/chapter5.html#eph",
    "title": "5  Casos de uso",
    "section": "5.2 EPH",
    "text": "5.2 EPH\n\nMencionar la flexibilidad de metasurvey\n\n\neph2022_3 &lt;- metasurvey::load_survey(\n  path = metasurvey::load_survey_example(\n    \"eph\",\n    \"eph2022_3\"\n  ),\n  svy_type = \"eph\",\n  svy_edition = \"eph_202302\",\n  svy_weight = add_weight(\n    monthly = \"PONDERA\"\n  )\n) |&gt;\n  metasurvey::step_recode(\n    \"pea\",\n    ESTADO %in% 1:2 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pet\",\n    ESTADO != 4 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"po\",\n    ESTADO == 1 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pd\",\n    ESTADO == 2 ~ 1,\n    .default = 0\n  )\n\n\nmetasurvey::view_graph(eph2022_3)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/bibliography.html",
    "href": "chapters/bibliography.html",
    "title": "7  Bibliografía",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey,\nand Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n“Apache Airflow Documentation.” n.d. https://airflow.apache.org/docs/latest/.\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael\nChirico, Toby Hocking, and Benjamin Schwendinger. 2024. Data.table:\nExtension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John\nAinsworth, Jiten Bhagat, Philip Couch, et al. 2013. “Why Linked\nData Is Not Enough for Scientists.” Future Generation\nComputer Systems, Special section: Recent advances in e-science, 29\n(2): 599–611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars\nKotthoff, and Bernd Bischl. 2021. “Mlr3pipelines - Flexible\nMachine Learning Pipelines in r.” Journal of Machine Learning\nResearch 22 (184): 1–7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, and Santa Ivanova. 2020. Vardpoor:\nEstimation of Indicators on Social Exclusion and Poverty and Its\nLinearization, Variance Estimation. Riga, Latvia: Central\nStatistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChambers, John M. 2014. “Object-Oriented Programming, Functional\nProgramming and r.” Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference\nSemantics.\n\n\nChevalier, Martin. 2023. Gustave: A User-Oriented Statistical\nToolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCodecov: Code Coverage Insights. 2024. https://about.codecov.io.\n\n\nCook, Di. 2014. “Statistical Computing Research |.” http://dicook.org/2014/10/05/content/post/2014-10-5-statistical-computing/.\n\n\nDavison, Andrew P, and John E Huth. 2012. “Sumatra: A Toolkit for\nReproducible Research.” arXiv Preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. “Ech: Caja de\nHerramientas Para Procesar La Encuesta Continua de Hogares.” https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, and Yves Tille. 1998. “Unequal Probability\nSampling Without Replacement Through a Splitting Method.”\nBiometrika 85 (1): 89–101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, and Yves Tillé. 2005. “Variance\nApproximation Under Balanced Sampling.” Journal of\nStatistical Planning and Inference 128 (2): 569–91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nDriessen, Vincent. 2010. “A Successful Git Branching\nModel.” https://nvie.com/posts/a-successful-git-branching-model/.\n\n\nEllis, Greg Freedman, and Ben Schneider. 2023. Srvyr: ’Dplyr’-Like\nSyntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nEscobar, Emilio L., and Yves G. Berger. 2013. “A New Replicate\nVariance Estimator for Unequal Probability Sampling Without\nReplacement.” The Canadian Journal of Statistics / La Revue\nCanadienne de Statistique 41 (3): 508–24. https://www.jstor.org/stable/43186201.\n\n\nEscobar, Emilio Lopez, Ernesto Barrios Zamudio, and Juan Francisco Munoz\nRosas. 2023. samplingVarEst: Sampling Variance Estimation.\n\n\nExpectations, Great. 2024. Great Expectations Documentation.\nSuperconductive. https://docs.greatexpectations.io.\n\n\nGitHub Actions: Automate Your Workflow. 2024. GitHub. https://github.com/features/actions.\n\n\nHajek, Jaroslav. 1964. “Asymptotic Theory of Rejective Sampling\nwith Varying Probabilities from a Finite Population.” The\nAnnals of Mathematical Statistics 35 (4): 1491–1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nHenry, Lionel, and Hadley Wickham. 2024. Rlang: Functions for Base\nTypes and Core r and ’Tidyverse’ Features. https://rlang.r-lib.org.\n\n\nHester, Jim, and Jennifer Bryan. 2024. Glue: Interpreted String\nLiterals. https://CRAN.R-project.org/package=glue.\n\n\nHorvitz, D. G., and D. J. Thompson. 1952. “A Generalization of\nSampling Without Replacement from a Finite Universe.” Journal\nof the American Statistical Association 47 (260): 663–85. https://doi.org/10.2307/2280784.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger,\nMatthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024.\nJupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” The\nComputer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, and\nNatsumi Shokida. 2020. Eph: Argentina’s Permanent Household Survey\nData and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, and Emil Hvitfeldt. 2024. Recipes:\nPreprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLandau, William Michael. 2018. “The Drake r Package: A Pipeline\nToolkit for Reproducibility and High-Performance Computing.”\nJournal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. “The Targets r Package: A Dynamic Make-Like\nFunction-Oriented Pipeline Toolkit for Reproducibility and\nHigh-Performance Computing.” Journal of Open Source\nSoftware 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2004. “Analysis of Complex Survey Samples.”\nJournal of Statistical Software 9 (April): 1–19. https://doi.org/10.18637/jss.v009.i08.\n\n\n———. 2011. Complex Surveys: A Guide to Analysis Using R. John\nWiley & Sons.\n\n\n———. 2024a. “Survey: Analysis of Complex Survey Samples.”\n\n\n———. 2024b. “Survey: Analysis of Complex Survey Samples.”\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in r:\nStatistical Programming for Data Science, Analysis and Finance.\nSPRINGER.\n\n\nMerkel, Dirk. 2014. “Docker: Lightweight Linux Containers for\nConsistent Development and Deployment.” Linux Journal\n2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy\nVasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and\nTimnit Gebru. 2019. “Model Cards for Model Reporting.” In,\n220–29. https://doi.org/10.1145/3287560.3287596.\n\n\nOoms, Jeroen. 2014. “The Jsonlite Package: A Practical and\nConsistent Mapping Between JSON Data and r Objects.”\narXiv:1403.2805 [Stat.CO]. https://arxiv.org/abs/1403.2805.\n\n\nPrabhu, Anirudh, and Peter Fox. 2020. “Reproducible\nWorkflow,” December. http://arxiv.org/abs/2012.13427.\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: Venv -\nCreation of Virtual Environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\nR Core Team. 2023a. Foreign: Read Data Stored by ’Minitab’, ’s’,\n’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\n———. 2023b. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\n“R Packages (2e).” n.d. https://r-pkgs.org/.\n\n\nrOpenSci, Brooke Anderson, Scott Chamberlain, Laura DeCicco, Julia\nGustavsen, Anna Krystalli, Mauro Lepore, et al. 2024. “rOpenSci Packages: Development, Maintenance, and Peer\nReview.” Zenodo. https://doi.org/10.5281/zenodo.10797633.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig.\n2013. “Ten Simple Rules for Reproducible Computational\nResearch.” PLOS Computational Biology 9 (10): e1003285.\nhttps://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSärndal, Carl-Erik, Bengt Swensson, and Jan Wretman. 2003. Model\nAssisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, and Alexander Walker. 2024. Openxlsx: Read,\nWrite and Edit Xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nSchneider, Benjamin. 2023. “Svrep: Tools for Creating, Updating,\nand Analyzing Survey Replicate Weights.” https://CRAN.R-project.org/package=svrep.\n\n\nSottile, Anthony, and Contributors. 2024. Pre-Commit: A Framework\nfor Managing and Maintaining Multi-Language Pre-Commit Hooks. https://pre-commit.com.\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D. Peng. 2014.\nImplementing Reproducible Research. CRC Press.\n\n\nThomas Mailund. 2017. Metaprogramming in r. 1st ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nUshey, Kevin, and Hadley Wickham. 2023. Renv: Project\nEnvironments. https://CRAN.R-project.org/package=renv.\n\n\nV., Almende B., Contributors, and Benoit Thieurmel. 2022.\nvisNetwork: Network Visualization Using ’Vis.js’ Library. https://CRAN.R-project.org/package=visNetwork.\n\n\nVargas, Mauricio. 2024. Casen: Metodos de Estimacion Con Disenio\nProbabilistico y Estratificado En Encuesta CASEN (Estimation Methods\nwith Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. “Reproducibility and Replicability in\nEconomics.” Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, and Matt Herman. 2024. Tidycensus: Load US Census\nBoundary and Attribute Data as ’Tidyverse’ and ’Sf’-Ready Data\nFrames. https://walker-data.com/tidycensus/.\n\n\nWickham, Hadley. 2011b. “Testthat: Get Started with\nTesting.” The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2011a. “Testthat: Get Started with Testing.” The R\nJournal 3: 5–10. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced r, Second Edition. CRC Press.\n\n\n———. 2023. Httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the Tidyverse.” Journal of Open Source\nSoftware 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher.\n2024. Usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster.\n2024. Roxygen2: In-Line\nDocumentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org.\n\n\nWickham, Hadley, Jay Hesselberth, Maëlle Salmon, Olivier Roy, and Salim\nBrüggemann. 2024. Pkgdown: Make Static HTML Documentation for a\nPackage. https://CRAN.R-project.org/package=pkgdown.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, and Jennifer Bryan. 2022.\nDevtools: Tools to Make Developing r Packages Easier. https://CRAN.R-project.org/package=devtools.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2023. Haven: Import\nand Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2024. Tidyr:\nTidy Messy Data. https://tidyr.tidyverse.org.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bibliografía</span>"
    ]
  },
  {
    "objectID": "Appendices/AppendixA.html",
    "href": "Appendices/AppendixA.html",
    "title": "Apéndice A — Frequently Asked Questions",
    "section": "",
    "text": "A.1 How do I change the colors of links?\nPass in urlcolor: in yaml. Or set these in the include-in-header file.\nIf you want to completely hide the links, you can use:\n{}, or even better:\n{}.\nIf you want to have obvious links in the PDF but not the printed text, use:\n{}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Frequently Asked Questions</span>"
    ]
  }
]