[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metaSurvey",
    "section": "",
    "text": "Descripci√≥n del proyecto\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEste cap√≠tulo est√° en proceso de escritura. Consulte la rama de desarrollo para ver el avance del cap√≠tulo\n\n\n\n\n\nmetaSurvey",
    "crumbs": [
      "Descripci√≥n del proyecto"
    ]
  },
  {
    "objectID": "chapters/chapter1.html",
    "href": "chapters/chapter1.html",
    "title": "1¬† Introducci√≥n",
    "section": "",
    "text": "Nota\n\n\n\nEste cap√≠tulo est√° en proceso de validaci√≥n. Cualquier comentario es bienvenido\n\n\n\nEl presente trabajo final de grado tiene como objetivo presentar el desarrollo del paquete metaSurvey disponible en R (R Core Team, 2023). R es un leguaje de programaci√≥n de c√≥digo abierto ampliamente utilizado en la comunidad cient√≠fica para el an√°lisis de datos, estad√≠stica y aprendizaje autom√°tico, y en general se utiliza el concepto paquete para referirse a una colecci√≥n de funciones, m√©todos y clases que extienden las funcionalidades de R propuestas por la misma comunidad de usuarios. A lo largo de deste trabajo se abordar√°n varios conceptos clave tanto para el desarrollo del paquete como para el an√°lisis de encuestas por muestreo.\nActualemente existen varios esfuerzos para facilitar el procesamiento de encuestas, entre ellos existen principalmente dos tipos de paquetes, aquellos que implementan la metodolog√≠a de inferencia en muestreo de poblaciones finitas como puede ser el paquete survey (lumley2024?), gustave (Incluir cita), vardpoor, svrep, weights y aquellos que permiten acceder y manipular encuestas espec√≠ficas como ech (Detomasi, 2020), eph (Kozlowski et¬†al., 2020), tidycensus (Walker & Herman, 2024), casen (Incluir cita) entre otros. Sin embargo, estos ultimos tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformaci√≥n de los microdatos a indicadores de inter√©s, como puede ser el indice de pobreza, tasas del mercado laboral, ingreso salarial, etc. En general, sus implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualizaci√≥n del paquete utilizado para obtener los indicadores en la nueva edicici√≥n de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la pr√°ctica. Adem√°s en las implementaciones actuales, el usuario cuenta con una funci√≥n de alto nivel que act√∫a como una caja negra, donde no se permite modificar el c√≥digo para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin tener que leer el c√≥digo fuente o la documentaci√≥n adjunta.\nEste tipo de problemas puede verse en ech (Detomasi, 2020), donde existen funciones para crear variables de mercado laboral, educaci√≥n o ingresos, pero estas funciones dependen de la existencia de ciertas variables en la encuesta, cuya estructura puede cambiar de una versi√≥n a otra de la encuesta. Sin revisar el cuerpo de la funci√≥n, no se conoce el proceso de construcci√≥n de variables. Algo similar ocurre con eph (Kozlowski et¬†al., 2020), donde se tienen funciones de alto nivel que no permiten modificar el c√≥digo para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin inspeccionar a fondo c√≥mo se construyen las funciones del paquete. Esta inspecci√≥n del c√≥digo fuente, como consultar el repositorio de GitHub del paquete o revisar la definici√≥n de la funci√≥n, puede ser una tarea tediosa y no garantiza que el usuario pueda entender el proceso de construcci√≥n de variables. Esto se debe a que el c√≥digo puede ser muy extenso o que el usuario no tenga el conocimiento suficiente para entender el c√≥digo o se empleen ciertos frameworks que el usuario no conozca, como el uso de las librer√≠as dplyr (Wickham et¬†al., 2023) o tidyr (Wickham et¬†al., 2024), muy populares en R para el manejo de datos. Tambi√©n puede ser dif√≠cil aislar el proceso de manipulaci√≥n de la encuesta de la implementaci√≥n espec√≠fica de la funci√≥n para manejar la forma de presentaci√≥n, estructura del objeto a devolver, etc. Un claro ejemplo de esto puede verse en tidycensus (Walker & Herman, 2024), donde existe una funci√≥n para obtener datos sobre la migraci√≥n de la comunidad estadounidense, pero en la misma funci√≥n tambi√©n se encuentran pasos para mejorar la estructura del conjunto de datos a devolver. En este sentido, el usuario no puede aislar el proceso de recodificaci√≥n/construcci√≥n de variables sobre variables originales y la obtenci√≥n de datos geogr√°ficos y presentaci√≥n.\nPara cientificos sociales, es importante tener en cuenta que el proceso de transformaci√≥n de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayor√≠a no es de conocimiento general. Es de inter√©s obtener informaci√≥n hist√≥rica de indicadores y en general es un proceso tedioso y propenso a errores, especialmente si proviene de encuestas donde su estructura y/o forma de preguntar o su codificaci√≥n puede cambiar con el tiempo. Esto resulta en un proceso extenso y dif√≠cil de entender hasta llegar a la construcci√≥n de esta serie de indicadores. Muchas veces, diferentes usuarios hacen el mismo proceso de construcci√≥n de indicadores de manera independiente y sin compartir el c√≥digo fuente o la metodolog√≠a de construcci√≥n de indicadores, ya que cada uno utiliza su propio estilo de programaci√≥n o hasta diferentes paquetes estad√≠sticos, en su mayor√≠a propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcci√≥n, esta est√° ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el c√≥digo.\nEn este sentido, es importante que el usuario pueda tener un control total sobre el proceso de transformaci√≥n de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcci√≥n de indicadores, adem√°s de brindar una herramienta com√∫n libre de estilos de programaci√≥n y definiendo con simples pasos el proceso de construcci√≥n de variables sint√©ticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodolog√≠a rigurosa y facil de referenciar en la implementaci√≥n. Es crucial que este proceso sea transparente y entendible para el usuario. En capitulos posteriores se abordar√°n ejemplos con los paquetes mencionados anteriormente y se presentar√° el paquete metaSurvey y su implementaci√≥n de recetas para la construcci√≥n de indicadores mediante la meta-programaci√≥n.\nAl trabajar con encuestas por muestreo, es importante tener en cuenta la forma en la que se obtuvier√≥n los datos y su proceso generador para poder realizar inferencias sobre la poblaci√≥n de inter√©s. En general, obtener estimaciones puntuales de estad√≠sticos de totales, promedios o proporciones es relativamente sencillo, pero puede ser que se reporte una estimaci√≥n donde no exista un tama√±o de muestra suficiente para obtener una estimaci√≥n confiable y/o que la variabilidad de la estimaci√≥n sea alta y no sea recomendable su uso. En este sentido, es importante que el usuario no experto tenga de forma nativa una forma de obtener estimaciones puntuales y sus errores asociados de manera sencilla. Es com√∫n utilizar estimaciones puntuales sin tener una medida de incertidumbre o a√∫n peor incluir una estimaci√≥n del error est√°ndar sin tener en cuenta el dise√±o muestral correcto, lo que puede llevar a conclusiones err√≥neas sobre la variabilidad de la estimaci√≥n. metaSurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de forma nativa y con estos resultados hacer recomendaciones sobre la utilidad y confianza de la estimaci√≥n mediante coeficientes de variaci√≥n, intervalos de confianza, tama√±o de muestra efectivo, entre otros sin tener que ser un experto en metodolog√≠a de estimaci√≥n de varianzas y remuestreo. En capitulos posteriores se abordar√°n ejemplos con los paquetes mencionados anteriormente y se presentar√° el paquete metaSurvey y su implementaci√≥n de estimaciones puntuales y sus errores asociados.\nEl desarrollo de un paquete en R es un proceso que requiere contar con una idea bien formada y los medios para llevarla a cabo es por esto que es importante contar con una metodolog√≠a de trabajo ordenada, heredada del desarrollo de software convencional ya que para la publicaci√≥n y difusi√≥n del paquete se tiene que cumplir con ciertos est√°ndares de calidad y documentaci√≥n para que otros usuarios puedan utilizarlo. En este sentido, es importante tener en cuenta que el desarrollo de un paquete en R puede llevar tiempo y esfuerzo, a consecuencia de esto, en el documento se presentar√°n diferentes conceptos sobre metodolog√≠a para el desarrollo de paquetes en R y se aboraran ejemplos con la implementaci√≥n de metaSurvey.\nEn este sentido, metaSurvey pretende ser una herramienta relevante para el trabajo con encuestas en ciencias sociales, buscando solucionar las limitaciones anteriormente mencionadas. Todo el proceso de transformaci√≥n de los microdatos a indicadores se realiza a trav√©s de una serie de funciones que permiten al usuario tener un control total y transparente sobre el proceso de transformaci√≥n de los microdatos a indicadores. Adem√°s, metaSurvey permite que el usuario pueda realizar el proceso de transformaci√≥n de los microdatos a indicadores de manera reproducible y transparente. El usuario puede compartir el c√≥digo de una forma entendible, casi como un ‚Äúrecetario de cocina‚Äù. El procedimiento aplicado a los datos utilizados para obtener los indicadores se realiza mediante lo que denominamos steps y recipes, conformando as√≠ una especie de camino transparente para la construcci√≥n de indicadores. Esto permite compartir en forma visual un DAG (Directed Acyclic Graph) que permite visualizar el proceso de construcci√≥n de indicadores sin tener que abrir un script de R. En complemento al proceso de creaci√≥n de variables, metaSurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de manera sencilla y brindar recomendaciones sobre la utilidad de la estimaci√≥n en el caso de que se cuente con una variabilidad alta en la estimaci√≥n, en base a recomendaciones a su coeficiente de variaci√≥n o m√©tricas similares.\nEl enfoque que permite la flexibilidad a la hora de construir los indicadores es la meta-programaci√≥n. La meta-programaci√≥n es un paradigma de programaci√≥n que permite que un programa pueda modificar su estructura interna en tiempo de ejecuci√≥n. En R, la meta-programaci√≥n se realiza a trav√©s de las funciones eval, parse, substitute, do.call y quote, que permiten evaluar y parsear c√≥digo de manera din√°mica. En este sentido, metaSurvey utiliza la meta-programaci√≥n para permitir que el usuario pueda modificar el c√≥digo que se utiliza para transformar los microdatos a indicadores, teniendo funciones de alto nivel similares a las que se utilizan en el paquete recipes de la librer√≠a tidymodels (Kuhn et¬†al., 2024).\nEn el siguiente capitulo se presentara un marco conceptual b√°sico sobre el muestreo de poblaciones finitas, diferentes paradigmas de programaci√≥n como puede ser la programaci√≥n orientada a objetos, programaci√≥n funcional y la meta-programaci√≥n y como se utilizan en el desarrollo del paquete. Luego, se ahondara en antecedentes previos tanto en la parte de metodolog√≠a de estimaci√≥n de varianzas y paquetes e ideas similares donde se basa el desarrollo del paquete. Finalmente, se presentar√°n ejemplos de c√≥mo utilizar el paquete metaSurvey para construir indicadores de mercado laboral a partir de los microdatos de la ECH y para mostrar su flexibilidad, se incluir√° un ejemplo con la EPH.\n\n\n\n\nDetomasi, G. M. &. R. (2020). ech: Caja de herramientas para procesar la Encuesta Continua de Hogares. https://github.com/calcita/ech\n\n\nKozlowski, D., Tiscornia, P., Weksler, G., Rosati, G., & Shokida, N. (2020). eph: Argentina‚Äôs Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/\n\n\nKuhn, M., Wickham, H., & Hvitfeldt, E. (2024). recipes: Preprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes\n\n\nR Core Team. (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing. https://www.R-project.org/\n\n\nWalker, K., & Herman, M. (2024). tidycensus: Load US Census Boundary and Attribute Data as ‚Äôtidyverse‚Äô and ‚Äôsf‚Äô-Ready Data Frames. https://walker-data.com/tidycensus/\n\n\nWickham, H., Fran√ßois, R., Henry, L., M√ºller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org\n\n\nWickham, H., Vaughan, D., & Girlich, M. (2024). tidyr: Tidy Messy Data. https://tidyr.tidyverse.org",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html",
    "href": "chapters/chapter2.html",
    "title": "2¬† Marco conceptual",
    "section": "",
    "text": "2.1 Inferencia en muestreo de poblaciones finitas\nComo fue mencionado anteriormente las encuestas por muestreo son la principal fuente de informaci√≥n para la construcci√≥n de indicdores sociodemogr√°ficos y economicos, en este sentido, es importante tener en cuenta un marco te√≥rico para realizar inferencias. Es sumamente sencillo obtener estimaciones puntuales de estad√≠sticos usuales aunque es importante considerar la variabilidad de los estimadores, tanto para poder realizar un proceso de inferencia completo as√≠ como tambi√©n para poder cuantificar la confiabilidad de la estimaci√≥n. A continuaci√≥n, se definen los conceptos b√°sicos de inferencia en muestreo de poblaciones finitas como son el dise√±o muestral, probabilidades de inclusi√≥n basadas en el dise√±o, estimadores de Horvitz-Thompson HT, ponderaci√≥n, medidas de incertidumbre y errores est√°ndar basados en (S√§rndal et¬†al., 2003).",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "href": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "title": "2¬† Marco conceptual",
    "section": "",
    "text": "2.1.1 Dise√±o muestral\nEl concepto de dise√±o muestral refiere al mecanismo mediante el cual se selecciona una muestra donde aqu√≠ se determinan propiedades estad√≠sticas claves como puede ser la distribuci√≥n en el muestreo, valores esperados y varianzas de estimadores poblacionales. En dise√±os sencillos es posible calcular esta funci√≥n o encontrar una expresi√≥n an√°litica con facilidad mientras que en dise√±os mas complejos como pueden ser los multietapicos es necesario abordar el problema de otra forma y asumir ciertas hipoesis para poder construir probabilidades de inclusi√≥n tanto de primer √≥rden como segundo √≥rden.\nLa definici√≥n matematica se basa en que dado un universo \\(U\\) de \\(N\\) elementos (puede ser conocido o no) \\(\\{u_{1},u_{2}, \\cdots, u_{N}\\}\\) y se considera un conjunto de tama√±o \\(n\\) de elementos de \\(U\\) que se denota como \\(s = \\{u_{1},u_{2}, \\cdots, u_{n}\\}\\) al cual comunmente denominamos muestra, el dise√±o muestral puede definirse de la siguiente forma:\n\\[\nPr(S = s) = p(s)\n\\]\nRealizando un poco de inspecci√≥n en la definici√≥n anterior se puede observar que el dise√±o muestral es una funci√≥n de probabilidad que asigna una probabilidad a cada subconjunto de \\(U\\) de tama√±o \\(n\\). En este sentido, es posible definir diferentes tipos de dise√±o, entre ellos los mas comunes:.\n\nDise√±o Aleatorio Simple (SI)\n\nEl dise√±o aleatorio simple es el dise√±o m√°s sencillo y se define de la siguiente forma:\n\\[\np(s) = \\frac{1}{\\binom{N}{n}}\n\\]\nDonde \\(\\binom{N}{n}\\) es el n√∫mero de subconjuntos posibles de \\(U\\) de tama√±o \\(n\\).\n\nDise√±o Bernoulli (BE)\n\nEl (BE) es un dise√±o sencillo que se utiliza cuando se desea seleccionar una muestra de un universo de tama√±o \\(N\\) adem√°s de considerar una una probabilidad de inclusi√≥n \\(\\pi\\) para cada elemento de \\(U\\). Se define el dise√±o Bernoulli de la siguiente forma:\n\\[\np(s) = \\underbrace{\\pi \\times \\pi \\times \\cdots \\times \\pi}_{n_{s}} \\times \\underbrace{(1-\\pi) \\times (1-\\pi) \\times \\cdots \\times (1-\\pi)}_{N-n_{s}} = \\pi ^{n_{s}} (1-\\pi)^{N-n_{s}}\n\\]\nUna diferencia fundamental entre el dise√±o (BE) y el dise√±o SI es que en el BE el tama√±o de muestra es aleatorio y su distribuci√≥n es binomial, mientras que en el dise√±o SI el tama√±o de muestra es fijo.\n\nDise√±o Estratificado (ST)\n\nEl dise√±o estratificado es un dise√±o que se utiliza cuando se desea seleccionar una muestra de tama√±o \\(n\\) de un universo de tama√±o \\(N\\) donde adem√°s se quiere dividir el universo en \\(H\\) estratos \\(U_{1}, U_{2}, \\cdots, U_{H}\\). Dentro de cada estrato se selecciona una muestra de tama√±o \\(n_{h}\\) y se define el dise√±o estratificado de la siguiente forma:\n\\[\np(s) = \\prod_{l=1}^{H} p(s_{H})\n\\]\nEn cada estrato se puede utilizar un dise√±o diferente pero en general se utiliza el dise√±o SI, mas conocido STSI (Stratified Simple Random Sampling). En este caso cada \\(p_{h}(s_{h})\\) es el dise√±o aleatorio simple en el estrato \\(h\\).\n\n\n2.1.2 Probabilidades de inclusi√≥n y estimador de Horvitz-Thompson\nUna vez definido el concepto de dise√±o muestral es posible definir la probabilidad de que un elemento de la poblaci√≥n sea seleccionado en la muestra, esta probabilidad se conoce como probabilidad de inclusi√≥n y se define de la siguiente forma:\n\nProbabilidad de inclusi√≥n de primer orden\n\n\\[\n\\pi_{k} = Pr(u_{k} \\in s) = Pr(I_{k} = 1)\n\\]\nDonde \\(I_{k}\\) es una variable aleatoria que toma el valor de 1 si el elemento \\(u_{k}\\) es seleccionado en la muestra y 0 en caso contrario. Definir estas variables indicadoras son de utilizada para entender el comportamiento de los estimadores bajo el dise√±o muestral y nos permite definir los estimaodres en \\(U\\) y no en \\(S\\). Es claro que \\(I_{k} \\sim Bernoulli(\\pi_{k})\\) y \\(E(I_{k}) = Pr(I_{k}) = \\pi_{k}\\).\nEsta probabilidad es importante ya que es la la base para la construcci√≥n de estimadores insesgados y eficientes, en este sentido, es posible definir el estimador de Horvitz-Thompson (HT) para estimar un total \\(t = \\sum_{U} {t_{k}}\\) de la siguiente forma:\n\\[\n\\hat{t}_{y} = \\sum_{k=1}^{N} \\frac{y_{k}}{\\pi_{k}} \\times I_{k}\n\\]\nEste estimador es propuesto por Horvitz y Thompson en 1952 y es un estimador insesgado en el dise√±o, en el sentido de que \\(E(\\hat{t}_{y}) = t\\) y es eficiente en el sentido de que \\(Var(\\hat{t}_{y})\\) es el menor posible entre los estimadores insesgados. Este estimador es muy utilizado en la pr√°ctica y es la base para la construcci√≥n de otros estad√≠sticos,como medias, proporciones, varianzas, entre otros. Para mas detalles sobre las propiedades de Horvitz-Thompson (HT) se puede consultar en (S√§rndal et¬†al., 2003) y (Horvitz & Thompson, 1952).\n\n\n2.1.3 Ponderaci√≥n basada en el dise√±o y estimadores m√°s comunes\nEn general es utilizado el concepto de ponderador para realizar estimaciones de totales, medias, proporciones, varianzas, entre otros. En este sentido, es posible definir el ponderador inducido por el dise√±o muestral de la siguiente forma:\n\\[\nw_{k} = \\frac{1}{\\pi_{k}}\n\\]\nEste ponderador puede interpretarse como el n√∫mero individuos que representra el individuo \\(k\\) en la poblaci√≥n. Este valor es el que comunmente se publica junto a los microdatos y el estandar en los diferentes softwares para procesar encuestas. Junto al estimador de un total es posible definir el estimador de un promedio, proporci√≥n o raz√≥n en el contexto de la $-expansi√≥n.\n\nEstimador de un promedio\n\\[\n\\hat{\\bar{y}} = \\frac{\\sum_{k=1}^{N} w_{k} I_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}}\n\\]\nEste estimador puede ser utilizados en encuestas de hogares, donde se desea estimar el ingreso promedio de los hogares de una regi√≥n de forma anual, o mensual.\n\n\nEstimador de una proporci√≥n\n\\[\n\\hat{p} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\hat{N}}\n\\]\nPuede ser de inter√©s estimar la proporci√≥n de hogares que tienen acceso a internet en una regi√≥n, en este caso se puede utilizar el estimador de proporci√≥n.\n\n\nEstimador de una raz√≥n\nSe quiere estimar la raz√≥n \\(R = \\frac{\\sum_{k=1}^{N} y_{k}}{\\sum_{k=1}^{N} z_{k}}\\). En este caso se puede definir el estimador de la raz√≥n de la siguiente forma:\n\\[\n\\hat{R} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k}z_{k}} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\hat{N}}\n\\]\nEl estimador de raz√≥n es utilizado para constuir variables de mercado de trabajo como la tasa de desempleo, tasa de ocupaci√≥n, entre otros.\n\n\nInferencia sobre el tama√±o de la poblaci√≥n\nUna vez definidos los estimadores, podemos ver que los estimaodres de medias y proporciones son un caso particular del estimador de raz√≥n. Un detalle no menor es que asumimos \\(N\\) fijo pero desconocido, por esto al realizar proporciones se ajusta el total sobre un estimador del tama√±o de la poblaci√≥n:\n\\[\n\\hat{N} = \\sum_{k=1}^{N} I_{k}w_{k}\n\\]\nExisten dise√±os denominados auto-ponderados donde por definici√≥n \\(\\sum_{k=1}^{N} w_{k} = N\\), en este caso particular el estimador de medidas y proporciones es un caso parciular del estimador de total, ya que el estad√≠stico puede definirse de la siguiente forma:\n\\[\n\\hat{\\bar{y}}_{s} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{N} = \\frac{1}{N} \\times \\sum_{k=1}^{N} I_{k} w_{k} y_{k} = a \\times \\hat{t}_{y}\n\\]\n\n\n\n2.1.4 Medidas de incertidumbre y errores est√°ndar\nSe puede medir la variabilidad de los estimadores y calcular su varianza. Esto es √∫til para entender cu√°n confiables son estos estimadores. Veamos c√≥mo se calcula la varianza de diferentes tipos de estimadores, como el total, promedio, proporci√≥n o raz√≥n.\n\n2.1.4.1 Momentos muestrales y estimadores de varianza\nPara un estad√≠stico \\(\\theta\\), su varianza bajo un dise√±o muestral \\(p(s)\\) se define como:\n\\[\nV(\\hat{\\theta}) = E((\\theta - E(\\hat{\\theta}))^{2}) = \\sum_{s \\in S}{p(s)\\left(\\hat{\\theta}_{s} - E(\\hat{\\theta}_{s})\\right)}\n\\]\nLa forma de calcular la varianza depende del estimador \\(\\hat{\\theta}\\). Por ejemplo, para el estimador de varianza de un total, se utiliza la siguiente f√≥rmula:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k} \\times y_{k} \\times w_{k})} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k} \\times y_{k} \\times w_{k}, I_{l} \\times y_{l} \\times w_{l})}}\n\\]\nDespu√©s de simplificar, obtenemos:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k}) \\times w_{k} \\times y_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k}, I_{l}) \\times y_{k} \\times w_{k} \\times y_{l}  \\times w_{l} }}\n\\]\nDonde definimos las siguientes identidades para simplificar c√°lculos:\n\\[\nCov(I_{k}, I_{l}) = \\Delta_{kl} = \\pi_{kl} - \\pi_{k} \\times \\pi_{l}\n\\]\n\\[\n\\check{y}_{k} = y_{k} \\times w_{k}\n\\]\n\\[\n\\check{\\Delta}_{kl} = \\Delta_{kl} \\times \\frac{1}{\\pi_{kl}} = \\Delta_{kl} \\times w_{kl}\n\\]\nUna vez definida la varianza del estimador, necesitamos estimar su varianza. Para esto, utilizamos la t√©cnica de \\(\\pi\\)-expansi√≥n. Despu√©s de algunas manipulaciones algebraicas, obtenemos la varianza del estimador:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{\\check{y}_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} } = \\sum_{U}{\\sum{\\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }}\n\\]\nPodemos verificar que este estimador de varianza es insesgado con la definiciones de \\(E(I_{k}I_{l})\\) y tomando esperanzas. Es decir, se verifica que \\(E(\\hat{V}(\\hat{t}_{y})) = V(\\hat{t}_{y})\\). Al ser un estimador insesgado, su eficiencia depende del dise√±o muestral y de la varianza de los ponderadores, es decir, de la varianza de las probabilidades de inclusi√≥n. En algunos casos es donde entra en juego dividir grupos heterog√©neos en estratos o realizar muestreos en varias etapas.\nPara el caso de un estimador de un promedio, la varianza se define de la siguiente forma: \\[\nV(\\hat{\\bar{y}}) = \\frac{1}{N^{2}} \\times \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }\n\\]\nEsto es v√°lido en el caso de contar con un tama√±o de poblaci√≥n conocido, en otro caso el estimador de la media no es un estimador lineal y para calcular su varianza deben optar por m√©todos de estimaci√≥n de varianzas m√°s complejos como el de linealizaci√≥n de Taylor.\nEs importante considerar que en esta secci√≥n se presenta un caso ideal donde la muestra es obtenida de un listado perfecto de la poblaci√≥n objetivo denominado marco de muestreo. En la pr√°ctica, el marco de muestreo es imperfecto y se debe considerar la no respuesta, la cobertura y la falta de actualizaci√≥n del marco de muestreo. En general para la publicaci√≥n de microdatos se publican ponderadores los ponderadores originales sometidos a un proceso de calibraci√≥n que ajusta los ponderadores para que los totales de la muestra coincidan con los totales de la poblaci√≥n en algunas variables de control y permita mejorar el sesgo de no respuesta. El objetivo principal es crear ponderadores calibrados lo mas cercano posible a los ponderadores originales, de forma que si los ponderadores originales son insesgados, los ponderadores calibrados seran proximos a ser insesgados.\nAdem√°s de contar con ponderadores calibrados para calcular varianzas de los estimaodres HT es necesario contar con las probabilidades de inclusi√≥n de segundo orden, donde dependiendo del dise√±o este puede ser imposibles de calcular o pueden existir probabilidades de inclusi√≥n de segundo orden que sean cero. Por esto es necesario contar con diferentes estrategias de estimaci√≥n de varianzas como pueden ser el M√©todo del Ultimo Conglomerado, el M√©todo de Jackknife, el M√©todo de Bootstrap, entre otros.\nEn resumen, para realizar estimaciones puntuales ya sean totales, medias, proporciones o razones simplemente debemos ponderar los datos con los estad√≠sticos anteriormente mencionadas pero para realizar un proceso de inferencia completo se requiere calcular sus errores est√°ndar, construir intervalos de confianza y/o poder medir estabilidad de nuestros resultados. En este sentido, es importante tener al alcance herramientas que permitan realizar este tipo de c√°lculos, ya que si bien en diferentes softwares estad√≠siticos junto a la estimaci√≥n puntual se presentan los errores est√°ndar pero por defecto se asumen dise√±os sencillos como por ejemplo, el dise√±o BE donde la probabilidad de inclusi√≥n de segundo orden es sencilla de calcular y unicamente es necesario las probabilidades de inclusi√≥n de primer orden para computar estimadores del error est√°ndar, siendo un valor completamente erroneo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#desarrollo-de-paquetes-en-r",
    "href": "chapters/chapter2.html#desarrollo-de-paquetes-en-r",
    "title": "2¬† Marco conceptual",
    "section": "2.2 Desarrollo de paquetes en R",
    "text": "2.2 Desarrollo de paquetes en R\nR al ser un lenguaje de c√≥digo abierto y adem√°s cuenta con una gran comunidad de usuarios, en diferentes √°reas de investigaci√≥n, ha permitido que se desarrollen una gran cantidad de paquetes que permiten realizar diferentes tareas de an√°lisis de datos, visualizaci√≥n, modelado, entre otros. En este sentido, el desarrollo de paquetes en R es una tarea que se ha vuelto muy com√∫n entre los usuarios de R, ya que permite compartir c√≥digo, documentaci√≥n y datos de manera sencilla.\nPara casi cualquier disciplina cient√≠fica o en la industria se puede encontrar una comunidad de usuarios que desarrollan paquetes en R, en este sentido, el desarrollo de paquetes en R es una tarea que se ha vuelto muy com√∫n entre los usuarios de R y es muy sencillo de realizar. A continuaci√≥n, se presentan los conceptos b√°sicos para el desarrollo de paquetes en R.\n\n2.2.1 ¬øPor qu√© desarrollar un paquete en R?\nDesarrollar un paquete en R tiene varias ventajas, entre las cuales se pueden mencionar las siguientes:\n\nReutilizaci√≥n de c√≥digo: Es importante tener en cuenta que existe una comunidad que hace cosas similares a las que uno hace, por lo que es posible que alguien ya haya escrito una funci√≥n que uno necesita. Por lo tanto, siempre es buena buscar si existe alg√∫n paquete que ya tenga las funcionalidades que se requieren.\nCompartir c√≥digo: La comunidad de R es muy activa y siempre est√° dispuesta a compartir c√≥digo, por esta raz√≥n es que se mantienen en constante desarrollo de paquetes.\nColaboraci√≥n: El trabajo colaborativo es esencial en el desarrollo de paquetes en R, ya que permite que diferentes personas puedan aportar con nuevas funcionalidades, correcciones de errores, entre otros.\n\n\n\n2.2.2 Elementos b√°sicos de un paquete en R\nPara que nuestro conjunto de funciones, datos y documentaci√≥n sea considerado un paquete en R, es necesario que cumpla con ciertos requisitos m√≠nimos. A continuaci√≥n, se presentan los componentes m√≠nimos que debe tener un paquete en R para ser publicado en CRAN.\n\nDirectorio: Un paquete en R debe estar contenido en un directorio que contenga al menos los siguientes archivos y directorios:\n\nR/: Directorio que contiene los archivos con las funciones que se desean incluir en el paquete.\nman/: Directorio que contiene los archivos con la documentaci√≥n de las funciones que se encuentran en el directorio R/. En general se utiliza Roxygen2 (Wickham et¬†al., 2024) para generar la documentaci√≥n de las funciones.\nDESCRIPTION: Archivo que contiene la descripci√≥n del paquete, incluyendo el nombre, versi√≥n, descripci√≥n, autor, entre otros.\nNAMESPACE: Archivo que contiene la informaci√≥n sobre las funciones que se exportan y las dependencias del paquete.\nLICENSE: Archivo que contiene la licencia bajo la cual se distribuye el paquete.\nREADME.md: Archivo que contiene informaci√≥n general sobre el paquete.\n\nDocumentaci√≥n: La documentaci√≥n de las funciones es un componente esencial de un paquete en R, ya que permite que los usuarios puedan entender el funcionamiento de las funciones que se encuentran en el paquete. La documentaci√≥n de las funciones se realiza utilizando el sistema de documentaci√≥n de R, que se basa en el uso de comentarios en el c√≥digo fuente de las funciones.\nPruebas: Es importante que el paquete tenga pruebas que permitan verificar que las funciones se comportan de la manera esperada. Las pruebas se realizan utilizando el paquete testthat (Wickham, 2011) que permite realizar pruebas unitarias.\nControl de versiones: Es importante que el paquete tenga un sistema de control de versiones que permita llevar un registro de los cambios que se realizan en el paquete. El sistema de control de versiones m√°s utilizado en la comunidad de R es git.\nLicencia: Es importante que el paquete tenga una licencia que permita a los usuarios utilizar, modificar y distribuir el paquete. La licencia m√°s utilizada en la comunidad de R es la licencia MIT.\n\nEl proceso de subir un paquete a CRAN es un proceso que puede ser tedioso, ya que se deben cumplir con ciertos requisitos que son revisados por los mantenedores de CRAN, no es trivial y puede tomar tiempo, sin embargo, es un proceso que vale la pena ya que permite que el paquete sea utilizado por una gran cantidad de usuarios.\nEl proceso de chequeo fue automatizado con github actions, por lo que cada vez que se realiza un cambio en el repositorio, se ejecutan los chequeos de CRAN y se notifica si el paquete cumple con los requisitos para ser publicado en caso de que no cumpla con los requisitos se notifica el error y no puede ser incluido en la rama principal del repositorio hasta que se corrija el error.\nTodo el proceso y c√≥digo fuente del paquete se encuentra disponible en el repositorio de github del paquete. En el caso que este interesado en colaborar con el desarrollo del paquete puede consultar la gu√≠a de contribuci√≥n",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#paradigmas-de-programaci√≥n-en-r",
    "href": "chapters/chapter2.html#paradigmas-de-programaci√≥n-en-r",
    "title": "2¬† Marco conceptual",
    "section": "2.3 Paradigmas de programaci√≥n en R",
    "text": "2.3 Paradigmas de programaci√≥n en R\nR es un lenguaje de programaci√≥n que permite realizar programaci√≥n funcional y orientada a objetos, lo que permite que los usuarios puedan utilizar diferentes paradigmas de programaci√≥n para resolver problemas. A continuaci√≥n, se presentan los conceptos b√°sicos de la programaci√≥n funcional y orientada a objetos en R.\n\n2.3.1 Programaci√≥n funcional\nLa programaci√≥n funcional es un paradigma de programaci√≥n que se basa en el uso de funciones para resolver problemas. En R, las funciones son objetos de primera clase, lo que significa que se pueden utilizar como argumentos de otras funciones, se pueden asignar a variables, entre otros (Wickham, 2019, pp. 204-281). A continuaci√≥n, se presentan los conceptos b√°sicos de la programaci√≥n funcional en R.\n\nFunciones de orden superior: En R, las funciones de orden superior son funciones que toman como argumento una o m√°s funciones y/o retornan una funci√≥n. Un ejemplo de una funci√≥n de orden superior en R es la funci√≥n lapply que toma como argumento una lista y una funci√≥n y retorna una lista con los resultados de aplicar la funci√≥n a cada elemento de la lista.\nFunciones an√≥nimas: En R, las funciones an√≥nimas son funciones que no tienen nombre y se crean utilizando la funci√≥n function. Un ejemplo de una funci√≥n an√≥nima en R es la funci√≥n function(x) x^2 que toma como argumento x y retorna x^2.\nFunciones puras: En R, las funciones puras son funciones que no tienen efectos secundarios y retornan el mismo resultado para los mismos argumentos. Un ejemplo de una funci√≥n pura en R es la funci√≥n sqrt que toma como argumento un n√∫mero y retorna la ra√≠z cuadrada de ese n√∫mero.\n\nEste paradigma de programaci√≥n es muy √∫til para realizar an√°lisis de datos, ya que permite que los usuarios puedan utilizar funciones para realizar operaciones sobre los datos de manera sencilla y eficiente, dentro de metaSurvey no existe una presencia fuerte de programaci√≥n funcional, sin embargo, se utilizan algunas funciones de orden superior para realizar operaciones sobre los datos.\n\n\n2.3.2 Programaci√≥n orientada a objetos\nLa programaci√≥n orientada a objetos es un paradigma de programaci√≥n que se basa en el uso de objetos para resolver problemas. En R, los objetos son instancias de clases que tienen atributos y m√©todos (Mailund, 2017; Wickham, 2019, pp. 285-370). A continuaci√≥n, se presentan los conceptos b√°sicos de la programaci√≥n orientada a objetos en R.\n\nClases y objetos: En R, las clases son plantillas que definen la estructura y el comportamiento de los objetos y los objetos son instancias de clases. En R, las clases se definen utilizando la funci√≥n setClass y los objetos se crean utilizando la funci√≥n new.\nAtributos y m√©todos: En R, los atributos son variables que almacenan informaci√≥n sobre el estado de un objeto y los m√©todos son funciones que permiten modificar el estado de un objeto. En R, los atributos se definen utilizando la funci√≥n setClass y los m√©todos se definen utilizando la funci√≥n setMethod.\n\nDentro de metaSurvey se utiliza la programaci√≥n orientada a objetos para definir las clases de los objetos que se utilizan para representar los datos de las encuestas mediante una creaci√≥n de una clase especifica llamada Survey que permite adem√°s de almacenar los datos de la encuesta a√±adir atributos y m√©todos que permiten realizar operaciones sobre los datos de manera sencilla y eficiente.\nDe forma similar se modelan las clases Step, Recipe y Workflow elementos cruciales en el ecosistema de metaSurvey donde se definen los pasos de preprocesamiento, recetas de preprocesamiento y flujos de trabajo respectivamente. En este caso particular se utiliza el paquete R6 (Chang, 2022) que permite definir clases de manera sencilla y eficiente adem√°s de permitir la herencia de clases y la definici√≥n de m√©todos y atributos de manera sencilla.\n\n\n2.3.3 Meta-programaci√≥n\nLa meta-programaci√≥n es un paradigma de programaci√≥n que se basa en el uso de c√≥digo para manipular c√≥digo (Thomas Mailund, 2017; Wickham, 2019, pp. 373-500) . En R, la meta-programaci√≥n se realiza utilizando el sistema de metaprogramaci√≥n de R que se basa en el uso de expresiones, llamadas y funciones. A continuaci√≥n, se presentan los conceptos b√°sicos de la meta-programaci√≥n en R.\n\nExpresiones: En R, las expresiones son objetos que representan c√≥digo y se crean utilizando la funci√≥n quote. Un ejemplo de una expresi√≥n en R es la expresi√≥n quote(x + y) que representa el c√≥digo x + y.\nLlamadas: En R, las llamadas son objetos que representan la aplicaci√≥n de una funci√≥n a sus argumentos y se crean utilizando la funci√≥n call. Un ejemplo de una llamada en R es la llamada call(\"sum\", 1, 2, 3) que representa la aplicaci√≥n de la funci√≥n sum a los argumentos 1, 2 y 3.\nFunciones: En R, las funciones son objetos que representan c√≥digo y se crean utilizando la funci√≥n function. Un ejemplo de una funci√≥n en R es la funci√≥n function(x, y) x + y que representa el c√≥digo x + y.\n\n\n\n\n\nChang, W. (2022). R6: Encapsulated Classes with Reference Semantics.\n\n\nHorvitz, D. G., & Thompson, D. J. (1952). A Generalization of Sampling Without Replacement From a Finite Universe. Journal of the American Statistical Association, 47(260), 663-685. https://doi.org/10.2307/2280784\n\n\nMailund, T. (2017). Advanced Object-Oriented Programming in R: Statistical Programming for Data Science, Analysis and Finance. SPRINGER.\n\n\nS√§rndal, C.-E., Swensson, B., & Wretman, J. (2003). Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nThomas Mailund. (2017). Metaprogramming in R (1.¬™ ed.). Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804\n\n\nWickham, H. (2011). testthat: Get Started with Testing. The R Journal, 3, 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf\n\n\nWickham, H. (2019). Advanced R, Second Edition. CRC Press.\n\n\nWickham, H., Danenberg, P., Cs√°rdi, G., & Eugster, M. (2024). roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html",
    "href": "chapters/chapter3.html",
    "title": "3¬† Antecedentes",
    "section": "",
    "text": "Advertencia\n\n\n\nEste cap√≠tulo est√° en proceso de escritura. Consulte la rama de desarrollo para ver el avance del cap√≠tulo",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Antecedentes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html",
    "href": "chapters/chapter4.html",
    "title": "4¬† Metodolog√≠a",
    "section": "",
    "text": "Advertencia\n\n\n\nEste cap√≠tulo est√° en proceso de escritura. Consulte la rama de desarrollo para ver el avance del cap√≠tulo",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Metodolog√≠a</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html",
    "href": "chapters/chapter5.html",
    "title": "5¬† Resultados",
    "section": "",
    "text": "5.1 ECH\nlibrary(magrittr)\n\nmetaSurvey::set_engine(\"data.table\")\n\nEngine: data.table\n\nech_meta = metaSurvey::load_survey(\n  path = metaSurvey::load_survey_example(\"ech_2018.csv\"),\n  svy_type = \"ech\",\n  svy_edition = \"2018\",\n  svy_weight = \"pesoano\"\n)\n\nech_meta_steps = ech_meta %&gt;%\n  metaSurvey::step_recode(\n    \"pea\",\n    pobpcoac %in% 2:5 ~ 1,\n    .default = 0\n  ) %&gt;%\n  metaSurvey::step_recode(\n    \"pet\",\n    pobpcoac != 1 ~ 1,\n    .default = 0\n  ) %&gt;%\n  metaSurvey::step_recode(\n    \"po\",\n    pobpcoac == 2 ~ 1,\n    .default = 0\n  ) %&gt;%\n  metaSurvey::step_recode(\n    \"pd\",\n    pobpcoac %in% 3:5 ~ 1,\n    .default = 0\n  )\nmetaSurvey::view_graph(ech_meta_steps)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Resultados</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eaii",
    "href": "chapters/chapter5.html#eaii",
    "title": "5¬† Resultados",
    "section": "5.2 EAII",
    "text": "5.2 EAII\n\nsvy_example = metaSurvey::load_survey(\n    svy_type = \"eaii\",\n    svy_edition = \"2019-2021\",\n    svy_weight = \"w_trans\",\n    input = metaSurvey::load_survey_example(\"2019-2021.csv\"),\n    dec = \",\"\n)\n\n# as.data.frame(svy_example)\n# as.tibble(svy_example)\n\nnew_svy = svy_example %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"realiza_innovacion\",\n        B1_1_1 == 1 ~ 1,\n        B1_2_1 == 1 ~ 1,\n        B1_3_1 == 1 ~ 1,\n        B1_4_1 == 1 ~ 1,\n        B1_5_1 == 1 ~ 1,\n        B1_6_1 == 1 ~ 1,\n        B1_7_1 == 1 ~ 1,\n        B1_8_1 == 1 ~ 1,\n        B1_9_1 == 1 ~ 1,\n        .default = 0\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"sector\",\n        data.table::between(Division, 10, 33) ~ \"Industria\",\n        data.table::between(Division, 34, 99) ~ \"Servicios\",\n        Division == \"C1\" ~ \"Industria\",\n        Division == \"C2\" ~ \"Servicios\",\n        Division == \"E1\" ~ \"Servicios\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"innovativa\",\n        E1_1_1 == 1 ~ 1,\n        E1_2_1 == 1 ~ 1,\n        .default = 0\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"tipo_actividad\",\n        B1_1_1 == 1 ~ \"I + D Interna\",\n        B1_2_1 == 1 ~ \"I + D Externa\",\n        B1_3_1 == 1 ~ \"Bienes de Capital\",\n        B1_4_1 == 1 ~ \"Software\",\n        B1_5_1 == 1 ~ \"Propiedad Intelectual\",\n        B1_6_1 == 1 ~ \"Ingenier√≠a\",\n        B1_7_1 == 1 ~ \"Capacitaci√≥n\",\n        B1_8_1 == 1 ~ \"Marketing\",\n        B1_9_1 == 1 ~ \"Gesti√≥n\",\n        .default = \"Otra\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"tipo_innovacion\",\n        E1_1_1 == 1 ~ \"Producto\",\n        E1_2_1 == 1 ~ \"Proceso\",\n        .default = \"Otra\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"cant_traba_tramo\",\n        data.table::between(IG_4_1_3, 0, 4) ~ \"1\",\n        data.table::between(IG_4_1_3, 5, 19) ~ \"2\",\n        data.table::between(IG_4_1_3, 20, 99) ~ \"3\",\n        IG_4_1_3 &gt; 99 ~ \"4\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"ingreso_vta_pesos\",\n        data.table::between(IG_5_1_1_3, 0, 9942787) ~ \"1\",\n        data.table::between(IG_5_1_1_3, 9942788, 49713934) ~ \"2\", # nolint\n        data.table::between(IG_5_1_1_3, 49713935, 372854507) ~ \"3\", # nolint\n        IG_5_1_1_3 &gt; 372854507 ~ \"4\"\n    ) %&gt;%\n    metaSurvey::step_recode(\n        new_var = \"tamanio\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"1\" ~ \"Pequenias\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"2\" ~ \"Pequenias\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"1\" ~ \"Pequenias\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"2\" ~ \"Pequenias\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"3\" ~ \"Medianas\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"2\" ~ \"Medianas\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"1\" ~ \"Medianas\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"3\" ~ \"Medianas\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"3\" ~ \"Medianas\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"3\" ~ \"Grandes\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"2\" ~ \"Grandes\",\n        cant_traba_tramo == \"4\" & ingreso_vta_pesos == \"1\" ~ \"Grandes\",\n        cant_traba_tramo == \"1\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\",\n        cant_traba_tramo == \"2\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\",\n        cant_traba_tramo == \"3\" & ingreso_vta_pesos == \"4\" ~ \"Grandes\"\n    ) %&gt;%\n    metaSurvey::step_compute(\n        subsector = Division\n    )\n\nmetaSurvey::get_metadata(new_svy)\n\n‚ÑπÔ∏è  Type: eaii\nüìà Edition: 2019-2021\nüñ•Ô∏è  Engine: data.table\nüßÆ Weight: w_trans\nüîç Steps: \n  - New group: realiza_innovacion\n  - New group: sector\n  - New group: innovativa\n  - New group: tipo_actividad\n  - New group: tipo_innovacion\n  - New group: cant_traba_tramo\n  - New group: ingreso_vta_pesos\n  - New group: tamanio\n  - New variable: subsector\n\n\n\nmetaSurvey::view_graph(new_svy)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Resultados</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eph",
    "href": "chapters/chapter5.html#eph",
    "title": "5¬† Resultados",
    "section": "5.3 EPH",
    "text": "5.3 EPH\n\nph2022_3 = metaSurvey::load_survey(\n  path = metaSurvey::load_survey_example(\"eph2022_3.csv\"),\n  svy_type = \"eph\",\n  svy_edition = \"2022_3\",\n  svy_weight = \"PONDERA\"\n) %&gt;% \n  metaSurvey::step_recode(\n    \"pea\",\n    ESTADO %in% 1:2 ~ 1,\n    .default = 0\n  ) %&gt;% \n  metaSurvey::step_recode(\n    \"pet\",\n    ESTADO != 4 ~ 1,\n    .default = 0\n  ) %&gt;% \n  metaSurvey::step_recode(\n    \"po\",\n    ESTADO == 1 ~ 1,\n    .default = 0\n  ) %&gt;% \n  metaSurvey::step_recode(\n    \"pd\",\n    ESTADO == 2 ~ 1,\n    .default = 0\n  )\n\n\nmetaSurvey::view_graph(ph2022_3)",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Resultados</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html",
    "href": "chapters/chapter6.html",
    "title": "6¬† Infraestructura",
    "section": "",
    "text": "Infra\nDocker\nKubernetes\nTests\nEnv√≠o a CRAN\n\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEste cap√≠tulo est√° en proceso de escritura. Consulte la rama de desarrollo para ver el avance del cap√≠tulo",
    "crumbs": [
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Infraestructura</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html",
    "href": "chapters/chapter7.html",
    "title": "7¬† Resultados",
    "section": "",
    "text": "Advertencia\n\n\n\nEste cap√≠tulo est√° en proceso de escritura. Consulte la rama de desarrollo para ver el avance del cap√≠tulo",
    "crumbs": [
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Resultados</span>"
    ]
  }
]