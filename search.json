[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metasurvey",
    "section": "",
    "text": "Descripción del proyecto metasurvey\n\n\nEste paquete proporciona un conjunto de funciones para facilitar el análisis de datos de encuestas con diseño muestral utilizando técnicas de metaprogramación. En el paquete puedes crear pipelines de análisis reproducibles, y generar fácilmente informes y tablas. El paquete está diseñado para trabajar con el paquete survey, y es particularmente útil para diseños de encuestas complejos. El mismo fue desarrolado en el contexto del un trabajo final de grado de la Licenciatura en Estadística de la Facultad de Ciencias Económicas de la Universidad de la República.\n\n\nLa idea inicial surgió debido a la dificultad de trabajar con microdatos de encuestas cuyos formularios son extensos y complejos, y que cambian de un año a otro. Esto hace que sea difícil mantener actualizados los códigos de análisis de datos y puede llevar a errores en la interpretación de los resultados.\n\n\nAdemás, en algunos casos se requiere analizar una serie de resultados de encuestas de diferentes años, lo que hace necesario unificar los códigos de análisis para poder comparar los resultados a lo largo del tiempo y realizar análisis longitudinales. Esto puede ser caótico, especialmente cuando se tienen muchos años de encuestas. A menudo, se obtienen indicadores de forma independiente para cada año y luego se guardan los resultados en una tabla de Excel o en un archivo de texto.\n\n\nEntender cómo se codifican las variables de las encuestas puede ser muy difícil, ya que cada programa estadístico maneja los datos de manera diferente y cada usuario tiene su propio estilo de programación. Además, puede ser necesario contar con un software específico para analizar los datos de la encuesta, lo que puede ser un problema si no se dispone del mismo.\n\n\nPor lo tanto, la idea de este paquete es facilitar el análisis de datos de encuestas con diseño muestral complejo, permitiendo la creación de pipelines de análisis reproducibles y la generación de informes y tablas de forma sencilla. El paquete está diseñado para trabajar con survey y es particularmente útil para diseños de encuestas complejos.\n\n\nEl paquete proporciona funciones para facilitar la estimación de la varianza de diseños de encuestas complejos y para el análisis de estos diseños utilizando survey.\n\n\nSu desarrollo fue motivado por el portal PRISMA, un portal de datos abiertos de la Agencia Nacional de Investigación e Innovación (ANII) de Uruguay. En el portal, la sección de Innovación y Género cuenta con una serie de indicadores que provienen de encuestas por muestreo. Construir estos indicadores de forma histórica y compararlos a lo largo del tiempo es un desafío, ya que las encuestas cambian de un año a otro y los códigos de análisis deben ser actualizados, siendo transparente para el usuario final cómo se codifican las variables.\n\n\nEn 2022, se presentó una versión previa en LatinR 2022 llamada srvyuRu. Esta versión era demasiado lenta tanto en los cálculos como en la transparencia de la codificación de variables. Por lo tanto, en 2023 se decidió reescribir el paquete en su totalidad y cambiar su nombre a metasurvey, haciendo referencia a la meta-programación utilizada en conjunto con survey.\n\n\nEl paquete incluye funciones para facilitar la carga de datos de encuestas, la recodificación de variables, la estimación de la varianza de diseños de encuestas complejos, la generación de tablas y gráficos, y la creación de informes. También facilita la creación de pipelines de análisis reproducibles y la generación de informes y tablas de forma sencilla.\n\n\nLa documentación del paquete está disponible en metasurveyr.github.io/metasurvey y el código fuente en github.com/metasurveyr/metasurvey, donde se puede colaborar en el desarrollo del paquete y reportar errores.\n\n\nDurante el desarrollo del proyecto se utilizaron diversas herramientas tanto dentro como fuera de R. Dentro de R se usaron devtools para la creación del paquete, roxygen2 para la documentación, testthat para tests unitarios, pkgdown para la página web del paquete, usethis para la creación de issues y pull requests, y covr para la cobertura de tests unitarios. Fuera de R se usaron pre-commit para hooks de pre-commit, codecov para la cobertura de tests unitarios, y GitHub Actions para workflows de GitHub Actions.\n\n\nEn el futuro, se espera contar con más colaboradores para avanzar en el desarrollo del paquete y publicarlo en CRAN para que pueda ser utilizado por toda la comunidad de R. El paquete está abierto a la comunidad de R y especialmente a estudiantes de estadística con un enfoque en herramientas computacionales que quieran colaborar en su desarrollo.\n\n\nPara revisar el estado actual del proyecto, consulte el cronograma donde se pueden ver las tareas realizadas y planificadas. También hay una lista de issues donde se pueden reportar problemas.\n\n\nA diciembre de 2024, el paquete no está disponible en CRAN, pero se espera que en 2025 esté publicado en CRAN para que pueda ser utilizado por toda la comunidad de R. Mientras tanto, se puede instalar la versión de desarrollo desde el repositorio de Github con el siguiente código:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"metasurveyR/metasurvey\")",
    "crumbs": [
      "Descripción del proyecto"
    ]
  },
  {
    "objectID": "chapters/chapter1.html",
    "href": "chapters/chapter1.html",
    "title": "1  Introducción",
    "section": "",
    "text": "Las encuestas por muestreo se consolidan como instrumentos esenciales en la investigación estadística, facilitando la obtención de información detallada sobre poblaciones de interés a partir de muestras representativas. No obstante, el procesamiento y análisis de estos datos enfrentan desafíos significativos, particularmente al derivar indicadores que involucran múltiples etapas, tales como tasas de mercado laboral, ingresos salariales o índices de pobreza (Vilhuber 2020). La complejidad inherente a estos procesos puede propiciar errores y obstaculizar la reproducibilidad y transparencia de los resultados.\nEn este contexto, el presente trabajo introduce el desarrollo de metasurvey, un paquete innovador en R diseñado para simplificar y agilizar el procesamiento de encuestas por muestreo. metasurvey proporciona a científicos sociales, estadísticos y economistas una herramienta robusta para transformar microdatos en indicadores de manera transparente, flexible y reproducible. Al ofrecer funciones avanzadas para la construcción de variables sintéticas y el manejo riguroso de variables continuas, el paquete supera las limitaciones de las herramientas existentes, permitiendo a los usuarios validar y comprender el proceso de construcción de indicadores de forma modular y clara.\nEs crucial que este proceso sea accesible y comprensible para los usuarios, dado que la transformación de microdatos en indicadores demanda un conocimiento profundo de las encuestas, conocimiento que no siempre está ampliamente distribuido. A pesar de los esfuerzos previos por facilitar este procesamiento, muchas herramientas disponibles carecen de flexibilidad y transparencia, y son sensibles a cambios en la estructura y variables de las encuestas, lo que dificulta su actualización y adaptación.\nEn el ámbito de la inferencia estadística de poblaciones finitas, resulta esencial considerar la incertidumbre y los errores asociados a las estimaciones. Con frecuencia, estos aspectos son subestimados por usuarios no expertos en metodología de muestreo, lo que puede conducir a conclusiones erróneas. metasurvey aborda esta problemática al permitir obtener estimaciones puntuales y sus errores asociados de forma nativa, ofreciendo herramientas para evaluar la confiabilidad de las estimaciones mediante coeficientes de variación, intervalos de confianza y otros indicadores, sin requerir un conocimiento profundo en estimación de varianzas y técnicas de remuestreo.\nEs pertinente distinguir entre los enfoques de inferencia estadística basados en modelos (model-based inference) y aquellos fundamentados en el diseño muestral (design-based inference) (Lumley 2011). Mientras el primero asume que la población puede modelarse mediante un modelo probabilístico y se enfoca en estimar los parámetros correspondientes, el segundo considera a la población como finita y obtiene estimaciones mediante técnicas de muestreo, enfatizando la importancia del diseño muestral en las inferencias.\nAdicionalmente, el concepto de peso o ponderador desempeña un papel esencial en la estimación de varianzas y errores asociados. En estadística, existen diversas nociones de ponderadores (basado en (Lumley 2011)):\nSi bien la utilización de estos pesos permite obtener estimaciones puntuales correctas en la mayoría de los casos, el cálculo de medidas de incertidumbre como errores estándar e intervalos de confianza válidos presenta una complejidad adicional.\nActualmente, existen diversos paquetes en R orientados al análisis de encuestas por muestreo, como survey (Lumley 2024), srvyr (Freedman Ellis y Schneider 2024), gustave (Chevalier 2023), vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023) y weights. No obstante, estos no abordan el proceso de creación de variables a partir de los formularios de las encuestas, lo que obliga a los usuarios a realizar este procedimiento manualmente cada vez que desean obtener un indicador. Por otra parte, herramientas específicas para encuestas particulares, como ech (Detomasi 2020) para la Encuesta Continua de Hogares de Uruguay, eph (Kozlowski et al. 2020) para la Encuesta Permanente de Hogares de Argentina, tidycensus (Walker y Herman 2024) para el Censo de Estados Unidos y casen (Vargas 2024) para la Encuesta CASEN de Chile, presentan limitaciones en cuanto a flexibilidad y transparencia, y son sensibles a cambios en la estructura de las encuestas.\nEn países como Uruguay, numerosos portales de datos abiertos o monitores de indicadores publican estadísticas derivadas de encuestas por muestreo sin detallar el proceso de construcción o recodificación de los indicadores, lo que dificulta la reproducibilidad y transparencia de los análisis. Esta situación es similar en artículos académicos que, al trabajar con datos de encuestas, no especifican la metodología empleada en la obtención de los resultados, limitándose a referenciar la fuente de datos.\nEs fundamental que los usuarios puedan obtener estimaciones puntuales y sus errores asociados de manera sencilla y confiable. Es común que se utilicen estimaciones puntuales sin una medida de incertidumbre o, en el peor de los casos, que se incorporen estimaciones del error estándar sin considerar el diseño muestral correcto, lo que puede llevar a conclusiones erróneas sobre la variabilidad de la estimación. metasurvey permite superar estas limitaciones al proporcionar herramientas integrales para el cálculo seguro y transparente de estimaciones y sus errores asociados.\nEl desarrollo de un paquete en R como metasurvey requiere una idea bien definida y los medios adecuados para llevarla a cabo. Es vital contar con una metodología de trabajo ordenada, heredada del desarrollo de software convencional, ya que para la publicación y difusión del paquete se deben cumplir estrictos estándares de calidad y documentación. En este sentido, metasurvey ha sido desarrollado siguiendo las mejores prácticas de desarrollo de software, incorporando conceptos avanzados de programación orientada a objetos, programación funcional y metaprogramación para brindar flexibilidad y potencia al usuario.\nEl enfoque que permite la flexibilidad en la construcción de indicadores es la metaprogramación. Este paradigma de programación posibilita que un programa modifique su propia estructura en tiempo de ejecución. En R, la metaprogramación se implementa a través de funciones como eval(), parse(), substitute(), do.call() y quote(), que permiten evaluar y manipular código de manera dinámica. metasurvey utiliza la metaprogramación para ofrecer funciones de alto nivel que facilitan la transformación de microdatos en indicadores. En particular, se ha adoptado una aproximación similar a la del paquete recipes de la librería tidymodels (Kuhn, Wickham, y Hvitfeldt 2024), donde se emplean “recipes” y “steps” para definir secuencias de operaciones de preprocesamiento de datos.\nEn metasurvey, una recipe encapsula una serie de transformaciones a aplicar sobre los datos. Cada step representa una transformación específica, permitiendo a los usuarios construir pipelines de procesamiento modulares y fácilmente comprensibles. Esta estructura proporciona una gran flexibilidad, ya que se pueden añadir, modificar o eliminar steps según sea necesario, adaptándose a distintos tipos de encuestas y requerimientos analíticos.\nEste documento se estructura de la siguiente manera: en el siguiente capítulo se presenta un marco conceptual detallado sobre el muestreo de poblaciones finitas y los paradigmas de programación utilizados en el desarrollo de metasurvey, incluyendo una explicación más profunda sobre el uso de recipes y steps en la metaprogramación. Posteriormente, se profundiza en los antecedentes relacionados con metodologías de estimación de varianzas y se examinan otros paquetes en R que han servido de base para su creación. Finalmente, se ofrecen ejemplos prácticos de cómo utilizar metasurvey para construir indicadores de mercado laboral a partir de los microdatos de la ECH y, para demostrar su flexibilidad, se incluye un ejemplo con la EPH. 1",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#footnotes",
    "href": "chapters/chapter1.html#footnotes",
    "title": "1  Introducción",
    "section": "",
    "text": "Este documento puede leerse en su formato de página web o en su formato de documento PDF. Tanto el código fuente del paquete como el de este documento se encuentran disponibles públicamente en los repositorios de GitHub. Para la realización de este documento se utilizó quarto (Publishing 2024), que permite escribir texto junto con código R.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html",
    "href": "chapters/chapter2.html",
    "title": "2  Marco teórico",
    "section": "",
    "text": "2.1 Inferencia en muestreo de poblaciones finitas\nEste capítulo desarrolla el fundamento teórico esencial para la comprensión de la inferencia estadística en el contexto de muestreo de poblaciones finitas, un pilar fundamental en la generación de indicadores sociales y estadística oficial. Se presenta una progresión sistemática y rigurosa desde los conceptos fundamentales hasta las técnicas más sofisticadas de estimación de varianza, con especial énfasis en su aplicación práctica en encuestas socioeconómicas complejas.\nEl marco teórico se estructura en tres componentes principales interrelacionados:\nEsta base teórica rigurosa resulta fundamental no solo para comprender la implementación de los métodos de estimación de varianza en el paquete metasurvey, sino también para garantizar la validez estadística y robustez de las inferencias realizadas.\nLas encuestas por muestreo constituyen el pilar metodológico para la construcción de indicadores socio-demográficos y económicos en la estadística oficial contemporánea. La inferencia en este contexto demanda no solo estimaciones puntuales precisas, sino también una cuantificación rigurosa de su variabilidad e incertidumbre asociada, elementos esenciales para establecer la confiabilidad y validez de las estimaciones y permitir una inferencia estadística robusta fundamentada en principios matemáticos sólidos.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "href": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "title": "2  Marco teórico",
    "section": "",
    "text": "2.1.1 Diseño muestral\nEl diseño muestral representa la piedra angular del proceso inferencial en poblaciones finitas, constituyendo el mecanismo probabilístico que determina la selección de unidades muestrales y, consecuentemente, las propiedades estadísticas fundamentales de los estimadores derivados.\nLa definición matemática se basa en que dado un universo \\(U\\) de \\(N\\) elementos (puede ser conocido o no) \\(\\{u_{1},u_{2}, \\cdots, u_{N}\\}\\) y se considera un conjunto de tamaño \\(n\\) de elementos de \\(U\\) que se denota como \\(s = \\{u_{1},u_{2}, \\cdots, u_{n}\\}\\) al cual comúnmente denominamos muestra, el diseño muestral puede definirse de la siguiente forma:\n\\[\nPr(S = s) = p(s)\n\\]\nRealizando un poco de inspección en la definición anterior se puede observar que el diseño muestral es una función de probabilidad que asigna una probabilidad a cada subconjunto de \\(U\\) de tamaño \\(n\\). En este sentido, es posible definir diferentes tipos de diseño, entre ellos los más comunes:.\n\nDiseño Aleatorio Simple (SI)\n\nEl diseño aleatorio simple es el diseño más sencillo y se define de la siguiente forma:\n\\[\np(s) = \\frac{1}{\\binom{N}{n}}\n\\]\nEjemplo: Si se tiene una población de 1000 individuos y se desea seleccionar una muestra de 100 de manera aleatoria, cada combinación de 100 individuos tiene la misma probabilidad de ser seleccionada.\n\nDiseño Bernoulli (BE)\n\nEl (BE) es un diseño sencillo que se utiliza cuando se desea seleccionar una muestra de un universo de tamaño \\(N\\) además de considerar una probabilidad de inclusión \\(\\pi\\) para cada elemento de \\(U\\). Se define el diseño Bernoulli de la siguiente forma:\n\\[\np(s) = \\underbrace{\\pi \\times \\pi \\times \\cdots \\times \\pi}_{n_{s}} \\times \\underbrace{(1-\\pi) \\times (1-\\pi) \\times \\cdots \\times (1-\\pi)}_{N-n_{s}} = \\pi ^{n_{s}} (1-\\pi)^{N-n_{s}}\n\\]\nUna diferencia fundamental entre el diseño (BE) y el diseño SI es que en el BE el tamaño de muestra es aleatorio y su distribución es binomial, mientras que en el diseño SI el tamaño de muestra es fijo.\n\nDiseño Estratificado (ST)\n\nEl diseño estratificado es un diseño que se utiliza cuando se desea seleccionar una muestra de tamaño \\(n\\) de un universo de tamaño \\(N\\) donde además se quiere dividir el universo en \\(H\\) estratos \\(U_{1}, U_{2}, \\cdots, U_{H}\\). Dentro de cada estrato se selecciona una muestra de tamaño \\(n_{h}\\) y se define el diseño estratificado de la siguiente forma:\n\\[\np(s) = \\prod_{l=1}^{H} p(s_{H})\n\\]\nEn cada estrato se puede utilizar un diseño diferente pero en general se utiliza el diseño SI, más conocido STSI (Stratified Simple Random Sampling). En este caso cada \\(p_{h}(s_{h})\\) es el diseño aleatorio simple en el estrato \\(h\\).\n\n\n2.1.2 Probabilidades de Inclusión y el Estimador de Horvitz-Thompson\nUna vez definido el concepto de diseño muestral es posible definir la probabilidad de que un elemento de la población sea seleccionado en la muestra, esta probabilidad se conoce como probabilidad de inclusión y se define de la siguiente forma:\n\nProbabilidad de inclusión de primer orden\n\n\\[\n\\pi_{k} = Pr(u_{k} \\in s) = Pr(I_{k} = 1)\n\\]\nDonde \\(I_{k}\\) es una variable aleatoria que toma el valor de 1 si el elemento \\(u_{k}\\) es seleccionado en la muestra y 0 en caso contrario. Definir estas variables indicadoras son de utilidad para entender el comportamiento de los estimadores bajo el diseño muestral y nos permite definir los estimadores en \\(U\\) y no en \\(S\\). Es claro que \\(I_{k} \\sim Bernoulli(\\pi_{k})\\) y \\(E(I_{k}) = Pr(I_{k}) = \\pi_{k}\\).\nEsta probabilidad es importante ya que es la la base para la construcción de estimadores insesgados y eficientes, en este sentido, es posible definir el estimador de Horvitz-Thompson (HT) para estimar un total \\(t = \\sum_{U} {t_{k}}\\) de la siguiente forma:\n\\[\n\\hat{t}_{y} = \\sum_{k=1}^{N} \\frac{y_{k}}{\\pi_{k}} \\times I_{k}\n\\]\nEste estimador es propuesto por Horvitz y Thompson en 1952 y es un estimador insesgado en el diseño, en el sentido de que \\(E(\\hat{t}_{y}) = t\\) y es eficiente en el sentido de que \\(Var(\\hat{t}_{y})\\) es el menor posible entre los estimadores insesgados. Este estimador es muy utilizado en la práctica y es la base para la construcción de otros estadísticos, como medias, proporciones, varianzas, entre otros. Para más detalles sobre las propiedades de Horvitz-Thompson (HT) se puede consultar en (Särndal, Swensson, y Wretman 2003) y (Horvitz y Thompson 1952).\n\n\n2.1.3 Ponderación basada en el diseño y estimadores más comunes\nEn general es utilizado el concepto de ponderador para realizar estimaciones de totales, medias, proporciones, varianzas, entre otros. En este sentido, es posible definir el ponderador inducido por el diseño muestral de la siguiente forma:\n\\[\nw_{k} = \\frac{1}{\\pi_{k}}\n\\]\nEste ponderador puede interpretarse como el número individuos que representa el individuo \\(k\\) en la población. Este valor es el que comúnmente se publica junto a los microdatos y el estándar en los diferentes softwares para procesar encuestas. Junto al estimador de un total es posible definir el estimador de un promedio, proporción o razón en el contexto de la \\(\\pi\\)-expansión.\n\nEstimador de un promedio\n\\[\n\\hat{\\bar{y}} = \\frac{\\sum_{k=1}^{N} w_{k} I_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}}\n\\]\nEste estimador puede ser utilizados en encuestas de hogares, donde se desea estimar el ingreso promedio de los hogares de una región de forma anual, o mensual.\n\n\nEstimador de una proporción\n\\[\n\\hat{p} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\hat{N}}\n\\]\nPuede ser de interés estimar la proporción de hogares que tienen acceso a internet en una región, en este caso se puede utilizar el estimador de proporción.\n\n\nEstimador de una razón\nSe quiere estimar la razón \\(R = \\frac{\\sum_{k=1}^{N} y_{k}}{\\sum_{k=1}^{N} z_{k}}\\). Siendo \\(z_{k}\\) otra variable dentro del conjunto de datos. En este caso se puede definir el estimador de la razón de la siguiente forma:\n\\[\n\\hat{R} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k}z_{k}}\n\\]\nEl estimador de razón es utilizado para construir variables de mercado de trabajo como la tasa de desempleo, tasa de ocupación, entre otros.\n\n\nInferencia sobre el tamaño de la población\nUna vez definidos los estimadores, podemos ver que los estimadores de medias y proporciones son un caso particular del estimador de razón. Un detalle no menor es que asumimos \\(N\\) fijo pero desconocido, por esto al realizar proporciones se ajusta el total sobre un estimador del tamaño de la población:\n\\[\n\\hat{N} = \\sum_{k=1}^{N} I_{k}w_{k}\n\\]\nExisten diseños denominados auto-ponderados donde por definición \\(\\sum_{k=1}^{N} w_{k} = N\\), en este caso particular el estimador de medidas y proporciones es un caso particular del estimador de total, ya que el estadístico puede definirse de la siguiente forma:\n\\[\n\\hat{\\bar{y}}_{s} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{N} = \\frac{1}{N} \\times \\sum_{k=1}^{N} I_{k} w_{k} y_{k} = a \\times \\hat{t}_{y}\n\\]\n\n\n\n2.1.4 Medidas de incertidumbre y errores estándar\nSe puede medir la variabilidad de los estimadores y calcular su varianza. Para detalles completos de los cálculos de varianza, consulte el Apéndice A.\n\n2.1.4.1 Momentos muéstrales y estimadores de varianza\nPara un estadístico \\(\\theta\\), su varianza bajo un diseño muestral \\(p(s)\\) se define como:\n\\[\nV(\\hat{\\theta}) = E((\\theta - E(\\hat{\\theta}))^{2}) = \\sum_{s \\in S}{p(s)\\left(\\hat{\\theta}_{s} - E(\\hat{\\theta}_{s})\\right)}\n\\]\nLa forma de calcular la varianza depende del estimador \\(\\hat{\\theta}\\). Por ejemplo, para el estimador de varianza de un total, se utiliza la siguiente fórmula:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k} \\times y_{k} \\times w_{k})} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k} \\times y_{k} \\times w_{k}, I_{l} \\times y_{l} \\times w_{l})}}\n\\]\nDespués de simplificar, obtenemos:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k}) \\times w_{k} \\times y_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k}, I_{l}) \\times y_{k} \\times w_{k} \\times y_{l}  \\times w_{l} }}\n\\]\nDonde definimos las siguientes identidades para simplificar cálculos:\n\\[\nCov(I_{k}, I_{l}) = \\Delta_{kl} = \\pi_{kl} - \\pi_{k} \\times \\pi_{l}\n\\]\n\\[\n\\check{y}_{k} = y_{k} \\times w_{k}\n\\]\n\\[\n\\check{\\Delta}_{kl} = \\Delta_{kl} \\times \\frac{1}{\\pi_{kl}} = \\Delta_{kl} \\times w_{kl}\n\\]\nUna vez definida la varianza del estimador, necesitamos estimar su varianza. Para esto, utilizamos la técnica de \\(\\pi\\)-expansión. Después de algunas manipulaciones algebraicas, obtenemos la varianza del estimador:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{\\check{y}_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} } = \\sum_{U}{\\sum{\\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }}\n\\]\nPodemos verificar que este estimador de varianza es insesgado con las definiciones de \\(E(I_{k}I_{l})\\) y tomando esperanzas. Es decir, se verifica que \\(E(\\hat{V}(\\hat{t}_{y})) = V(\\hat{t}_{y})\\). Al ser un estimador insesgado, su eficiencia depende del diseño muestral y de la varianza de los ponderadores, es decir, de la varianza de las probabilidades de inclusión. En algunos casos, es donde entra en juego dividir grupos heterogéneos en estratos o realizar muestreos en varias etapas.\nPara el caso de un estimador de un promedio, la varianza se define de la siguiente forma: \\[\nV(\\hat{\\bar{y}}) = \\frac{1}{N^{2}} \\times \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }\n\\]\nEsto es válido en el caso de contar con un tamaño de población conocido. En otro caso, el estimador de la media no es un estimador lineal y para calcular su varianza deben optarse por métodos de estimación de varianzas alternativos como el de linealización de Taylor.\nEs importante considerar que en esta sección se presenta un caso ideal donde la muestra es obtenida de un listado perfecto de la población objetivo denominado marco muestral. En la práctica, el marco muestral es imperfecto y se debe considerar la no respuesta, la cobertura y la falta de actualización del marco. En general, los microdatos publicados incluyen ciertos ponderadores que no son precisamente los ponderadores originales definidos en la sección anterior, sino que son sometidos a un proceso de calibración donde se intenta ajustar a ciertas variables de control y mejorar problemas causados por la no respuesta. Al realizar el proceso de calibración, los ponderadores calibrados son lo más cercano posible a los ponderadores originales, de forma que si los ponderadores originales son insesgados, los ponderadores calibrados serán próximos a ser insesgados.\nEn la práctica, para diseños complejos no se dispone de las probabilidades de selección de segundo orden, insumo principal para calcular los errores estándar como se expuso en las formulaciones anteriores. Por esto, se requiere optar por metodologías alternativas como el método del último conglomerado, método de replicación jackknife, método de bootstrap, entre otros. En este sentido, es importante tener en cuenta que la varianza de los estimadores es un componente fundamental para realizar inferencias y cuantificar la confiabilidad de los resultados.\nEn resumen, para realizar estimaciones puntuales ya sean totales, medias, proporciones o razones, simplemente debemos ponderar los datos con los estadísticos anteriormente mencionados. Pero para realizar un proceso de inferencia completo se requiere calcular sus errores estándar, construir intervalos de confianza y/o poder medir la estabilidad de nuestros resultados. En este sentido, es importante tener al alcance herramientas que permitan realizar este tipo de cálculos, ya que en diferentes softwares estadísticos junto a la estimación puntual se presentan los errores estándar asumiendo diseños sencillos ya sea por omisión del usuario o por limitaciones de los paquetes estadísticos.\nEn base a lo expuesto en la sección anterior, es posible definir los errores estándar de los estimadores de forma teórica. Sin embargo, en la práctica, la estimación de la varianza de los estimadores es un problema complejo, especialmente en diseños de muestreo multietápicos y complejos. En estos casos, las probabilidades de inclusión de segundo orden son difíciles de calcular y se requieren métodos alternativos para estimar la varianza de los estimadores.\nCada estimador tiene asociado un error estándar que permite cuantificar la variabilidad de la estimación, debido a que la muestra es aleatoria esta medida es una variable aleatoria. Dentro de la incertidumbre puede separarse en errores muestrales y no muestrales. Los primeros refieren a la variabilidad de la estimación debido a la selección de la muestra y los segundos refieren a la variabilidad de la estimación debido a errores de medición, errores de no respuesta, entre otros (Särndal, Swensson, y Wretman 2003).\nEn este trabajo se centra en la estimación de los errores muestrales, ya que los errores no muestrales son difíciles de cuantificar. Los errores muestrales se pueden cuantificar mediante la varianza de la estimación. Esta varianza depende del diseño muestral ya que, como se mencionó anteriormente, el diseño muestral induce propiedades estadísticas claves como la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. El paquete survey permite estimar la varianza de la estimación de forma sencilla y eficiente, sin embargo, en algunos casos la estimación de la varianza no es correcta, ya que el paquete survey asume un muestreo simple con probabilidades de inclusión desiguales y con reposición, es decir, con una fracción de muestreo \\(f = \\frac{n}{N} \\approx 0\\) (Lumley 2004).\nPara diseños multietápicos, las probabilidades de segundo orden son muy complejas de calcular, por lo que una estimación directa no es muy factible. Además, estos ponderadores no son exactamente los pesos muestrales definidos en los capítulos anteriores, ya que se ajustan para tener en cuenta la no respuesta y la calibración, lo cual permite una estimación más precisa de ciertas variables de interés. En el caso de que se cuente con un mecanismo para obtener las probabilidades de inclusión de segundo orden, este no tendría en cuenta el proceso posterior de calibración, por lo que la estimación de la varianza no sería correcta.\nEn general, para este tipo de casos se utilizan principalmente las siguientes estrategias: el método del último conglomerado, donde se asume que la variabilidad proviene únicamente de la selección en la primera etapa, y métodos de remuestreo como el Bootstrap o Jackknife. En este trabajo se propone la implementación de forma nativa de diferentes métodos utilizando solamente un argumento al cargar la encuesta, permitiendo a usuarios no expertos en metodología de muestreo obtener estimaciones de varianzas correctas y confiables.\nAdicionalmente, para estimadores no lineales se utiliza el método de Linearización de Taylor, que permite aproximar el estimador como función de estimadores lineales. Un caso típico es la tasa de desempleo, que se calcula como el cociente entre la población desocupada y la población económicamente activa. En este caso, se puede aproximar la tasa de desempleo como función de estimadores lineales y obtener una estimación de la varianza de la tasa de desempleo o, de forma similar, un estimador de medias o proporciones.\n\n\n\n2.1.5 Métodos de remuestreo\nLa estimación del error estándar de una media u otros resúmenes poblacionales se basa en la desviación estándar de dicho estimador a través de múltiples muestras independientes. Sin embargo, en encuestas reales solo se cuenta con una muestra. El enfoque de pesos replicados ofrece una alternativa, al calcular la variabilidad del estimador a partir de múltiples subconjuntos que se comportan de manera parcialmente independiente, y luego extrapolar esta variabilidad para obtener una estimación que se asemeje a la que se obtendría si se tuvieran múltiples muestras independientes.\n\nRéplicas de Mitad de Muestra\nPara entender mejor este método, se puede considerar un diseño estratificado en el que se seleccionan dos unidades por estrato. Si se dividen los datos en dos mitades, tomando una unidad de cada estrato, se crean subconjuntos que se pueden considerar como “mitades” independientes. Si la corrección por población finita no es relevante, la varianza de un estimador basado en una mitad de muestra es aproximadamente el doble de la varianza de la muestra completa. Dado que se tienen dos mitades, se puede usar la diferencia entre sus estimaciones para calcular la varianza:\n\\[\n\\text{Var}(\\hat{\\theta}) \\approx \\frac{1}{2} (\\hat{\\theta}_A - \\hat{\\theta}_B)^2,\n\\]\ndonde \\(\\hat{\\theta}_A\\) y \\(\\hat{\\theta}_B\\) son las estimaciones de cada mitad de la muestra. Este enfoque es sencillo pero puede ser inestable, por lo que se suelen usar múltiples conjuntos de divisiones para obtener un promedio más preciso.\n\n\nBalanced Repeated Replication (BRR)\nEl método de Balanced Repeated Replication (BRR) es una forma sistemática de elegir subconjuntos de la muestra, garantizando que cada unidad se incluya de manera equilibrada en las réplicas. Esto se logra mediante un balanceo ortogonal, donde cada observación está presente en aproximadamente la mitad de las réplicas, y cada par de unidades de diferentes estratos aparece en las réplicas de forma equilibrada. Con (K) estratos, se puede generar un conjunto de hasta (K + 4) réplicas que produzca una estimación de la varianza que es prácticamente idéntica a la que se obtendría usando todas las (2^K) combinaciones posibles.\nLa varianza utilizando BRR se calcula así:\n\\[\n\\text{Var}_{\\text{BRR}}(\\hat{\\theta}) = \\frac{1}{R} \\sum_{r=1}^R (\\hat{\\theta}_r - \\hat{\\theta})^2,\n\\]\ndonde \\(R\\) es el número de réplicas seleccionadas y \\(\\hat{\\theta}_r\\) es el estimador obtenido de cada réplica.\n\n\nPesos Replicados en Diseños Multietápicos y Complejos\nEl enfoque de pesos replicados no solo se aplica a diseños simples, sino que también se adapta a diseños de muestreo multietápicos y diseños complejos. En estos casos, la estructura de la muestra se complica, ya que puede involucrar varias etapas de selección (por ejemplo, seleccionar primero conglomerados como municipios, luego hogares dentro de los municipios, y finalmente personas dentro de los hogares). Esto hace que la varianza deba considerar la correlación entre unidades seleccionadas en cada etapa.\nPara estos diseños, se utilizan métodos como el Jackknife y el Bootstrap, que permiten manejar la estructura multietápica. Por ejemplo:\n\nEn un diseño Jackknife, se ajustan los pesos eliminando una observación o un conglomerado completo en cada réplica, y recalculando el estimador con los datos restantes. Esto puede ajustarse para considerar la estructura de estratos y conglomerados.\n\n\\[\n\\text{Var}_{\\text{Jackknife}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\theta}_i - \\hat{\\theta})^2\n\\]\ndonde (n) es el número de observaciones o conglomerados, \\(\\hat{\\theta}_i\\) es la estimación obtenida cuando se omite la \\(i\\)-ésima unidad, y \\(\\hat{\\theta}\\) es la estimación con todos los datos.\n\nEn el Bootstrap, se seleccionan subconjuntos con reemplazo de cada conglomerado, y se ajustan los pesos según el número de veces que cada unidad aparece en la réplica. Esto es especialmente útil cuando las unidades de muestreo tienen una estructura jerárquica, como es el caso de los diseños multietápicos.\n\n\\[\n\\text{Var}_{\\text{Bootstrap}}(\\hat{\\theta}) = \\frac{1}{B} \\sum_{b=1}^B (\\hat{\\theta}_b - \\hat{\\theta})^2,\n\\]\ndonde \\(B\\) es el número de réplicas y \\(\\hat{\\theta}_b\\) es el estimador obtenido en la \\(b\\)-ésima réplica.\n\n\nVentajas de los Pesos Replicados\nAunque estos métodos requieren más esfuerzo computacional comparados con métodos tradicionales como el estimador de Horvitz-Thompson, son muy versátiles. Facilitan la estimación de errores estándar para diferentes tipos de estadísticas, no solo para medias o totales, y son especialmente útiles cuando se trabaja con diseños de muestreo complejos. Además, permiten obtener errores estándar precisos para estimaciones de subpoblaciones sin necesidad de ajustes adicionales. Esto los convierte en una herramienta poderosa para el análisis de encuestas complejas, especialmente con el soporte de software estadístico moderno.\nEl paquete survey con svrep proporciona una implementación robusta de varios métodos de pesos replicados, incluyendo Balanced Repeated Replication (BRR), Jackknife, y Bootstrap. Sin embargo, el uso adecuado de estos métodos a menudo no es tan conocido por usuarios que no son expertos en muestreo. La correcta especificación del diseño y la interpretación de los resultados pueden ser complejas, especialmente en el caso de diseños de muestreo multietápicos o aquellos que requieren calibración.\nDentro de metasurvey se busca simplificar el uso de estos métodos, pudiendo especificar el tipo de réplica deseado con un solo argumento al cargar la encuesta o utilizar réplicas brindadas por la institución que publica los microdatos. Además, se busca incorporar medidas de calidad de las estimaciones como el coeficiente de variación, el error relativo y el error absoluto, para facilitar la interpretación de los resultados y la comparación entre diferentes estimaciones y subpoblaciones.\n\n\nMedidas de calidad de las estimaciones\nBrindar medidas de calidad de las estimaciones es fundamental para evaluar la confiabilidad de los resultados y comparar diferentes estimaciones. Estas medidas permiten cuantificar la precisión de los estimadores y evaluar la variabilidad de los resultados. Algunas de las medidas más comunes son el coeficiente de variación (CV) y el efecto diseño (deff), ya que en algunos casos, si bien se pueden obtener estimaciones, estas pueden no ser precisas o el tamaño de la muestra en el dominio de interés puede ser pequeño, lo que puede llevar a estimaciones poco confiables.\n\n\nHerramientas para la estimación de varianza\nSi bien para una persona con experiencia en muestreo estas medidas son familiares, para un usuario no experto, en caso de no contar con herramientas que permitan calcular estas medidas, se pueden pasar por alto. En este sentido, es importante contar con herramientas que permitan calcular estas medidas de forma sencilla y eficiente, para facilitar la interpretación de los resultados y la toma de decisiones.\nEn la actualidad, existen diferentes métodos para la estimación de varianzas. Aunque en la mayoría de los casos se utilizan métodos de remuestreo como el Bootstrap o el Jackknife, existen diferentes ideas o propuestas como se menciona en (Deville y Tille 1998) y (Deville y Tillé 2005), que demuestran con resultados numéricos que estimadores del tipo H-T bajo un diseño balanceado pueden aproximarse desde el enfoque de regresión o calibración. Además, existen estimadores alternativos que complementan métodos de remuestreo para aproximar probabilidades de inclusión de segundo orden (Escobar y Berger 2013) utilizando ciertas aproximaciones límites (Hajek 1964).\nEn este sentido, metasurvey busca ser una herramienta que permita a usuarios no expertos en muestreo realizar análisis de encuestas de manera sencilla, proporcionando una interfaz amigable y herramientas que faciliten la interpretación de los resultados. Además, busca integrar diferentes métodos de estimación de varianzas y medidas de calidad de las estimaciones, para que los usuarios puedan obtener resultados confiables y precisos, sin necesidad de ser expertos en muestreo.\nEn el Capítulo 3 se presentarán conceptos relacionados al desarrollo de paquetes en R junto a la presentación de diferentes herramientas para desarrollar paquetes. Se mencionarán paquetes que permiten realizar estimaciones de varianzas y que complementarán el paquete metasurvey así como también paquetes similares o trabajos similares en el Capítulo 4. En el Capítulo 5 se presentará cómo se han integrado los conceptos de muestreo y estimación de varianzas, en conjunto con las dependencias e implementaciones realizadas en el paquete metasurvey para facilitar el proceso de obtención de indicadores socioeconómicos y demográficos.\n\n\n\n\nDeville, Jean-Claude, y Yves Tille. 1998. «Unequal Probability Sampling Without Replacement Through a Splitting Method». Biometrika 85 (1): 89-101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, y Yves Tillé. 2005. «Variance approximation under balanced sampling». Journal of Statistical Planning and Inference 128 (2): 569-91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nEscobar, Emilio L., y Yves G. Berger. 2013. «A new replicate variance estimator for unequal probability sampling without replacement». The Canadian Journal of Statistics / La Revue Canadienne de Statistique 41 (3): 508-24. https://www.jstor.org/stable/43186201.\n\n\nHajek, Jaroslav. 1964. «Asymptotic Theory of Rejective Sampling with Varying Probabilities from a Finite Population». The Annals of Mathematical Statistics 35 (4): 1491-1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nHorvitz, D. G., y D. J. Thompson. 1952. «A Generalization of Sampling Without Replacement From a Finite Universe». Journal of the American Statistical Association 47 (260): 663-85. https://doi.org/10.2307/2280784.\n\n\nLumley, Thomas. 2004. «Analysis of Complex Survey Samples». Journal of Statistical Software 9 (abril): 1-19. https://doi.org/10.18637/jss.v009.i08.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html",
    "href": "chapters/chapter3.html",
    "title": "3  Métodos computacionales",
    "section": "",
    "text": "3.1 Desarrollo de paquetes en R\nEn este capítulo se presentan los antecedentes y conceptos aplicados en el desarrollo de metasurvey. También se abordan conceptos de investigación reproducible, la importancia de R como herramienta, la revisión de paquetes para el procesamiento de encuestas por muestreo y la relevancia del diseño muestral. Se mencionan paquetes y herramientas en las cual fue inspirado del desarrollo del paquete y paquetes similares junto a sus limitaciones.\nLa generación de indicadores sociales se ha convertido en una tarea fundamental tanto para la toma de decisiones a nivel de una empresa o país así como para la investigación. Sin embargo, este proceso puede resultar complejo, ya que requiere conocimiento específico sobre el formulario de la encuesta y formas de construir ciertos índices o variables auxiliares que no necesariamente son triviales y dependen de la experiencia del usuario. Este proceso de generación de indicadores frecuentemente carece de transparencia o documentación adecuada, en parte por la ausencia de herramientas apropiadas y en parte por la falta de una cultura de reproducibilidad, ya que generalmente solo se hace referencia a los datos y no al proceso completo de generación de los indicadores.\nR es un lenguaje de código abierto con una gran comunidad de usuarios en diversas áreas de investigación. Esto ha permitido el desarrollo de una extensa colección de paquetes que facilitan tareas de análisis de datos, visualización, bioinformática, aprendizaje automático y otras ramas afines a la estadística. El ecosistema de R se destaca por:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos computacionales</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#sec-developmentR",
    "href": "chapters/chapter3.html#sec-developmentR",
    "title": "3  Métodos computacionales",
    "section": "",
    "text": "Repositorios centralizados: CRAN (Comprehensive R Archive Network) actúa como el principal repositorio de paquetes verificados y estables. Otros repositorios especializados incluyen Bioconductor para análisis biológicos y rOpenSci para ciencia abierta (Gentle 2009).\nEstándares de calidad: Los paquetes deben pasar rigurosas verificaciones antes de ser aceptados en CRAN, incluyendo pruebas en múltiples plataformas, documentación completa y coherencia en el código.\nComunidad activa: La comunidad de R mantiene foros activos, conferencias regulares (useR!, rstudio::conf) y grupos de trabajo que continuamente mejoran el ecosistema (R Core Team 2023).\n\n\n3.1.1 ¿Por qué desarrollar un paquete en R?\nDesarrollar un paquete en R tiene varias ventajas:\n\nReutilización de código: Es posible que alguien ya haya escrito una función que uno necesita. Por lo tanto, siempre es bueno buscar si existe algún paquete que ya tenga las funcionalidades requeridas.\nCompartir código: La comunidad de R es muy activa y siempre está dispuesta a compartir código, lo que fomenta el desarrollo continuo de paquetes.\nColaboración: El trabajo colaborativo es esencial en el desarrollo de paquetes en R, permitiendo que diferentes personas aporten nuevas funcionalidades, correcciones de errores, entre otros.\n\n\n\n3.1.2 Elementos básicos de un paquete en R\nLa estructura de un paquete en R sigue convenciones estrictas que facilitan su distribución y mantenimiento. Los componentes esenciales incluyen:\n\nEstructura de directorios:\n\nR/: Código fuente en R\nman/: Documentación en formato .Rd\nsrc/: Código en otros lenguajes (C++, Fortran)\ntests/: Pruebas unitarias\ndata/: Conjuntos de datos\nvignettes/: Tutoriales y ejemplos extensos\n\nArchivos de control:\n\nDESCRIPTION: Metadatos del paquete\nNAMESPACE: Control de exportación de funciones\nLICENSE: Términos de uso y distribución\n.Rbuildignore: Archivos excluidos del build\n\nControl de versiones:\n\nSistema de versionado semántico (MAJOR.MINOR.PATCH)\nIntegración con Git/GitHub\nRegistro de cambios en NEWS.md\n\n\n\nDocumentación: Es esencial para que los usuarios puedan entender el funcionamiento de las funciones del paquete. Se realiza utilizando el sistema de documentación de R, basado en comentarios en el código fuente.\nPruebas: Es importante que el paquete tenga pruebas que verifiquen que las funciones se comportan como se espera. Las pruebas se realizan utilizando el paquete testthat (Wickham 2011a).\nControl de versiones: Permite llevar un registro de los cambios realizados en el paquete. El sistema de control de versiones más utilizado en la comunidad de R es git.\nLicencia: Permite a los usuarios utilizar, modificar y distribuir el paquete. La licencia más utilizada en la comunidad de R es la licencia MIT.\n\nEl proceso de subir un paquete a CRAN puede ser tedioso, ya que se deben cumplir ciertos requisitos revisados por los mantenedores de CRAN. Sin embargo, es un proceso que vale la pena, ya que permite que el paquete sea utilizado por una gran cantidad de usuarios.\nEl proceso de chequeo fue automatizado con GitHub Actions, por lo que cada vez que se realiza un cambio en el repositorio, se ejecutan los chequeos de CRAN y se notifica si el paquete cumple con los requisitos para ser publicado. En caso de que no cumpla con los requisitos, se notifica el error y no puede ser incluido en la rama principal del repositorio hasta que se corrija.\nTodo el proceso y código fuente del paquete se encuentra disponible en el repositorio de GitHub del paquete. Si está interesado en colaborar con el desarrollo del paquete, puede consultar la guía de contribución.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos computacionales</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#paradigmas-de-programación-en-r",
    "href": "chapters/chapter3.html#paradigmas-de-programación-en-r",
    "title": "3  Métodos computacionales",
    "section": "3.2 Paradigmas de programación en R",
    "text": "3.2 Paradigmas de programación en R\nR es un lenguaje de programación que permite realizar programación funcional y orientada a objetos (Chambers 2014), lo que permite que los usuarios puedan utilizar diferentes paradigmas de programación para resolver problemas. A continuación, se presentan los conceptos básicos de la programación funcional y orientada a objetos en R.\n\n3.2.1 Programación funcional\nLa programación funcional es un paradigma de programación que se basa en el uso de funciones para resolver problemas. En R, las funciones son objetos de primera clase, lo que significa que se pueden utilizar como argumentos de otras funciones, se pueden asignar a variables, entre otros (Wickham 2019, 204-81). A continuación, se presentan los conceptos básicos de la programación funcional en R.\n\nFunciones de orden superior: En R, las funciones de orden superior son funciones que toman como argumento una o más funciones y/o retornan una función. Un ejemplo de una función de orden superior en R es la función lapply que toma como argumento una lista y una función y retorna una lista con los resultados de aplicar la función a cada elemento de la lista.\nFunciones anónimas: En R, las funciones anónimas son funciones que no tienen nombre y se crean utilizando la función function. Un ejemplo de una función anónima en R es la función function(x) x^2 que toma como argumento x y retorna x^2.\nFunciones puras: En R, las funciones puras son funciones que no tienen efectos secundarios y retornan el mismo resultado para los mismos argumentos. Un ejemplo de una función pura en R es la función sqrt que toma como argumento un número y retorna la raíz cuadrada de ese número.\n\nEste paradigma de programación es muy útil para realizar análisis de datos, ya que permite que los usuarios puedan utilizar funciones para realizar operaciones sobre los datos de manera sencilla y eficiente. Dentro de metasurvey no existe una presencia fuerte de programación funcional, sin embargo, se utilizan algunas funciones de orden superior para realizar operaciones sobre los datos.\n\n\n3.2.2 Programación orientada a objetos\nLa programación orientada a objetos es un paradigma de programación que se basa en el uso de objetos para resolver problemas. En R, los objetos son instancias de clases que tienen atributos y métodos (Wickham 2019, 285-370; Mailund 2017). A continuación, se presentan los conceptos básicos de la programación orientada a objetos en R.\n\nClases y objetos: En R, las clases son plantillas que definen la estructura y el comportamiento de los objetos y los objetos son instancias de clases. En R, las clases mas utilizadas provienen del sistema de programación orientada a objetos llamado S3 las definen utilizando la función setClass y los objetos se crean utilizando la función new. También se pueden utilizar las clases del sistema S4 aunque este tiene una sintaxis mas compleja y no es tan utilizado.\nAtributos y métodos: En R, los atributos son variables que almacenan información sobre el estado de un objeto y los métodos son funciones que permiten modificar el estado de un objeto. En R, los atributos se definen utilizando la función setClass y los métodos se definen utilizando la función setMethod.\n\nDentro de metasurvey se utiliza la programación orientada a objetos para definir las clases de los objetos que se utilizan para representar los datos de las encuestas mediante la creación de una clase específica llamada Survey que permite, además de almacenar los datos de la encuesta, añadir atributos y métodos que permiten realizar operaciones sobre los datos de manera sencilla y eficiente.\nDe forma similar se definen las clases Step, Recipe y Survey, entre otras, elementos cruciales en el ecosistema de metasurvey donde se definen los pasos de preprocesamiento, recetas de preprocesamiento y flujos de trabajo respectivamente. En este caso particular se utiliza el paquete R6 (Chang 2022) que permite definir clases de manera intuitiva y eficiente, además de permitir la herencia de clases y la definición de métodos y atributos de manera sencilla.\n\n\n3.2.3 Meta-programación\nLa meta-programación es un paradigma de programación que se basa en el uso de código para manipular código (Wickham 2019, 373-500; Thomas Mailund 2017). En R, la meta-programación se realiza utilizando el sistema de meta-programación de R que se basa en el uso de expresiones, llamadas y funciones. A continuación, se presentan los conceptos básicos de la meta-programación en R.\n\nExpresiones: En R, las expresiones son objetos que representan código y se crean utilizando la función quote(). Un ejemplo de una expresión en R es la expresión quote(x + y) que representa el código x + y.\nLlamadas: En R, las llamadas son objetos que representan la aplicación de una función a sus argumentos y se crean utilizando la función call(). Un ejemplo de una llamada en R es la llamada call(\"sum\", 1, 2, 3) que representa la aplicación de la función sum a los argumentos 1, 2 y 3.\nFunciones: En R, las funciones son objetos que representan código y se crean utilizando la función function(). Un ejemplo se puede ver en Código 3.1.\n\n\n\n\nCódigo 3.1: Se define una función que toma dos argumentos x e y y retorna la suma de los mismos.\n\n\n\n\nCódigo\nfunction(x, y) {\n  x + y\n}\n\n\n\n\n\nEn metasurvey se utiliza la meta-programación para generar código de manera dinámica y realizar operaciones sobre los datos de manera eficiente. En particular, se utiliza la función eval() para evaluar expresiones y la función substitute() para reemplazar variables en expresiones. Además, se utilizan las funciones lapply(), sapply(), mapply() y do.call() para aplicar funciones a listas y vectores de manera eficiente. En general, la meta-programación es una técnica muy útil para realizar operaciones sobre los datos de manera eficiente y sencilla.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos computacionales</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#investigación-reproducible",
    "href": "chapters/chapter3.html#investigación-reproducible",
    "title": "3  Métodos computacionales",
    "section": "3.3 Investigación reproducible",
    "text": "3.3 Investigación reproducible\nEl concepto de investigación reproducible ha cobrado relevancia en los últimos años, tanto en la academia como en la industria y esto se debe a la fricción que puede llegar a existir al momento de presentar resultados de investigación o generación indicadores relevantes para la toma de decisiones debido al proceso de generación de los mismos. Dentro de las diferentes disciplinas generar ambientes de trabajo reproducibles puede llegar a ser un desafío, ya que en la mayoría de los casos se utilizan diferentes herramientas, lenguajes de programación y bases de datos.\nEn la actualidad existen diferentes revistas científicas que promueven la investigación reproducible, herramientas, guías para buenas prácticas para trabajar con datos y código fuente como Sumatra (Davison y Huth 2012), implementaciones de programación literal (Knuth 1984) como RMarkdown (Allaire et al. 2024) o Jupyter Notebook (Kluyver et al. 2024) y diferentes implementaciones para gestionar dependencias de software como Anaconda (Anaconda 2024), aunque algunas de ellas se han vuelto herramientas de pago o ya no existen en la actualidad, más referencias y casos de uso pueden encontrarse en (Stodden, Leisch, y Peng 2014).\nAntes de continuar es necesario definir conceptos fundamentales en el ámbito de la investigación reproducible, tales como la Reproducibilidad que refiere a la capacidad de poder obtener los mismos resultados de un estudio, experimento o un cálculo en particular. Si bien en la actualidad la reproducibilidad se incentiva en algunas revistas científicas es de suma importancia en otras instancias donde se comparten datos, se monitorean indicadores entre otro. Cuando se comparten datos o ya sea de una encuesta o datos recolectados para una investigación, rara vez se documenta y rara se menciona o explica el código fuente para hacer las transformaciones. Aún compartiendo el código fuente, esto aún no es suficiente para poder reproducir un estudio o un indicador por incompatibilidades de versiones de software, cambios en la estructura de los datos interpretaciones de los datos, estilos de programación, entre otros pudiendo llevar mucho tiempo y esfuerzo para poder replicar un resultado.\nEl proceso de tratamiento de datos y limpieza forma parte de lo que se conoce como publicaciones grises (Vilhuber 2020). Este concepto se refiere a la publicación de datos, código y reportes que no son publicaciones formales, pero son esenciales para generar conocimiento científico. En su mayoría al no tener una revisión por pares o una forma estandarizada esto se incluye de forma muy dispar o sin ningún tipo de documentación para poder ser reproducido y esto forma una gran parte de la investigación científica que no se encuentra aprovechada.\nExisten diversas iniciativas destinadas a fomentar la reproducibilidad en la ciencia, lo que ha llevado a las revistas a establecer políticas de datos y código abierto. Sin embargo, persisten desafíos en la generación de indicadores sociales, ya que como se menciono anteriormente no basta con hacer referencia a los datos, como se señala en (Bechhofer et al. 2013); además de publicar el artículo junto a los datos, es necesario vincular los objetos de investigación (Research Objects RO), existen diferentes plataformas que permiten la publicación de estos objetos como Zenodo y Figshare o OSF que permiten la integración de datos, código e interacción con repositorios con control de versiones como GitHub o GitLab.\nDe conceptos generales sobre reproducibilidad es importante contar con un flujo de trabajo (Workflow managment System (Prabhu y Fox 2020)) para la obtención de estimadores en el procesamiento de encuestas por muestreo ya que el indicador final es el resultado de una serie de pasos que se deben seguir de manera ordenada y documentada para poder ser auditados y replicados en diferentes contextos, inspirado en (Sandve et al. 2013) se pueden considerar algunas buenas prácticas para la generación de indicadores:\n\nPara cada resultado, se debe tener un respaldo de como fue construido: Al trabajar con lenguajes de programación como R, los script de código fuente son un respaldo de como obtener cierto resultado, sin embargo, esto puede estar ligado a tu estilo de programación y la versión de los paquetes que se utilizan.\nCrear manuales en la manipulación de datos: Es importante resumir cada paso por más mínimo que sea en la transformación de variables, esto permite entender todo el proceso de generación de un indicador.\nGuardar las versiones de los paquetes utilizados: Al trabajar con R, es importante guardar las versiones de los paquetes que se utilizan, esto permite que en un futuro se pueda replicar el proceso de generación de indicadores, para esto puede utilizarse herramientas como renv (Ushey y Wickham 2023) un paquete que permite crear ambientes locales con versiones específicas de paquetes de R, venv (Python Software Foundation 2024) que son ambientes virtuales en python o Docker (Merkel 2014) para poder emular un ambiente de trabajo en diferentes sistemas operativos.\nGuardar pasos intermedios, en un formato estándar: Al trabajar con encuestas por muestreo y para crear indicadores sencillos se realizan dos grandes tipos de operaciones: crear grupos o categorías o realizar operaciones matemáticas, es importante guardar estos pasos en un formato estándar para poder ser reutilizados en diferentes contextos.\nCompartir las ejecuciones y scripts: Es importante que los scripts de código fuente estén disponibles para que puedan ser auditados y replicados en diferentes contextos.\n\n\n3.3.1 Conceptos clave\nmetasurvey se basa en las buenas prácticas mencionadas anteriormente y permite crear herramientas de flujo de trabajo siguiendo los siguientes principios:\n\nReusable: Se separa el proceso de transformación de variables en Steps que refiere a transformaciones de columnas, estos procedimientos pueden ser comunes tanto en diferentes encuestas como en diferentes indicadores. Estos Steps pueden ser reutilizados en diferentes Recipes para calcular indicadores de mercados de trabajo, pobreza, e incluso aplicarlos en varias encuestas simultáneamente mediante un Workflow.\nRepetible: Al tener un proceso definido en un Workflow, es posible repetir el proceso de generación de indicadores de la misma manera y automatizar la generación de reportes.\nReferenciable y Acreditable: Al contar con un Workflow, es posible hacer referencia al proceso de generación de indicadores especificando todos los pasos seguidos y el autor o equipo que lo realizó. Además, se puede acreditar a los autores de los Steps y Recipes que se utilizaron en el proceso.\n\n\n\n3.3.2 Workflow reproducible\nEl concepto de Workflow no es nuevo y exclusivo en la comunidad científica, en la actualidad en la industria de la ciencia de datos se han desarrollado diferentes herramientas para la gestión de flujos de trabajo para el procesamiento de datos, con diferentes enfoques y objetivos. metasurvey se inspira en diferentes herramientas como Apache AirFlow («Apache Airflow Documentation», s. f.) que es una plataforma de orquestación de flujos de trabajo de código abierto, Great Expectations (Expectations 2024) que es una biblioteca de validación de datos para la generación de reportes de calidad de datos y Make que es una herramienta de automatización de flujos de trabajo que se basa en la definición de reglas y dependencias.\nEn el ámbito del aprendizaje automático existe un gran esfuerzo para poder desgranar y documentar los modelos conocido como Model Cards (Mitchell et al. 2019) donde se hace un detalle de los algoritmos utilizados, las métricas de evaluación, los datos utilizados y su procesamiento, siendo esto el análogo a los Steps y Recipes de metasurvey. Este concepto se ha extendido siendo un estándar en la industria y siendo adoptado por diferentes organizaciones como Google y Hugging Face.\nTomando en cuenta estos conceptos, metasurvey tiene disponible la posibilidad de generar, compartir y visualizar los flujos de trabajo de manera gráfica permitiendo la transparencia y auditabilidad de los procesos de generación de indicadores.\n\n\n3.3.3 Investigación reproducible en R\nDentro de CRAN existe una guía sobre conjunto de paquetes y herramientas con objetivos comunes denominado Task Views que agrupa paquetes de R que se utilizan para un propósito específico. En el Task View de Reproducible Research se encuentran diferentes paquetes que permiten la generación de reportes dinámicos, la gestión de flujos de trabajo y la generación de documentos interactivos aunque también existen herramientas para la gestión de flujos de trabajo generales como targets (Landau 2021) y drake (Landau 2018), metasurvey fue inspirado en los conceptos y la forma de trabajo de estos paquetes.\nLos conceptos de meta-programación y programación orientada a objetos fue inspirado en el paquete mlr3pipelines (Binder et al. 2021) que permite la creación de flujos de trabajo para el preprocesamiento de datos y la generación de modelos de aprendizaje automático, aquí se definen PipeOps que son operaciones que se pueden aplicar a los datos y se pueden combinar en un Graph que define el flujo de trabajo para ello se definen clases y métodos que permiten una fácil extensión por parte del usuario y la creación de flujos de trabajo complejos.\nDentro de la comunidad existen organizaciones como rOpenSci que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R. Esta organización promueve la creación de paquetes donde además de la guías sobre el desarrollo de paquetes y la revisión de los mismos, se promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación. Para formar parte de rOpenSci, se sigue una evaluación entre pares y una revisión de la calidad del paquete, además de la documentación y la calidad del código complementado con tests automatizados.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos computacionales</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#herramientas-para-el-desarrollo-de-paquetes-en-r",
    "href": "chapters/chapter3.html#herramientas-para-el-desarrollo-de-paquetes-en-r",
    "title": "3  Métodos computacionales",
    "section": "3.4 Herramientas para el desarrollo de paquetes en R",
    "text": "3.4 Herramientas para el desarrollo de paquetes en R\nCualquier usuario puede desarrollar un paquete en R, aunque existen diferentes guías y estándares para el desarrollo de paquetes en R, como se menciona en («R Packages (2e)», s. f.), además de la guía de rOpenSci (rOpenSci et al. 2024) que promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación.\nPara el desarrollo de metasurvey se utilizaron paquetes como usethis (Wickham, Bryan, et al. 2024) que permite la creación de paquetes en R, roxygen2 (Wickham, Danenberg, et al. 2024) que permite la documentación de funciones y la creación de manuales, testthat (Wickham 2011b) que permite la creación de tests automatizados, pkgdown (Wickham, Hesselberth, et al. 2024) que permite la creación de sitios web para paquetes de R, devtools (Wickham et al. 2022) que permite la instalación y la carga de paquetes en R, renv (Ushey y Wickham 2023) que permite la creación de ambientes locales con versiones especificas de paquetes de R junto a herramientas herramientas como pre-commit (Sottile y Contributors 2024) que permite la ejecución de scripts antes de realizar un commit en un repositorio de git esto con el fin de mantener la calidad del código y la documentación antes de realizar un cambio en el repositorio. De forma conjunta se utilizó GitFlow (Driessen 2010) que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git. Para la automatización de los tests en diferentes sistemas operativos se utilizó GitHub Actions (GitHub Actions: Automate Your Workflow 2024) que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov (Codecov: Code Coverage Insights 2024).\nTodo estas herramientas permiten que la creación de paquetes sea sencilla y permita a los usuarios enfocarse en la implementación con cierto grado de calidad y documentación, además de permitir la colaboración y la integración continua de los cambios en un repositorio de git.\n\nImplementación de tests automatizados\nEl paquete incluye tests automatizados creados con testthat, lo que asegura la robustez del código fuente al ser utilizado en diversos contextos. Un ejemplo es el test de la función extract_time_pattern, que analiza el nombre de una encuesta y retorna su tipo, año y periodicidad. Esta función clave utiliza expresiones regulares para manejar distintos formatos de tiempo y es fundamental para tareas como definir la edición de encuestas o emparejar réplicas bootstrap. Su implementación completa puede encontrarse aquí: extract_time_pattern.\n\n\n\nCódigo 3.2: Ejemplo de un test automatizado para verificar el correcto funcionamiento de la función extract_time_pattern.\n\n\n\n\nCódigo\ntest_that(\n  \"Probar extraer time pattern anual\",\n  {\n    testthat::expect_equal(\n      metasurvey:::extract_time_pattern(\"ECH_2023\"),\n      list(\n        type = \"ECH\",\n        year = 2023,\n        periodicity = \"Annual\"\n      )\n    )\n  }\n)\n\n\n\n\n\nAl tener una serie de test automatizados como el presentado en el código 3.2 permite que los mismos se ejecuten ante una nueva versión del código fuente y poder revisar si implementaciones anteriores funcionan de la misma manera luego de realizar estos cambios. Para el envió a CRAN se realizan estos test automático y una serie de pruebas de calidad y documentación para que el paquete sea aceptado en CRAN. Actualmente metasurvey no tiene errores, mensajes de advertencia o notas en CRAN, la cobertura del código es baste baja ya que realizar test para todas las funciones es un trabajo arduo y que requiere tiempo, sin embargo en futuras versiones se espera tener una cobertura del código mayor al 80%. La cobertura puede ser verificada en el siguiente enlace: codecov.\n\n\nDocumentación\nPara la documentación se utilizó roxygen2 que permite la documentación de funciones y la creación de manuales, además de pkgdown que permite la creación de sitios web para paquetes de R, esto permite que los usuarios puedan tener una guía de referencia para utilizar el paquete y que los desarrolladores puedan tener una guía de referencia para la implementación de nuevas funciones o la modificación de las existentes.\n\n\n\nCódigo 3.3: Extracto de la documentación de la función load_survey con las etiquetas necesarias para la generación de la documentación.\n\n\n\n\nCódigo\n#' @title Load survey\n#' @param path Path to the survey file\n#' @param svy_type Type of survey\n#' @param svy_edition Edition of the survey\n#' @param svy_weight Weight of the survey\n#' @param svy_psu Primary sampling unit\n#' @param ... Additional arguments\n#' @param bake Logical\n#' @return Survey object\n#' @keywords preprocessing\n#' @export\nload_survey &lt;- function(\n    path = NULL,\n    svy_type = NULL,\n    svy_edition = NULL,\n    svy_weight = NULL,\n    svy_psu = NULL,\n    ..., bake = FALSE) {\n      # Ejemplo no mostrado debido a la extensión del\n      # código puede ser consultado en \n      # el repositorio de GitHub\n}\n\n\n\n\n\nComo se puede observar en el código 3.3, la documentación de las funciones se realiza con comentarios en el código fuente, esto permite que roxygen2 pueda generar la documentación de las funciones y los manuales de manera automática, simplemente hay que añadir comentarios con ciertas etiquetas que dependiendo si la función es exportada o no, es un requisito para la aceptación en CRAN que las funciones que se exporten estén documentadas y que la documentación sea clara y concisa. La documentación puede ser consultada en el siguiente enlace: Documentación de metasurvey o en la ayuda de R con ?load_survey.\n\n\n\nPruebas en diferentes sistemas operativos y versiones de R junto a GitHub Actions\nEn muchos casos, los paquetes de R pueden tener problemas de compatibilidad con diferentes versiones de R o con diferentes sistemas operativos, para evitar estos problemas se utilizó GitHub Actions que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov. En el caso de metasurvey se realizan pruebas en diferentes versiones de R y en diferentes sistemas operativos como Windows, MacOS y Linux, esto permite que el paquete sea compatible con diferentes versiones de R y sistemas operativos.\nTodo esto fue realizado en GitHub Actions donde se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R. En este caso al utilizar GitFlow que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git, se puede tener una rama de desarrollo y una rama de producción, donde en la rama de desarrollo se realizan los cambios y se ejecutan los test y en la rama de producción se realiza la publicación en CRAN. Todo esto permite que el paquete sea robusto y que los cambios sean integrados de manera continua en el repositorio. Para la integración de una nueva versión se realizan pull request que son un pedido de integración de cambios en la rama de desarrollo, esto permite que los cambios sean revisados y auditados antes de ser integrados en la rama principal.\n\n\n\nCódigo 3.4: Archivo de configuración de GitHub Actions para la ejecución de tests en diferentes sistemas operativos y versiones de R.\n\n\n\n\nCódigo\non:\n  push:\n    branches: \n      - main\n      - develop\n  pull_request:\n    branches: [develop]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macos-latest,   r: 'release'}\n          - {os: windows-latest, r: 'release'}\n          - {os: ubuntu-latest,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: ubuntu-latest,   r: 'oldrel-1'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: r-lib/actions/setup-pandoc@v2\n\n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v2\n        with:\n          extra-packages: any::rcmdcheck\n          needs: check\n\n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n\n\n\nComo se puede observar en el código 3.4, se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R, esto es lanzado automáticamente cuando se hace un cambio en la rama de desarrollo o en la rama de producción puede aquí verse el historial y ejemplos del mismo paquete.\nEn capítulos posteriores se presentará la implementación de conceptos de workflows, meta-programación y metodologías de estimación de varianzas en metasurvey para la generación de indicadores sociales.\n\n\n\n\nAllaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey, y Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n«Apache Airflow Documentation». s. f. https://airflow.apache.org/docs/latest/.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John Ainsworth, Jiten Bhagat, Philip Couch, et al. 2013. «Why linked data is not enough for scientists». Future Generation Computer Systems, Special section: Recent advances en e-Science, 29 (2): 599-611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars Kotthoff, y Bernd Bischl. 2021. «mlr3pipelines - Flexible Machine Learning Pipelines in R». Journal of Machine Learning Research 22 (184): 1-7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nChambers, John M. 2014. «Object-Oriented Programming, Functional Programming and R». Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nCodecov: Code Coverage Insights. 2024. https://about.codecov.io.\n\n\nDavison, Andrew P, y John E Huth. 2012. «Sumatra: A toolkit for reproducible research». arXiv preprint arXiv:1207.5548.\n\n\nDriessen, Vincent. 2010. «A Successful Git Branching Model». https://nvie.com/posts/a-successful-git-branching-model/.\n\n\nExpectations, Great. 2024. Great Expectations Documentation. Superconductive. https://docs.greatexpectations.io.\n\n\nGentle, James E. 2009. Computational Statistics. Statistics y Computing. New York, NY: Springer. https://link.springer.com/10.1007/978-0-387-98144-4.\n\n\nGitHub Actions: Automate Your Workflow. 2024. GitHub. https://github.com/features/actions.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024. Jupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. «Literate programming». The Computer Journal 27 (2): 97111.\n\n\nLandau, William Michael. 2018. «The drake R package: a pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. «The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in R: Statistical Programming for Data Science, Analysis and Finance. SPRINGER.\n\n\nMerkel, Dirk. 2014. «Docker: lightweight linux containers for consistent development and deployment». Linux journal 2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, y Timnit Gebru. 2019. «Model Cards for Model Reporting». En, 220-29. https://doi.org/10.1145/3287560.3287596.\n\n\nPrabhu, Anirudh, y Peter Fox. 2020. «Reproducible Workflow», diciembre. http://arxiv.org/abs/2012.13427.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: venv - Creation of virtual environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\n«R Packages (2e)». s. f. https://r-pkgs.org/.\n\n\nrOpenSci, Brooke Anderson, Scott Chamberlain, Laura DeCicco, Julia Gustavsen, Anna Krystalli, Mauro Lepore, et al. 2024. «rOpenSci Packages: Development, Maintenance, and Peer Review». Zenodo. https://doi.org/10.5281/zenodo.10797633.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, y Eivind Hovig. 2013. «Ten Simple Rules for Reproducible Computational Research». PLOS Computational Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSottile, Anthony, y Contributors. 2024. pre-commit: A framework for managing and maintaining multi-language pre-commit hooks. https://pre-commit.com.\n\n\nStodden, Victoria, Friedrich Leisch, y Roger D. Peng. 2014. Implementing Reproducible Research. CRC Press.\n\n\nThomas Mailund. 2017. Metaprogramming in R. 1.ª ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nUshey, Kevin, y Hadley Wickham. 2023. renv: Project Environments. https://CRAN.R-project.org/package=renv.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWickham, Hadley. 2011a. «testthat: Get Started with Testing». The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2011b. «testthat: Get Started with Testing». The R Journal 3: 5-10. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced R, Second Edition. CRC Press.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, y Andy Teucher. 2024. usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, y Manuel Eugster. 2024. roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, Maëlle Salmon, Olivier Roy, y Salim Brüggemann. 2024. pkgdown: Make Static HTML Documentation for a Package. https://CRAN.R-project.org/package=pkgdown.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, y Jennifer Bryan. 2022. devtools: Tools to Make Developing R Packages Easier. https://CRAN.R-project.org/package=devtools.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Métodos computacionales</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html",
    "href": "chapters/chapter4.html",
    "title": "4  Antecedentes",
    "section": "",
    "text": "4.1 Monitores y plataformas de datos públicos\nLa evolución del análisis estadístico basado en encuestas por muestreo refleja una tensión constante entre la sofisticación metodológica y la necesidad de herramientas accesibles y reproducibles. Este capítulo examina el panorama actual de soluciones, desde plataformas institucionales hasta herramientas especializadas, proporcionando el contexto necesario para comprender la contribución de metasurvey al campo.\nEl ecosistema uruguayo de datos públicos representa un esfuerzo institucional significativo por democratizar el acceso a la información estadística. Sin embargo, más allá de la disponibilidad de datos, existe una brecha importante en términos de transparencia metodológica y reproducibilidad técnica.\nEn el Instituto de Economía de la Facultad de Ciencias Económicas y de Administración (FCEA) de la Universidad de la República (UdelaR) cuentan con un trabajo de compatibilización de Encuestas Continuas de Hogares (Instituto de Economía, Universidad de la República 2020) para construir y homogeneizar series de tiempo de indicadores de mercado laboral, ingresos y pobreza.\nSi bien estas plataformas cumplen un rol fundamental en la diseminación de información estadística, presentan limitaciones significativas en términos de documentación metodológica y capacidades de reproducción. El trabajo del IECON sobre la compatibilización de Encuestas Continuas de Hogares (Instituto de Economía, Universidad de la República 2020) representa un avance importante, pero la ausencia de herramientas estandarizadas para la documentación y reproducción de procesos sigue siendo un desafío pendiente.\nAdemás, la integración de datos provenientes de múltiples fuentes institucionales a menudo requiere procesos de limpieza y transformación manuales, lo que no solo incrementa la carga de trabajo de los analistas sino que también introduce potenciales sesgos y errores humanos. La falta de una estandarización en los procedimientos de procesamiento de datos complica la comparación de resultados entre diferentes estudios y limita la capacidad de realizar análisis longitudinales robustos.\nEste contexto resalta la necesidad de desarrollar herramientas que no solo faciliten el acceso a los datos, sino que también promuevan la transparencia metodológica y la reproducibilidad de los análisis. En este sentido, metasurvey surge como una respuesta innovadora, orientada a superar estas limitaciones mediante la automatización y estandarización de los procesos de limpieza y transformación de datos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Antecedentes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#monitores-y-plataformas-de-datos-públicos",
    "href": "chapters/chapter4.html#monitores-y-plataformas-de-datos-públicos",
    "title": "4  Antecedentes",
    "section": "",
    "text": "El Instituto Nacional de Estadística (INE) con sus monitores especializados:\n\nMonitor de Mercado de Trabajo\nMonitor de Ingresos de hogares y personas\nMercado de trabajo por área geográfica de referencia\n\nEl Ministerio de Desarrollo Social (MIDES) a través de su Observatorio Social\nLa Oficina de Planeamiento y Presupuesto (OPP) mediante el Observatorio Territorio Uruguay\nLa Agencia Nacional de Investigación e Innovación (ANII) con su portal PRISMA",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Antecedentes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#ecosistema-de-herramientas-en-r",
    "href": "chapters/chapter4.html#ecosistema-de-herramientas-en-r",
    "title": "4  Antecedentes",
    "section": "4.2 Ecosistema de herramientas en R",
    "text": "4.2 Ecosistema de herramientas en R\nEl análisis de encuestas en R ha evolucionado desde implementaciones aisladas hacia un ecosistema interconectado de herramientas especializadas. El paquete survey establece los fundamentos estadísticos, mientras que extensiones como srvyr, gustave, vardpoor y convey abordan necesidades específicas de estimación y análisis. Los paquetes dedicados a encuestas nacionales como ech, eph y casen complementan este ecosistema adaptando las herramientas generales a contextos específicos.\n\n#&gt; file:////tmp/RtmpbEZ1P1/file17f54f3113b0.html screenshot completed\n\nLa Tabla 4.1 presenta un análisis detallado de los principales paquetes de R utilizados para el análisis de encuestas por muestreo. Esta comparación revela aspectos fundamentales de cada implementación. En cuanto a los paquetes base, survey se destaca como el componente fundamental para el análisis de encuestas complejas, implementando los estimadores más comunes y sirviendo como dependencia clave para otros paquetes, mientras que srvyr ofrece una interfaz más moderna usando tidyverse, aunque esto implica incorporar múltiples dependencias.\nEn el ámbito de los paquetes especializados en varianza, gustave implementa métodos específicos como Deville y Tillé, mientras que vardpoor se enfoca en el método de último conglomerado. Por su parte, svrepprovee métodos de replicación como Bootstrap y Jackknife. En cuanto a paquetes para análisis específicos,convey` se especializa en medidas de desigualdad y se integra eficientemente con el diseño muestral.\nUn aspecto crucial que se evidencia en la tabla es que, si bien cada paquete tiene sus fortalezas específicas, ninguno aborda completamente la necesidad de reutilización de procesos de limpieza y transformación, visualización del flujo de trabajo, ni documentación integrada del proceso. Esta comparación fue fundamental para decidir las dependencias de metasurvey, optando por survey como motor principal de estimación y svrep para métodos de replicación, mientras se evitan dependencias innecesarias que podrían comprometer la mantenibilidad.\n\n\n\n\nTabla 4.1: Comparación de paquetes para análisis de encuestas\n\n\n\n\n\n\n\n\n\n\nEl análisis del ecosistema actual revela cuatro limitaciones principales: la dificultad en la reutilización de procesos, la falta de visualización del flujo de trabajo, la rigidez ante cambios estructurales y la opacidad en la implementación. metasurvey se desarrolló como respuesta a estas limitaciones, adoptando un enfoque de meta-programación que permite abstraer los procesos de transformación en elementos reutilizables, visualizar y documentar el flujo de trabajo, mantener la flexibilidad ante cambios en las estructuras de datos y aprovechar las capacidades de paquetes establecidos como survey y svrep.\n\n\n\n\nInstituto de Economía, Universidad de la República. 2020. «Encuesta Continua de Hogares Compatibilizada 1981-2018». http://doi.org/10.47426/ECH.INE.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Antecedentes</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html",
    "href": "chapters/chapter5.html",
    "title": "5  Metodología y desarrollo",
    "section": "",
    "text": "5.1 Desarrollo e Implementación\nEn este capítulo se divide en dos partes, la primera parte se centra en la metodología de los métodos de estimación de varianzas y errores estándar, donde se describen los diferentes métodos de remuestreo y se explican las ventajas de los pesos replicados. La segunda parte se centra en el desarrollo e implementación de las diferentes partes del paquete. Los ejemplos de código se muestran con código real del paquete metasurvey y donde allí se explican las diferentes partes del código y su funcionamiento intentando ser lo más expositivo posible para que el lector pueda entender el funcionamiento de la meta-programación aunque estos no sean los ejemplos más complejos que se encuentran en el paquete.\nEl desarrollo de metasurvey se fundamenta en tres pilares principales: una gestión eficiente de dependencias, una arquitectura modular basada en clases, y el uso de técnicas avanzadas de meta-programación. A continuación, se detalla cada uno de estos aspectos.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Metodología y desarrollo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#desarrollo-e-implementación",
    "href": "chapters/chapter5.html#desarrollo-e-implementación",
    "title": "5  Metodología y desarrollo",
    "section": "",
    "text": "5.1.1 Gestión de Dependencias\nEl diseño de metasurvey prioriza la eficiencia y minimalismo en sus dependencias externas. El núcleo del paquete se apoya en survey para el procesamiento de encuestas complejas, data.table para la manipulación eficiente de datos mediante referencias, y R6 para la implementación orientada a objetos. Para mejorar la legibilidad del código se utiliza glue, mientras que jsonlite y httr facilitan la comunicación con la API. Esta selección cuidadosa contrasta con versiones anteriores que incluían dependencias más pesadas como tidyverse y rlang, priorizando ahora la eficiencia y ligereza del paquete.\n\n\n5.1.2 Arquitectura y Diseño de Clases\nEl paquete utiliza una arquitectura orientada a objetos mediante R6, implementando las siguientes clases principales:\n\nClase Survey\n\nAlmacena la encuesta, metadatos y diseño muestral\nMantiene registro de recetas y pasos aplicados\n\nClase Step\n\nDefine transformaciones individuales\nGestiona dependencias y evaluación perezosa\n\nClase Recipe\n\nAgrupa steps y metadatos del proceso\nFacilita compartir flujos de trabajo\nIncluye DOI para citación académica\n\nClase RotativePanelSurvey y PoolSurvey\n\nExtensiones para casos específicos (paneles rotativos y combinación de encuestas)\nImplementan estimadores especializados\n\n\nLa arquitectura modular facilita la extensión del paquete y protege los objetos mediante encapsulamiento.\n\n\n5.1.3 Implementación de Meta-programación\nLa meta-programación en metasurvey cumple tres objetivos principales:\n\nRegistro Automático de Transformaciones\n\nCada operación realizada en una encuesta se registra automáticamente\nFacilita la replicabilidad y transparencia de los análisis\n\nEvaluación Perezosa\n\nLas transformaciones se aplican solo cuando es necesario\nOptimiza el rendimiento y uso de memoria\n\nGestión de Dependencias\n\nIdentificación automática de variables dependientes\nAsegura la correcta aplicación de transformaciones en el orden adecuado\n\n\nImplementar la evaluación perezosa y dependencias fue un gran desafío, ya que requirió un diseño cuidadoso de los métodos para poder trabajar con las expresiones de R y extraer información de las mismas. La meta-programación se encuentra en casi toda la implementación de los Step y de las funciones auxiliares que permiten la creación y aplicación de recetas y pasos. Dentro de esta misma sintaxis se permite extraer las expresiones para luego poder compartir las recetas o poder decidir en que momento se aplican los pasos y recetas a la encuesta.\n\n\n5.1.4 Ejemplos de la implementación\n\nCarga de una encuesta\nEl paquete puede didirse en dos partes principales: la carga y procesamiento de encuestas, y la estimación de errores estándar. Dentro de lo que es la carga y procesamiento de encuestas, se incluyen funciones para cargar encuestas en diferentes formatos, como SPSS, STATA, CSV, y RDS, y para realizar operaciones básicas como la selección de variables, la recodificación de categorías, y la creación de indicadores.\nEsta implementación puede verse en load_survey.R donde aquí se define la función principal load_survey esta misma se encarga de cargar la encuesta y realizar las operaciones básicas mencionadas anteriormente. Dentro de ella podemos ver que es simplemente un wrapper de diferentes paquetes para cargar la encuesta ya sea read.spss del paquete foregin (R Core Team 2023) para cargar encuestas provenientes en formato SAV o DTA, fread de data.table (Barrett et al. 2024) para archivos CSV y por último loadWorkbook del paquete openxlsx (Schauberger y Walker 2024), todas estas funciones se encargan de cargar la encuesta en base a la extensión del archivo, el usuario puede modificar cambiando el engine como por ejemplo a tidyverse donde la lectura CSV se realiza con read_csv del paquete readr (Wickham 2023), o haven (Wickham, Miller, y Smith 2023) para cargar encuestas en formato SPSS o STATA.\nAl cargar la encuesta el usuario debe de especificar el tipo de encuesta que está cargando y la edición de la misma, estos metadatos serán cruciales para poder obtener recetas y pasos de la API de metasurvey. Además, se puede especificar el tipo de réplica que se desea utilizar, por defecto se utiliza el método de BRR, pero el usuario puede especificar el método de réplica que desee, ya sea Jackknife o Bootstrap, en el Capítulo 6 se menciona como utilizar replicas brindadas por la institución que publica los microdatos y estimadores de cambios netos compuestos.\nUna vez definida la carga de datos dentro de la misma implementación de crea un objeto de la clase Survey la cual se encuentra definida en survey.R. Esta clase es realizada con el paquete R6 (Chang 2022) y se encarga de almacenar la encuesta, los metadatos, las recetas y los pasos junto al diseño muestral, el usuario puede obtener información con wrappers de cada método para que sea más sencillo de utilizar, como por ejemplo cat_steps donde se obtiene todos los pasos que fueron aplicados a la encuesta, cat_recipes donde se obtienen todas las recetas que fueron aplicadas a la encuesta, cat_design donde se obtiene el diseño muestral, entre otros.\nEn el código 5.1 se muestra un ejemplo de cómo se carga una encuesta y se obtiene la información de la misma.\n\n\n\nCódigo 5.1: Lectura de la encuesta ECH 2022, fijación del ponderador y obtención de recetas.\n\n\n\n\nCódigo\nlibrary(metasurvey)\n\n# Cargar encuesta\n\n## Encuesta ECH 2022\n## Se fija el ponderador de la encuesta\n## Se obtienen las recetas de la encuesta\n\nech_2022 &lt;- load_survey(\n  metasurvey::load_survey_example(\n    \"ech\",\n    \"ech_2022\"\n  ),\n  svy_edition = \"2022\",\n  svy_type = \"ech\",\n  svy_weight = add_weight(annual = \"w_ano\"),\n  recipes = get_recipe(\n    \"ech\",\n    \"2022\"\n  )\n)\n\n\n\n\n\nDentro de este mismo ejemplo se puede ver que se fija el ponderador de la encuesta, en este caso se fija el ponderador w_ano que es el ponderador anual de la encuesta ECH 2022, este ponderador es crucial para la estimación de errores estándar y para la obtención de recetas y pasos de la encuesta.\n\n\nClase Step\nLa clase Step es una clase que se encarga de almacenar los pasos que se aplican a la encuesta, esta clase se encuentra definida en step.R y se encarga de almacenar los pasos que se aplican a la encuesta, los pasos se aplican a través de recetas que se obtienen de la API de metasurvey, los pasos pueden ser de diferentes tipos, como por ejemplo step_compute que se encarga de calcular una variable, step_recode que se encarga de recodificar una variable, entre otros.\nEn el Código 5.2 se muestra un ejemplo de cómo se crea un objeto de la clase Step con una clase de R6 (Chang 2022) paquete que permite la programación orientada a objetos en R donde tiene aquí se encuentran los atributos de la clase Step como name, edition, survey_type, type, new_var, exprs, call, svy_before, default_engine, depends_on, comments, bake en conjunto con el método initialize que se encarga de inicializar la clase Step con los atributos mencionados anteriormente. Los objetos Survey, Recipe, PanelRotativeSurvey y PoolSurvey son clases que se encuentran definidas en el paquete metasurvey donde modelar en una clase los diferentes objetos que se utilizan en el paquete permite una mejor organización y estructura del código y facilita la implementación de la meta-programación.\nEs importante mencionar que la clase Step es una clase que se utiliza internamente en el paquete y no es necesario que el usuario la utilice directamente, sin embargo, es importante mencionarla ya que es una parte esencial del paquete y es utilizada en la implementación de las recetas y pasos de la encuesta, además de que es un ejemplo claro de cómo se puede utilizar la programación orientada a objetos en R para modelar diferentes objetos y clases.\n\n\n\nCódigo 5.2: Definición de la clase Step con sus atributos y método initialize para inicializar la clase. Las clases de R6 son encapsuladas y permiten que los métodos y atributos sean privados o públicos.\n\n\n\n\nCódigo\nstep &lt;- R6Class(\n  \"Step\",\n  public = list(\n    name = NULL,\n    edition = NULL,\n    survey_type = NULL,\n    type = NULL,\n    new_var = NULL,\n    exprs = NULL,\n    call = NULL,\n    svy_before = NULL,\n    default_engine = NULL,\n    depends_on = list(),\n    comments = NULL,\n    bake = NULL,\n    initialize = function(...args) {\n      self$name &lt;- name\n      # Inicialización de los atributos de la clase\n      # Se omiten por la extensión del código\n      # Definir un constructor permite que siempre\n      # se inicialicen los atributos de la clase\n      # de forma correcta\n    },\n    method1 = function(...) {\n      # Método 1 (Método generico no se muestra por extensión)\n    },\n    method2 = function(...) {\n      # Método 2 (Método generico no se muestra por extensión)\n    }\n  )\n)\n\n\n\n\n\nEl principal uso de R6 y no de S3 o S4 es que R6 permite la creación de objetos con estado en conjunto con su propiedad de encapsulamiento, lo cual es esencial para la implementación de la meta-programación, ya que permite almacenar el estado de los objetos y modificarlos a través de métodos, lo cual es esencial para la implementación de las recetas y pasos de la encuesta. Además se puede manejar las copias de los objetos de forma más sencilla siendo algo que mejora el rendimiento y la eficiencia del paquete.\n\n\nLazy evaluation\nLa evaluación perezosa es una técnica de programación que consiste en retrasar la evaluación de una expresión hasta que sea necesaria. En el contexto de metasurvey, la evaluación perezosa se utiliza para retrasar la aplicación de recetas y pasos a la encuesta hasta que sea necesario, lo cual permite optimizar el rendimiento y la eficiencia del paquete. Esto hace que los Steps se ejecuten con una validación mínima en base a las dependencias de las variables, y se ejecuten solo cuando se necesiten o al cocinar la receta.\nEl paquete tiene por defecto la evaluación perezosa de los pasos y recetas, lo cual hace que sea más eficiente y rápido el procesamiento de las encuestas aunque puede llevar a confusiones al usuario cuando revisa los datos de forma manual ya que si bien se aplican los Step los mismos no tienen efecto hasta que se cocine la receta, el usuario puede desactivar (código 5.3) la evaluación perezosa de los pasos y recetas si lo desea. La evaluación perezosa se implementa a través de la clase Step y de la función bake que se encarga de aplicar los pasos y recetas a la encuesta.\n\n\n\nCódigo 5.3: Forma de desactivar la evaluación perezosa de los pasos y recetas. Esto hace que los pasos y recetas se apliquen de forma inmediata.\n\n\n\n\nCódigo\nmetasurvey::set_lazy_processing(FALSE)\n\n\n\n\n\n\n\nUso de copias y referencias\nEl paquete data.table (Barrett et al. 2024) logra una eficiencia en la manipulación de datos al utilizar referencias en lugar de copias, lo cual permite que las operaciones se realicen de forma más rápida y eficiente. Dentro de metasurvey al utilizar como motor data.table permite que sea eficiente y rápido aunque puede llevar a confusiones al usuario donde se modifican las referencias de los objetos algo que no es común en R, sin embargo, se puede utilizar la función copy para realizar copias de los objetos y no modificar las referencias de los mismos código 5.4.\n\n\n\nCódigo 5.4: Desactivar el uso de referencias y utilizar copias de los objetos.\n\n\n\n\nCódigo\nmetasurvey::set_use_copy(TRUE)\n\n\n\n\n\n\n\n\n5.1.5 Meta-programación\nLa meta-programación fue un aspecto clave en el desarrollo de metasurvey, ya que permitió que al realizar una operación en una encuesta, se generara un registro de los pasos y recetas aplicados, lo cual es esencial para la replicabilidad y la transparencia de los análisis. La meta-programación se implementó a través de la clase Survey y de las funciones auxiliares que permiten la creación y aplicación de recetas y pasos.\n\n\n\nCódigo 5.5: Ejemplo de función para encontrar dependencias de variables en una expresión de un step. Puede encontrar más ejemplos en el código fuente en la implementación de los Steps.\n\n\n\n\nCódigo\nfind_dependencies &lt;- function(call_expr, survey) {\n  dependencies &lt;- character()\n\n  if (is.call(call_expr)) {\n    for (i in seq_along(call_expr)) {\n      result &lt;- find_dependencies(call_expr[[i]], survey)\n      if (!is.null(result)) {\n        dependencies &lt;- unique(c(dependencies, result))\n      }\n    }\n  } else if (\n    is.name(call_expr) && as.character(call_expr) %in% names(survey)\n  ) {\n    dependencies &lt;- unique(c(dependencies, as.character(call_expr)))\n  }\n\n  return(unique(dependencies))\n}\n\n\n\n\n\nEn el código 5.5 se muestra una función auxiliar que permite encontrar las dependencias de variables en una expresión de un Step. Esta función se utiliza para identificar las variables que se utilizan en un paso y que deben ser incluidas en el registro de recetas. La función find_dependencies recibe una expresión de un paso y un objeto de la clase Survey, y devuelve un vector con las variables que se utilizan en el paso. Esta función se utiliza de forma interna en las implementaciones de step_compute y step_recode para registrar las dependencias esto es un ejemplo claro de como con código se puede extraer información del mismo y utilizarla para otros fines.\nLa meta-programación también fue utilizada para que el usuario utilice la misma sintaxis del paquete survey para definir los estadísticos a estimar y no deba de incluir el diseño el cual ya se encuentra dentro del objeto Survey, donde aquí también se encuentran diferentes diseños en base a la periodicidad de la encuesta, algo que es útil cuando se trabaja con encuestas de panel rotativos como la ECH luego de cambio de metodología en 2021, en el Capítulo 6 se menciona como se puede utilizar diferentes diseños en base a la periodicidad de la encuesta y un ejemplo con la encuesta ECH.\n\nEjemplos Avanzados de Meta-programación\nLa meta-programación avanzada en R permite manipular ambientes y expresiones de forma dinámica, lo cual es esencial para la implementación de recetas y pasos en metasurvey. A continuación, se presentan casos típicos de meta-programación, la manipulación de ambientes y expresiones, y el uso de substitute y bquote para evaluar expresiones de forma parcial.\n\nAmbientes y Evaluación\n\n\n\nCódigo 5.6: En este ejemplo se crea un nuevo ambiente env y se asignan valores a las variables x\n\n\n\n\nCódigo\n# Crear un nuevo ambiente\nenv &lt;- new.env()\n\n# Asignar valores en el nuevo ambiente\nassign(\"x\", 10, envir = env)\nassign(\"y\", 20, envir = env)\n\n# Evaluar una expresión en el nuevo ambiente\neval(quote(x + y), envir = env)\n\n\n\n\n\n\n\nManipulación de Expresiones\n\n\n\nCódigo 5.7\n\n\n\n\nCódigo\n# Crear una expresión\nexpr &lt;- quote(x + y)\n\n# Modificar la expresión\nexpr[[1]] &lt;- quote(`*`)\nexpr[[2]] &lt;- quote(x)\nexpr[[3]] &lt;- quote(y)\n\n# Evaluar la nueva expresión\neval(expr, envir = env)\n\n\n\n\n\n\n\nUso de substitute y bquote\n\n\n\nCódigo 5.8: En este ejemplo se muestra cómo se pueden reemplazar variables en una expresión utilizando substitute y cómo se puede evaluar parcialmente una expresión utilizando bquote.\n\n\n\n\nCódigo\n# Usar substitute para reemplazar variables en una expresión\nexpr &lt;- quote(a + b)\nsubstitute(expr, list(a = 1, b = 2))\n\n# Usar bquote para evaluar parcialmente una expresión\nbquote(a + .(b))\n\n\n\n\n\nEstos ejemplos muestran cómo se pueden manipular ambientes y expresiones en R para realizar meta-programación avanzada. La capacidad de modificar y evaluar expresiones dinámicamente es una herramienta poderosa que se utiliza en metasurvey para registrar y aplicar transformaciones y brindar la flexibilidad necesaria para adaptarse a diferentes tipos de encuestas y diseños muestrales.\n\n\n\n\n5.1.6 Sistema de Comunicación y Optimización\nEl paquete implementa una API REST desarrollada en Node.js que permite compartir y gestionar recetas entre usuarios. La API proporciona endpoints para obtener, crear y actualizar recetas, almacenadas en MongoDB. El sistema incluye autenticación mediante tokens JWT, con planes futuros para implementar un portal web de registro automático.\nMongoDB se eligió por su flexibilidad y escalabilidad, permitiendo almacenar recetas de forma estructurada y eficiente. Es un sistema de base de datos NoSQL (Not Only SQL) enfocada en documentos, en lugar de tablas, se agrupan en colecciones y se almacenan en formato JSON. Esto permite almacenar recetas de forma flexible y escalable, sin necesidad de definir un esquema fijo.\nSi bien dentro de la configuración de la API se define un esquema semi-estructurado para las recetas, se permite la flexibilidad de agregar nuevos campos y estructuras de datos pero se mantiene una estructura mínima para mantener la consistencia de los datos. La API se comunica con el paquete metasurvey a través de solicitudes HTTP el usuario no necesita interactuar directamente con la API ya que el paquete se encarga de la comunicación con la misma. \nPara optimizar el rendimiento, se implementó un sistema de cache que gestiona proactivamente la memoria mediante liberación de recursos y reutilización de cálculos intermedios. El sistema aprovecha la paralelización automática y el procesamiento por lotes cuando es posible.\nLa arquitectura modular del sistema facilita la incorporación de nuevos tipos de encuestas y diseños muestrales, permitiendo adaptarse a diferentes necesidades sin modificar el núcleo del paquete.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Metodología y desarrollo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#síntesis-del-capítulo",
    "href": "chapters/chapter5.html#síntesis-del-capítulo",
    "title": "5  Metodología y desarrollo",
    "section": "5.2 Síntesis del capítulo",
    "text": "5.2 Síntesis del capítulo\nEn este capítulo se ha presentado una revisión detallada de los métodos de estimación de varianzas y errores estándar, así como su implementación en el paquete metasurvey. Se han descrito las ventajas de utilizar métodos de remuestreo como Bootstrap y Jackknife, y se ha destacado la importancia de los pesos replicados en diseños de muestreo complejos. Además, se ha mostrado cómo metasurvey facilita la creación y el manejo de encuestas, permitiendo a los usuarios obtener transformaciones transparentes y reproducibles.\n\n\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, Toby Hocking, y Benjamin Schwendinger. 2024. data.table: Extension of ‘data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nR Core Team. 2023. foreign: Read Data Stored by ’Minitab’, ’S’, ’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\nSchauberger, Philipp, y Alexander Walker. 2024. openxlsx: Read, Write and Edit xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nWickham, Hadley. 2023. httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Evan Miller, y Danny Smith. 2023. haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Metodología y desarrollo</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html",
    "href": "chapters/chapter6.html",
    "title": "6  Casos de uso",
    "section": "",
    "text": "6.1 Encuesta Continua de Hogares con Paneles Rotativos\nPara este capítulo se presentan dos casos de uso que demuestran la versatilidad y eficacia de metasurvey en el análisis de encuestas de hogares en América Latina. Se abordarán dos encuestas representativas de la región: la Encuesta Continua de Hogares (ECH) de Uruguay y la Encuesta Permanente de Hogares (EPH) de Argentina. Estas encuestas son fuentes clave de información sobre el mercado laboral en sus respectivos países y han sido utilizadas en diversos estudios y análisis socioeconómicos.\nEl paquete metasurvey facilita el procesamiento y análisis de encuestas de hogares a través de una interfaz unificada. Este capítulo presenta dos casos de uso que demuestran su versatilidad: el análisis de la Encuesta Continua de Hogares (ECH) de Uruguay y la Encuesta Permanente de Hogares (EPH) de Argentina.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#encuesta-continua-de-hogares-con-paneles-rotativos",
    "href": "chapters/chapter6.html#encuesta-continua-de-hogares-con-paneles-rotativos",
    "title": "6  Casos de uso",
    "section": "",
    "text": "6.1.1 Contexto y Cambios Metodológicos\nEn 2021, la ECH adoptó un diseño de panel rotativo, reemplazando su diseño cross-section anterior. Este cambio permite el seguimiento de hogares durante seis meses, tras lo cual se incorporan nuevos grupos de rotación en el panel, como se muestra en la Figura 6.1 (Instituto Nacional de Estadı́stica 2021). Esto mejora:\n\nLa precisión de las estimaciones\nEl análisis de dinámicas laborales\nLa medición de indicadores socioeconómicos\nEl estudio de transiciones en el mercado laboral\n\n\n\n\n\n\n\nFigura 6.1: Paneles Rotativos, extraído de documento metodológico de la ECH 2023\n\n\n\n\n\n6.1.2 Carga y Procesamiento de Datos\nLa ECH ha sido la principal fuente de información sobre el mercado laboral uruguayo desde 1968 y expandió su cobertura nacional en 1980. Los microdatos están disponibles desde 2006 en el portal ANDA del INE.\nPara trabajar con la ECH 2023, se requieren:\n\nECH_implantacion_2023.csv\nECH Seguimiento[1-12].csv\nArchivos de pesos replicados Bootstrap mensuales (enero-diciembre 2023)\n\nUn aspecto técnico importante es el manejo eficiente de los pesos muestrales replicados. metasurvey optimiza este proceso convirtiendo automáticamente los archivos Excel de pesos bootstrap a formato CSV, mejorando significativamente el rendimiento en análisis posteriores.\n\n\n\nCódigo 6.1: Carga de la encuesta continua de hogares en 2023, se carga la implantación y el seguimiento de la encuesta, se especifica el tipo de encuesta, el peso de la implantación y el peso del seguimiento, en este caso se utilizan pesos replicados bootstrap para el seguimiento de la encuesta.\n\n\n\n\nCódigo\npath_dir &lt;- here::here(\"example-data\", \"ech\", \"ech_2023\")\nech_2023 &lt;- load_panel_survey(\n  path_implantation = file.path(\n    path_dir,\n    \"ECH_implantacion_2023.csv\"\n  ),\n  path_follow_up = file.path(\n    path_dir,\n    \"seguimiento\"\n  ),\n  svy_type = \"ECH_2023\",\n  svy_weight_implantation = add_weight(\n    annual = \"W_ANO\"\n  ),\n  svy_weight_follow_up = add_weight(\n    monthly = add_replicate(\n      \"W\",\n      replicate_path = file.path(\n        path_dir,\n        c(\n          \"Pesos replicados Bootstrap mensuales enero_junio 2023\",\n          \"Pesos replicados Bootstrap mensuales julio_diciembre 2023\"\n        ),\n        c(\n          \"Pesos replicados mensuales enero_junio 2023\",\n          \"Pesos replicados mensuales Julio_diciembre 2023\"\n        )\n      ),\n      replicate_id = c(\"ID\" = \"ID\"),\n      replicate_pattern = \"wr[0-9]+\",\n      replicate_type = \"bootstrap\"\n    )\n  )\n)\n\n\n\n\n\n\n\n\n6.1.3 Construcción de Variables e Indicadores\nEl paquete permite dos enfoques para la construcción de variables:\n\nUtilizar recetas predefinidas disponibles a través de la API de metasurvey\nCrear recetas personalizadas según necesidades específicas\n\nPor ejemplo, para calcular indicadores del mercado laboral:\n\n\n\nCódigo 6.2: Se puede ver las variables que dependen de la receta de ingreso compatibilizado para la ECH 2022.\n\n\n\n\nCódigo\ningreso_compatibilizado &lt;- get_recipe(\n  svy_type = \"ech\",\n  svy_edition = \"2022\",\n  topic = \"ingreso\"\n)\ningreso_compatibilizado$depends_on\n\n\n\n\n\nA continuación se presentan algunas recetas que se pueden utilizar para calcular las tasas de mercado de trabajo a nivel mensual, trimestral y anual.\n\n\n\nCódigo 6.3: Creación de variables para el cálculo de tasas de mercado de trabajo en los microdatos de seguimiento de la ECH 2023.\n\n\n\n\nCódigo\nech_2023 &lt;- ech_2023 %&gt;%\n    step_recode(\n        \"pea\",\n        POBPCOAC %in% 2:5 ~ 1,\n        .default = 0,\n        comment = \"Población Económicamente Activa\",\n        .level = \"follow_up\"\n    ) %&gt;%\n    step_recode(\n        \"pet\",\n        e27 &gt;= 14 ~ 1,\n        .default = 0,\n        comment = \"Población Empleada\",\n        .level = \"follow_up\"\n    ) %&gt;%\n    step_recode(\n        \"po\",\n        POBPCOAC == 2 ~ 1,\n        .default = 0,\n        comment = \"Población Ocupada\",\n        .level = \"follow_up\"\n    ) %&gt;%\n    step_recode(\n        \"pd\",\n        POBPCOAC %in% 3:5 ~ 1,\n        .default = 0,\n        comment = \"Población Desocupada\",\n        .level = \"follow_up\"\n    )\n\nech_2023_bake &lt;- bake_steps(ech_2023)\n\n\n\n\n\nEn el código 6.3 se crean las variables necesarias para el cálculo de las tasas de mercado de trabajo a partir de los microdatos de seguimiento de la ECH 2023. Las variables creadas son: Población Económicamente Activa (PEA), Población Empleada (PET), Población Ocupada (PO) y Población Desocupada (PD). Una cosa importante es que la variable POBPCOAC es una variable construida por el INE que indica la condición de actividad, esta variable se construye a partir de los formularios dentro de metasurvey se encuentra a modo de receta la sintaxis publicada hasta la versión 2019 de la ECH, la misma fue basado en archivos PDF donde incluían un script de SPSS para la construcción de la variable. Para años posteriores no fue publicado este documento, se espera en breve dejar disponible la receta para los años 2020 considerando el nuevo formulario y revisando las versiones anteriores.\n\n\n6.1.4 Estimación de Tasas de Mercado de Trabajo\nUna vez creadas las variables básicas, podemos calcular las tasas de actividad, empleo y desempleo utilizando la función workflow. Esta función permite realizar estimaciones a diferentes niveles temporales (mensual, trimestral, anual) y con distintos tipos de agregación.\n\nEstimación por trimestre\n\n\n\nCódigo 6.4: Estimación de tasas de mercado de trabajo a nivel trimestral a partir de las estimaciones mensuales.\n\n\n\n\nCódigo\nmercado_trabajo_mensual &lt;-\n    workflow(\n        survey = extract_surveys(\n            ech_2023_bake,\n            quarterly = 1:4\n        ),\n        survey::svyratio(\n            ~pea,\n            denominator = ~pet\n        ),\n        survey::svyratio(\n            ~po,\n            denominator = ~pet\n        ),\n        survey::svyratio(\n            ~pd,\n            denominator = ~pea\n        ),\n        estimation_type = \"quarterly:monthly\"\n    )\n\n\n\n\n\n\n#&gt; file:////tmp/RtmpPMJ4X1/file18fa1a948dad.html screenshot completed\n\n\n\n\nTabla 6.1: Tasas de mercado de trabajo a nivel trimestral a partir de las estimaciones mensuales de la ECH 2023 con sus respectivos errores estándar y coeficientes de variación.\n\n\n\n\n\n\n\n\n\n\n\nComo se puede ver en el código 6.4 se pueden realizar estimaciones a diferentes niveles temporales y con distintos tipos de agregación, en este caso se realizan estimaciones a nivel trimestral a partir de las estimaciones mensuales, el resultado de la estimación se puede ver en la Tabla 6.1.\n\n\nEstimación de valores anuales\nTambién es posible realizar estimaciones a nivel anual, para esto se debe de considerar las medias de las estimaciones mensuales para cada trimestre y luego realizar la estimación anual.\nLa nueva metodología puede dar confusiones sobre que microdatos utilizar ya que para estimaciones anuales se consideran los microdatos de implantación y las referidas a mercado de trabajo se consideran los microdatos de seguimiento esto se debe a que el hogar luego de ser seleccionado en la implantación el formulario se realiza por vía telefónica y se centra unicamente a variables referidas al situación de empleo del hogar. Para realizar estimaciones por ejemplo de cantidad de personas que finalizaron un ciclo educativo se debe de considerar los microdatos de implantación a nivel anual.\nSi bien dentro de metasurvey se pueden realizar estimaciones en diferentes años, es necesario tener cierta consideración del cambio metodológico al momento de interpretar los resultados, situaciones que también ocurrieron en la edición de 2012 y 2006 («Comunicado Encuesta Continua de Hogares» 2024).\n\n\n\nCódigo 6.5: Estimación de tasas de mercado de trabajo a nivel anual a partir de las estimaciones mensuales.\n\n\n\n\nCódigo\nmercado_trabajo_anual = workflow(\n  survey = extract_surveys(\n    ech_2023_bake,\n    annual = 2023\n  ),\n  survey::svyratio(\n    ~ pea,\n    denominator = ~ pet\n  ),\n  survey::svyratio(\n    ~ po,\n    denominator = ~ pet\n  ),\n  survey::svyratio(\n    ~ pd,\n    denominator = ~ pea\n  ),\n  estimation_type = \"annual:monthly\"\n)\n\n\n\n\n\n\n\n\nTabla 6.2: Tasas de mercado de trabajo a nivel anual a partir de las estimaciones mensuales de la ECH 2023 con sus respectivos errores estándar y coeficientes de variación considerando las replicas bootstrap.\n\n\n\n\n\n\n\n\n\n\n\nPodemos ver que se obtiene un objeto donde se tiene las estimaciones de las tasas de mercado de trabajo a nivel mensual, trimestral y anual. En este caso se utilizan las replicas bootstrap para calcular los errores estándar de las estimaciones y se incluye una recomendación sobre la confiabilidad de las estimaciones en base al coeficiente de variación de las estimaciones.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#encuesta-permanente-de-hogares-de-argentina",
    "href": "chapters/chapter6.html#encuesta-permanente-de-hogares-de-argentina",
    "title": "6  Casos de uso",
    "section": "6.2 Encuesta Permanente de Hogares de Argentina",
    "text": "6.2 Encuesta Permanente de Hogares de Argentina\nPara demostrar la versatilidad de metasurvey, se presenta un segundo caso de uso con la Encuesta Permanente de Hogares (EPH) de Argentina. La EPH es una encuesta continua de hogares que se realiza en el país desde 1985 y es la principal fuente de información sobre el mercado laboral argentino. Los microdatos de la EPH están disponibles en el portal del INDEC.\nPodemos hacer algo similar a lo que hicimos con la ECH, en este caso cargamos los microdatos de la EPH 2022 trimestre 3 y creamos las variables necesarias para el cálculo de las tasas de mercado de trabajo. Estos steps fueron basados en base al formulario de la encuesta y la documentación disponible.\n\n\n\nCódigo 6.6: Carga de la encuesta permanente de hogares en el tercer trimestre de 2022, se crean las variables necesarias para el cálculo de tasas de mercado de trabajo.\n\n\n\n\nCódigo\neph2022_3 &lt;- metasurvey::load_survey(\n    path = metasurvey::load_survey_example(\n        \"eph\",\n        \"eph2022_3\"\n    ),\n    svy_type = \"eph\",\n    svy_edition = \"eph_202302\",\n    svy_weight = add_weight(\n        monthly = \"PONDERA\"\n    )\n) |&gt;\n    metasurvey::step_recode(\n        \"pea\",\n        ESTADO %in% 1:2 ~ 1,\n        .default = 0\n    ) |&gt;\n    metasurvey::step_recode(\n        \"pet\",\n        ESTADO != 4 ~ 1,\n        .default = 0\n    ) |&gt;\n    metasurvey::step_recode(\n        \"po\",\n        ESTADO == 1 ~ 1,\n        .default = 0\n    ) |&gt;\n    metasurvey::step_recode(\n        \"pd\",\n        ESTADO == 2 ~ 1,\n        .default = 0\n    )\n\n\n\n\n\n\n6.2.1 Visualización de las recetas\nAlgo interesante que se puede hacer con metasurvey es visualizar las recetas que se utilizan para la construcción de las variables, esto puede ser útil para entender como se construyen las variables y que variables dependen de otras. En este caso se muestra la visualización para la creación de la variable POBPCOAC en la ECH 2019, si bien el INE ya incorpora esta variable en los microdatos, se puede ver como se construye la variable en base a otras variables del formulario.\n\n\n\nCódigo 6.7: Carga de la encuesta y se obtienen las recetas disponibles referidas al tópico de mercado de trabajo.\n\n\n\n\nCódigo\nech_2019 &lt;- load_survey(\n    path = \"https://metasurvey-example-data.s3.us-east-2.amazonaws.com/ech/ech_2019.csv\",\n    svy_type = \"ech\",\n    svy_edition = \"2019\",\n    svy_weight = add_weight(\n      annual = \"pesoano\"\n    ),\n    recipes = get_recipe(\n      svy_type = \"ECH\",\n      svy_edition = 2019,\n      topic = \"Mercado de trabajo\"\n    )\n)\nech_2019 &lt;- bake_recipes(ech_2019)\n\n\n\n\n\nSi bien se puede ingresar a los atributos de la receta para ver las variables que dependen de la misma, se puede visualizar de una forma más amigable con la función view_graph como se puede ver en la Figura 6.2.\n\n\n\n\n\n\n\n\n\n\n\nFigura 6.2: Flujo de construcción de la variable POBPCOAC en la ECH 2019 y variables de mercado de trabajo que dependen de la misma.\n\n\n\n\n\n6.2.2 Compartiendo Recetas entre Usuarios\nEn el ejemplo anterior se descargaron recetas ya definidas pero también se pueden compartir recetas entre usuarios, esto puede ser útil para compartir recetas que se han construido en base a la documentación de la encuesta o para compartir recetas que se han construido en base a la experiencia de los usuarios como se ve en el código 6.8.\n\n\n\nCódigo 6.8: Compartir receta de clasificación de la población por condición de actividad en la ECH 2019.\n\n\n\n\nCódigo\nreceta &lt;- steps_to_recipe(\n    name = \"Población por condición de actividad\",\n    user = \"INE-Uruguay\",\n    svy = ech_2019,\n    description = \"Clasificación de la población por condición de actividad\",\n    steps = ech_2019$steps,\n    topic = \"Mercado de trabajo\"\n)\n\npublish_recipe(receta)\n#&gt; Recipe successfully published to metasurvey API. Thanks for your contribution :). Status code: 201\n#&gt; $insertedId\n#&gt; [1] \"674ef08cc946aff505309e15\"",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#más-sobre-metasurvey",
    "href": "chapters/chapter6.html#más-sobre-metasurvey",
    "title": "6  Casos de uso",
    "section": "6.3 Más sobre metasurvey",
    "text": "6.3 Más sobre metasurvey\nPara la construcción del paquete se ha realizado mucho trabajo en el desarrollo de cada una de las funciones, se ha buscado que el paquete sea lo más eficiente posible y que sea fácil de usar, se han realizado pruebas de rendimiento y se han buscado formas de optimizar el código para que sea lo más rápido posible.\nEn la Figura 6.3 se puede ver las dependencias de las funciones dentro de metasurvey, se puede ver que las funciones están muy bien organizadas y que se pueden utilizar de forma independiente, esto permite que el paquete sea muy flexible y que se puedan utilizar las funciones de forma independiente o en conjunto.\nDesarrollar el paquete ha sido un proceso largo y complejo, pero ha sido muy gratificante ver cómo ha evolucionado puede ser utilizado por diferentes usuarios para diferentes tipos de encuestas, se espera que el paquete siga evolucionando y que se sigan incorporando nuevas funcionalidades y mejoras. Si bien el paquete ha sido desarrollado en base a las encuestas de hogares de Uruguay y Argentina, se espera que pueda ser utilizado para otras encuestas de hogares en América Latina y en otros países.\nEn futuras versiones se espera que el usuario pueda buscar y crear recetas de una interfaz gráfica, un registro de usuarios, monitoreo y analítica de uso, entre otras funcionalidades.\nEl paquete es muy flexible y la forma de que sea más útil es que los usuarios compartan sus recetas y que se puedan compartir entre usuarios, esto permitirá que el paquete sea más útil y que se puedan construir recetas más complejas y que se puedan compartir entre usuarios.\n\n\n\n\n\n\n\n\n\n\n\nFigura 6.3: Funciones dentro de metasurvey y sus dependencias. Los nodos representan las funciones y las aristas las dependencias entre ellas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#resumen",
    "href": "chapters/chapter6.html#resumen",
    "title": "6  Casos de uso",
    "section": "6.4 Resumen",
    "text": "6.4 Resumen\nLos casos de uso presentados demuestran la flexibilidad y potencia de metasurvey para el procesamiento de diferentes encuestas de hogares:\n\nEn el caso de la ECH, se mostró cómo manejar eficientemente el nuevo diseño de panel rotativo y los pesos muestrales replicados bootstrap para generar estimaciones precisas de indicadores del mercado laboral.\nCon la EPH, se evidenció la capacidad del paquete para adaptarse a diferentes estructuras de datos y metodologías de encuestas, manteniendo una interfaz consistente.\nLa visualización de recetas mediante view_graph() facilita la comprensión de las dependencias entre variables y la transparencia en la construcción de indicadores.\nLa posibilidad de compartir recetas entre usuarios permite aprovechar el conocimiento colectivo y acelerar el proceso de análisis de encuestas.\n\nEstas características hacen de metasurvey una herramienta valiosa para investigadores y analistas que trabajan con encuestas de hogares en América Latina, proporcionando un marco unificado y eficiente para el procesamiento y análisis de datos.\n\n\n\n\n«Comunicado Encuesta Continua de Hogares». 2024. https://www.gub.uy/instituto-nacional-estadistica/comunicacion/noticias/comunicado-encuesta-continua-hogares.\n\n\nInstituto Nacional de Estadı́stica. 2021. «Metodologı́a de la Encuesta Continua de Hogares Instituto Nacional de Estadı́stica». https://www.ine.gub.uy.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html",
    "href": "chapters/chapter7.html",
    "title": "7  Pasos a futuro",
    "section": "",
    "text": "7.1 Logros alcanzados y su relevancia\nEl desarrollo de metasurvey marca un hito significativo en la creación de herramientas reproducibles y transparentes para el análisis de encuestas por muestreo. Sin embargo, más allá de los avances alcanzados, este trabajo abre múltiples caminos de exploración, mejora y expansión. En este capítulo, reflexionamos sobre los logros conseguidos y planteamos una hoja de ruta ambiciosa pero alcanzable para el futuro.\nDurante este proceso, metasurvey ha consolidado su posición como una herramienta versátil y poderosa para investigadores y analistas de datos. Su diseño modular y su enfoque en la reproducibilidad han sido claves para facilitar el análisis de datos complejos en un entorno accesible. Este capítulo busca contextualizar estos logros dentro de una visión más amplia de las necesidades actuales y emergentes en el campo de las encuestas por muestreo.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html#optimización-del-rendimiento-y-escalabilidad",
    "href": "chapters/chapter7.html#optimización-del-rendimiento-y-escalabilidad",
    "title": "7  Pasos a futuro",
    "section": "7.2 Optimización del rendimiento y escalabilidad",
    "text": "7.2 Optimización del rendimiento y escalabilidad\n\n7.2.1 Hacia un procesamiento paralelo eficiente\nUno de los desafíos principales en el manejo de encuestas es la escalabilidad. En particular, el procesamiento de grandes conjuntos de datos o de análisis longitudinales representa una carga significativa para los sistemas. La implementación de procesamiento paralelo nativo se erige como una prioridad. Al habilitar cálculos distribuidos para operaciones intensivas como la generación de réplicas bootstrap, no solo se reducirán los tiempos de ejecución, sino que se abrirá la puerta a análisis más complejos y en tiempo real.\nAdemás, exploraremos estrategias de reducción de memoria mediante la implementación de estructuras de datos más ligeras y algoritmos optimizados, adaptados a los escenarios más comunes de uso.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html#expansión-de-funcionalidades-estadísticas",
    "href": "chapters/chapter7.html#expansión-de-funcionalidades-estadísticas",
    "title": "7  Pasos a futuro",
    "section": "7.3 Expansión de funcionalidades estadísticas",
    "text": "7.3 Expansión de funcionalidades estadísticas\n\n7.3.1 Integración de nuevos métodos analíticos\nLa robustez de una herramienta radica en su capacidad de adaptarse a nuevos paradigmas y métodos. En este sentido, la integración de metodologías avanzadas para el cálculo de varianzas y estimaciones en diseños complejos es un área de desarrollo clave. Por ejemplo, los métodos de (Deville y Tillé 2005) proporcionan un marco teórico sólido que puede fortalecer las capacidades de metasurvey.\nAdicionalmente, el soporte para modelos lineales representará un paso adelante en el tratamiento de diseños muestrales complejos, permitiendo a los usuarios responder preguntas de investigación más sofisticadas.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html#fomentar-una-comunidad-activa-de-usuarios",
    "href": "chapters/chapter7.html#fomentar-una-comunidad-activa-de-usuarios",
    "title": "7  Pasos a futuro",
    "section": "7.4 Fomentar una comunidad activa de usuarios",
    "text": "7.4 Fomentar una comunidad activa de usuarios\nLa sostenibilidad de metasurvey como herramienta de referencia depende en gran medida de la creación de una comunidad activa y comprometida. Para ello, se prevé:\n\nPlataformas de colaboración: Establecimiento de un repositorio público interactivo donde los usuarios puedan compartir scripts, soluciones y preguntas frecuentes.\nEventos de capacitación: Organización de talleres y webinars orientados tanto a principiantes como a usuarios avanzados, cubriendo casos prácticos y metodologías avanzadas.\nReconocimiento a contribuciones: Introducción de un sistema de menciones en las publicaciones científicas del proyecto para quienes contribuyan de manera significativa al desarrollo de metasurvey.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter7.html#conclusión",
    "href": "chapters/chapter7.html#conclusión",
    "title": "7  Pasos a futuro",
    "section": "7.5 Conclusión",
    "text": "7.5 Conclusión\nmetasurvey no solo es una herramienta; es un paso hacia la democratización del análisis de encuestas. A medida que avanzamos hacia un futuro más interconectado, el compromiso con la innovación, la reproducibilidad y la colaboración será el motor que impulse su evolución continua. Este proyecto, aunque ambicioso, refleja la pasión y el compromiso de una comunidad dedicada a transformar la investigación por muestreo.\nEn resumen, los próximos pasos delineados aquí representan no solo una oportunidad de mejora técnica, sino también una invitación a co-crear un futuro donde el análisis de encuestas sea accesible, inclusivo y poderoso.\n\n\n\n\nDeville, Jean-Claude, y Yves Tillé. 2005. «Variance approximation under balanced sampling». Journal of Statistical Planning and Inference 128 (2): 569-91. https://doi.org/10.1016/j.jspi.2003.11.011.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/bibliography.html",
    "href": "chapters/bibliography.html",
    "title": "Biblografía",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey,\nand Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n“Apache Airflow Documentation.” n.d. https://airflow.apache.org/docs/latest/.\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael\nChirico, Toby Hocking, and Benjamin Schwendinger. 2024. Data.table:\nExtension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John\nAinsworth, Jiten Bhagat, Philip Couch, et al. 2013. “Why Linked\nData Is Not Enough for Scientists.” Future Generation\nComputer Systems, Special section: Recent advances in e-science, 29\n(2): 599–611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars\nKotthoff, and Bernd Bischl. 2021. “Mlr3pipelines - Flexible\nMachine Learning Pipelines in r.” Journal of Machine Learning\nResearch 22 (184): 1–7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, and Santa Ivanova. 2020. Vardpoor:\nEstimation of Indicators on Social Exclusion and Poverty and Its\nLinearization, Variance Estimation. Riga, Latvia: Central\nStatistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChambers, John M. 2014. “Object-Oriented Programming, Functional\nProgramming and r.” Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference\nSemantics.\n\n\nChevalier, Martin. 2023. Gustave: A User-Oriented Statistical\nToolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCodecov: Code Coverage Insights. 2024. https://about.codecov.io.\n\n\n“Comunicado Encuesta Continua de Hogares.” 2024. https://www.gub.uy/instituto-nacional-estadistica/comunicacion/noticias/comunicado-encuesta-continua-hogares.\n\n\nDavison, Andrew P, and John E Huth. 2012. “Sumatra: A Toolkit for\nReproducible Research.” arXiv Preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. “Ech: Caja de\nHerramientas Para Procesar La Encuesta Continua de Hogares.” https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, and Yves Tille. 1998. “Unequal Probability\nSampling Without Replacement Through a Splitting Method.”\nBiometrika 85 (1): 89–101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, and Yves Tillé. 2005. “Variance\nApproximation Under Balanced Sampling.” Journal of\nStatistical Planning and Inference 128 (2): 569–91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nDriessen, Vincent. 2010. “A Successful Git Branching\nModel.” https://nvie.com/posts/a-successful-git-branching-model/.\n\n\nEscobar, Emilio L., and Yves G. Berger. 2013. “A New Replicate\nVariance Estimator for Unequal Probability Sampling Without\nReplacement.” The Canadian Journal of Statistics / La Revue\nCanadienne de Statistique 41 (3): 508–24. https://www.jstor.org/stable/43186201.\n\n\nExpectations, Great. 2024. Great Expectations Documentation.\nSuperconductive. https://docs.greatexpectations.io.\n\n\nFreedman Ellis, Greg, and Ben Schneider. 2024. Srvyr: ’Dplyr’-Like\nSyntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nGentle, James E. 2009. Computational Statistics. Statistics and\nComputing. New York, NY: Springer. https://link.springer.com/10.1007/978-0-387-98144-4.\n\n\nGitHub Actions: Automate Your Workflow. 2024. GitHub. https://github.com/features/actions.\n\n\nHajek, Jaroslav. 1964. “Asymptotic Theory of Rejective Sampling\nwith Varying Probabilities from a Finite Population.” The\nAnnals of Mathematical Statistics 35 (4): 1491–1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nHorvitz, D. G., and D. J. Thompson. 1952. “A Generalization of\nSampling Without Replacement from a Finite Universe.” Journal\nof the American Statistical Association 47 (260): 663–85. https://doi.org/10.2307/2280784.\n\n\nInstituto de Economía, Universidad de la República. 2020.\n“Encuesta Continua de Hogares Compatibilizada 1981-2018.”\nhttp://doi.org/10.47426/ECH.INE.\n\n\nInstituto Nacional de Estadı́stica. 2021. “Metodologı́a\nde La Encuesta Continua de\nHogares Instituto Nacional de\nEstadı́stica.” https://www.ine.gub.uy.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger,\nMatthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024.\nJupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” The\nComputer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, and\nNatsumi Shokida. 2020. Eph: Argentina’s Permanent Household Survey\nData and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, and Emil Hvitfeldt. 2024. Recipes:\nPreprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLandau, William Michael. 2018. “The Drake r Package: A Pipeline\nToolkit for Reproducibility and High-Performance Computing.”\nJournal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. “The Targets r Package: A Dynamic Make-Like\nFunction-Oriented Pipeline Toolkit for Reproducibility and\nHigh-Performance Computing.” Journal of Open Source\nSoftware 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2004. “Analysis of Complex Survey Samples.”\nJournal of Statistical Software 9 (April): 1–19. https://doi.org/10.18637/jss.v009.i08.\n\n\n———. 2011. Complex Surveys: A Guide to Analysis Using R. John\nWiley & Sons.\n\n\n———. 2024. “Survey: Analysis of Complex Survey Samples.”\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in r:\nStatistical Programming for Data Science, Analysis and Finance.\nSPRINGER.\n\n\nMerkel, Dirk. 2014. “Docker: Lightweight Linux Containers for\nConsistent Development and Deployment.” Linux Journal\n2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy\nVasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and\nTimnit Gebru. 2019. “Model Cards for Model Reporting.” In,\n220–29. https://doi.org/10.1145/3287560.3287596.\n\n\nPrabhu, Anirudh, and Peter Fox. 2020. “Reproducible\nWorkflow,” December. http://arxiv.org/abs/2012.13427.\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: Venv -\nCreation of Virtual Environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\nR Core Team. 2023a. Foreign: Read Data Stored by ’Minitab’, ’s’,\n’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\n———. 2023b. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\n“R Packages (2e).” n.d. https://r-pkgs.org/.\n\n\nrOpenSci, Brooke Anderson, Scott Chamberlain, Laura DeCicco, Julia\nGustavsen, Anna Krystalli, Mauro Lepore, et al. 2024. “rOpenSci Packages: Development, Maintenance, and Peer\nReview.” Zenodo. https://doi.org/10.5281/zenodo.10797633.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig.\n2013. “Ten Simple Rules for Reproducible Computational\nResearch.” PLOS Computational Biology 9 (10): e1003285.\nhttps://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSärndal, Carl-Erik, Bengt Swensson, and Jan Wretman. 2003. Model\nAssisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, and Alexander Walker. 2024. Openxlsx: Read,\nWrite and Edit Xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nSchneider, Benjamin. 2023. “Svrep: Tools for Creating, Updating,\nand Analyzing Survey Replicate Weights.” https://CRAN.R-project.org/package=svrep.\n\n\nSottile, Anthony, and Contributors. 2024. Pre-Commit: A Framework\nfor Managing and Maintaining Multi-Language Pre-Commit Hooks. https://pre-commit.com.\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D. Peng. 2014.\nImplementing Reproducible Research. CRC Press.\n\n\nThomas Mailund. 2017. Metaprogramming in r. 1st ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nUshey, Kevin, and Hadley Wickham. 2023. Renv: Project\nEnvironments. https://CRAN.R-project.org/package=renv.\n\n\nVargas, Mauricio. 2024. Casen: Metodos de Estimacion Con Disenio\nProbabilistico y Estratificado En Encuesta CASEN (Estimation Methods\nwith Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. “Reproducibility and Replicability in\nEconomics.” Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, and Matt Herman. 2024. Tidycensus: Load US Census\nBoundary and Attribute Data as ’Tidyverse’ and ’Sf’-Ready Data\nFrames. https://walker-data.com/tidycensus/.\n\n\nWickham, Hadley. 2011b. “Testthat: Get Started with\nTesting.” The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2011a. “Testthat: Get Started with Testing.” The R\nJournal 3: 5–10. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced r, Second Edition. CRC Press.\n\n\n———. 2023. Httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher.\n2024. Usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster.\n2024. Roxygen2: In-Line\nDocumentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, Maëlle Salmon, Olivier Roy, and Salim\nBrüggemann. 2024. Pkgdown: Make Static HTML Documentation for a\nPackage. https://CRAN.R-project.org/package=pkgdown.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, and Jennifer Bryan. 2022.\nDevtools: Tools to Make Developing r Packages Easier. https://CRAN.R-project.org/package=devtools.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2023. Haven: Import\nand Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "Biblografía"
    ]
  },
  {
    "objectID": "Appendices/AppendixA.html",
    "href": "Appendices/AppendixA.html",
    "title": "Apéndice A — Apendice",
    "section": "",
    "text": "Código A.1: Instalación del paquete\n\n\n\nbranch &lt;- \"develop\"\n\nis_available &lt;- \"metasurvey\" %in% rownames(\n available.packages(\n    repos = \"https://cloud.r-project.org/\"\n    )\n  )\n\n  if (is_available) {\n    install.packages(\"metasurvey\")\n  } else {\n    remotes::install_github(\n      \"metasurveyr/metasurvey\",\n      ref = branch,\n      force = TRUE\n    )\n    message(\"Se instaló la versión de desarrollo de metasurvey\")\n  }",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Apendice</span>"
    ]
  }
]