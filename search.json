[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metasurvey",
    "section": "",
    "text": "Descripción del proyecto metasurvey\n\n\nEste paquete proporciona un conjunto de funciones para facilitar el análisis de datos de encuestas con diseño muestral utilizando técnicas de metaprogramación. Permite crear pipelines de análisis reproducibles y generar informes y tablas fácilmente. El paquete está diseñado para trabajar con survey y es particularmente útil para diseños de encuestas complejos. Fue desarrollado en el contexto de un trabajo final de grado de la Licenciatura en Estadística de la Facultad de Ciencias Económicas de la Universidad de la República.\n\n\nLa idea inicial surgió debido a la dificultad de trabajar con microdatos de encuestas cuyos formularios son extensos y complejos, y que cambian de un año a otro. Esto hace que sea difícil mantener actualizados los códigos de análisis de datos y puede llevar a errores en la interpretación de los resultados.\n\n\nAdemás, en algunos casos se requiere analizar una serie de resultados de encuestas de diferentes años, lo que hace necesario unificar los códigos de análisis para poder comparar los resultados a lo largo del tiempo y realizar análisis longitudinales. Esto puede ser caótico, especialmente cuando se tienen muchos años de encuestas. A menudo, se obtienen indicadores de forma independiente para cada año y luego se guardan los resultados en una tabla de Excel o en un archivo de texto.\n\n\nEntender cómo se codifican las variables de las encuestas puede ser muy difícil, ya que cada programa estadístico maneja los datos de manera diferente y cada usuario tiene su propio estilo de programación. Además, puede ser necesario contar con un software específico para analizar los datos de la encuesta, lo que puede ser un problema si no se dispone del mismo.\n\n\nPor lo tanto, la idea de este paquete es facilitar el análisis de datos de encuestas con diseño muestral complejo, permitiendo la creación de pipelines de análisis reproducibles y la generación de informes y tablas de forma sencilla. El paquete está diseñado para trabajar con survey y es particularmente útil para diseños de encuestas complejos.\n\n\nEl paquete proporciona funciones para facilitar la estimación de la varianza de diseños de encuestas complejos y para el análisis de estos diseños utilizando survey.\n\n\nSu desarrollo fue motivado por el portal PRISMA, un portal de datos abiertos de la Agencia Nacional de Investigación e Innovación (ANII) de Uruguay. En el portal, la sección de Innovación y Género cuenta con una serie de indicadores que provienen de encuestas por muestreo. Construir estos indicadores de forma histórica y compararlos a lo largo del tiempo es un desafío, ya que las encuestas cambian de un año a otro y los códigos de análisis deben ser actualizados, siendo transparente para el usuario final cómo se codifican las variables.\n\n\nEn 2022, se presentó una versión previa en LatinR 2022 llamada srvyuRu. Esta versión era demasiado lenta tanto en los cálculos como en la transparencia de la codificación de variables. Por lo tanto, en 2023 se decidió reescribir el paquete en su totalidad y cambiar su nombre a metasurvey, haciendo referencia a la meta-programación utilizada en conjunto con survey.\n\n\nEl paquete incluye funciones para facilitar la carga de datos de encuestas, la recodificación de variables, la estimación de la varianza de diseños de encuestas complejos, la generación de tablas y gráficos, y la creación de informes. También facilita la creación de pipelines de análisis reproducibles y la generación de informes y tablas de forma sencilla.\n\n\nLa documentación del paquete está disponible en metasurveyr.github.io/metasurvey y el código fuente en github.com/metasurveyr/metasurvey, donde se puede colaborar en el desarrollo del paquete y reportar errores.\n\n\nDurante el desarrollo del proyecto se utilizaron diversas herramientas tanto dentro como fuera de R. Dentro de R se usaron devtools para la creación del paquete, roxygen2 para la documentación, testthat para tests unitarios, pkgdown para la página web del paquete, usethis para la creación de issues y pull requests, y covr para la cobertura de tests unitarios. Fuera de R se usaron pre-commit para hooks de pre-commit, codecov para la cobertura de tests unitarios, y GitHub Actions para workflows de GitHub Actions.\n\n\nEn el futuro, se espera contar con más colaboradores para avanzar en el desarrollo del paquete y publicarlo en CRAN para que pueda ser utilizado por toda la comunidad de R. El paquete está abierto a la comunidad de R y especialmente a estudiantes de estadística con un enfoque en herramientas computacionales que quieran colaborar en su desarrollo.\n\n\nPara revisar el estado actual del proyecto, consulte el cronograma donde se pueden ver las tareas realizadas y planificadas. También hay una lista de issues donde se pueden reportar problemas.\n\n\nA diciembre de 2024, el paquete no está disponible en CRAN, pero se espera que en 2025 esté publicado en CRAN para que pueda ser utilizado por toda la comunidad de R. Mientras tanto, se puede instalar la versión de desarrollo desde el repositorio de Github con el siguiente código:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"metasurveyR/metasurvey\")",
    "crumbs": [
      "Descripción del proyecto"
    ]
  },
  {
    "objectID": "chapters/chapter1.html",
    "href": "chapters/chapter1.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Motivación\nEn este trabajo se presenta el paquete metasurvey, una herramienta para el procesamiento y obtención de indicadores a partir de encuestas por muestreo. El paquete proporciona al usuario control total y transparencia en el proceso de transformación de microdatos a indicadores, permitiendo validar y entender su construcción. Además, facilita la creación de variables sintéticas, recodificación de variables con criterios complejos y el tratamiento de variables continuas como el ingreso salarial mediante una metodología rigurosa y fácil de implementar. Es crucial que este proceso sea transparente y entendible para el usuario.\nLas encuestas por muestreo son una herramienta fundamental para la obtención de información sobre una población de interés, ya que permiten obtener datos a partir de una muestra representativa. Sin embargo, el procesamiento de encuestas puede ser tedioso, propenso a errores y difícil de transparentar y reproducir, especialmente al generar indicadores como tasas de mercado laboral, ingreso salarial e índices de pobreza (Vilhuber 2020).\nDado que las herramientas actuales no permiten flexibilidad al usuario, metasurvey se presenta como una alternativa que incorpora flexibilidad y transparencia en el proceso de transformación de microdatos a indicadores.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#contexto",
    "href": "chapters/chapter1.html#contexto",
    "title": "1  Introducción",
    "section": "1.2 Contexto",
    "text": "1.2 Contexto\nEn la teoría de la inferencia de poblaciones finitas, es crucial considerar la incertidumbre y los errores asociados a las estimaciones producidas. Generalmente, esto no es tomado en cuenta por usuarios no expertos en metodología de muestreo, lo que puede llevar a conclusiones erróneas. En algunos casos, el estimador asociado a la estimación puede tener una alta variabilidad o haber sido calculado sin considerar el diseño muestral correcto.\nEs importante distinguir entre los enfoques de inferencia estadística model-based inference y design-based inference (Lumley 2011). En el primer enfoque, se asume que la población de interés puede modelarse mediante un modelo probabilístico, y se obtienen estimaciones de los parámetros del modelo mediante técnicas de inferencia estadística. En el segundo enfoque, se asume que la población de interés es finita y se obtienen estimaciones de los parámetros de la población mediante técnicas de muestreo.\nEn este trabajo se mencionará intensivamente el concepto de peso o ponderador y su importancia en la estimación de varianzas y errores asociados a las estimaciones. En estadística, existen diferentes conceptos referidos a ponderadores o pesos, entre ellos (basado en (Lumley 2011)):\n\nPesos muestrales: Refieren a la cantidad de veces que un individuo de la población de interés está representado en la muestra. Estos pesos provienen del diseño muestral, ya sea por el inverso de las probabilidades de selección, ajustes por no respuesta, entre otros.\nPesos de precisión: Relacionados con la variabilidad que tiene una observación sobre la estimación de un parámetro.\nPesos de frecuencia: Refieren a la cantidad de veces que aparece un individuo en una muestra y se resumen para incluir en un único registro.\n\nEs importante hacer esta distinción ya que, tomando en cuenta los pesos en cualquiera de sus definiciones, en la mayoría de los casos se pueden obtener estimaciones puntuales correctas. Sin embargo, como se mencionó anteriormente, llegar a medidas de incertidumbre como errores estándar e intervalos de confianza puede ser incorrecto.\nAdemás de la inferencia, es crucial considerar el proceso de transformación de los microdatos a indicadores para interpretar correctamente los indicadores y realizar comparaciones a lo largo del tiempo. Muchas veces, diferentes usuarios realizan el mismo esfuerzo de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología, ya que cada uno utiliza su propio estilo de programación o diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA. Aunque el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa.\nEn los últimos años, el uso de R (R Core Team 2023) ha crecido exponencialmente en la comunidad científica, especialmente en estadística y ciencia de datos. R es un lenguaje de programación de código abierto ampliamente utilizado para el análisis de datos, estadística y aprendizaje automático. En R, se utiliza el concepto de paquete para referirse a una colección de funciones, métodos y clases que extienden las funcionalidades de R propuestas por la comunidad de usuarios. En este sentido, metasurvey busca ser una herramienta relevante para el trabajo con encuestas por muestreo en diversas disciplinas, solucionando las limitaciones mencionadas anteriormente.\nEs importante definir el concepto de Estadística Computacional y su diferencia con Computación Estadística (Cook 2014), siendo este trabajo un aporte a la Estadística Computacional. La Estadística Computacional se refiere a la implementación de algoritmos y métodos estadísticos en un lenguaje de programación, mientras que la Computación Estadística se refiere a la utilización de herramientas computacionales para resolver problemas estadísticos. R permite realizar tanto Estadística Computacional como Computación Estadística, ya que cuenta con una amplia variedad de paquetes que permiten implementar algoritmos y métodos estadísticos y realizar análisis de datos de manera eficiente y reproducible.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#antecedentes-e-implementaciones-similares",
    "href": "chapters/chapter1.html#antecedentes-e-implementaciones-similares",
    "title": "1  Introducción",
    "section": "1.3 Antecedentes e implementaciones similares",
    "text": "1.3 Antecedentes e implementaciones similares\nActualmente existen diversos esfuerzos para facilitar el procesamiento de encuestas. Estos pueden clasificarse principalmente en dos tipos de paquetes:\n\nPaquetes para inferencia estadística: Implementan metodologías de inferencia en muestreo de poblaciones finitas, como survey (Lumley 2024), gustave (Chevalier 2023), vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023) y weights.\nPaquetes para encuestas específicas: Permiten acceder y manipular datos de encuestas particulares:\n\nech: Procesa la Encuesta Continua de Hogares (ECH) del Instituto Nacional de Estadística (INE) de Uruguay (Detomasi 2020)\neph: Procesa la Encuesta Permanente de Hogares (EPH) del Instituto Nacional de Estadística y Censos (INDEC) de Argentina (Kozlowski et al. 2020)\ntidycensus: Obtiene datos del Censo de Estados Unidos (Walker y Herman 2024)\ncasen: Procesa la Encuesta de Caracterización Socioeconómica Nacional (CASEN) del Ministerio de Desarrollo Social y Economía de Chile (Vargas 2024)\n\n\nSin embargo, estos últimos tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés, como puede ser el índice de pobreza, tasas del mercado laboral, ingreso salarial, etc. En general, sus implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica. Además en las implementaciones actuales, el usuario cuenta con una función de alto nivel que actúa como una caja negra, donde no se permite modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin tener que leer el código fuente o la documentación adjunta.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#propuesta",
    "href": "chapters/chapter1.html#propuesta",
    "title": "1  Introducción",
    "section": "1.4 Propuesta",
    "text": "1.4 Propuesta\nPara científicos sociales, es importante tener en cuenta que el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Es de interés obtener información histórica de indicadores y en general es un proceso tedioso y propenso a errores, especialmente si proviene de encuestas donde su estructura y/o forma de preguntar o su codificación puede cambiar con el tiempo. Esto resulta en un proceso extenso y difícil de entender hasta llegar a la construcción de esta serie de indicadores. Muchas veces, diferentes usuarios hacen el mismo proceso de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.\nEn este sentido, es importante que el usuario pueda tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, además de brindar una herramienta común libre de estilos de programación y definiendo con simples pasos el proceso de construcción de variables sintéticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodología rigurosa y fácil de referenciar en la implementación. Es crucial que este proceso sea transparente y entendible para el usuario. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metasurvey y su implementación de recetas para la construcción de indicadores mediante la meta-programación.\nAl trabajar con encuestas por muestreo, es importante tener en cuenta la forma en la que se obtuvieron los datos y su proceso generador para poder realizar inferencias sobre la población de interés. En general, obtener estimaciones puntuales de estadísticos de totales, promedios o proporciones es relativamente sencillo, pero puede ser que se reporte una estimación donde no exista un tamaño de muestra suficiente para obtener una estimación confiable y/o que la variabilidad de la estimación sea alta y no sea recomendable su uso. En este sentido, es importante que el usuario no experto tenga de forma nativa una forma de obtener estimaciones puntuales y sus errores asociados de manera sencilla. Es común utilizar estimaciones puntuales sin tener una medida de incertidumbre o aún peor incluir una estimación del error estándar sin tener en cuenta el diseño muestral correcto, lo que puede llevar a conclusiones erróneas sobre la variabilidad de la estimación. metasurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de forma nativa y con estos resultados hacer recomendaciones sobre la utilidad y confianza de la estimación mediante coeficientes de variación, intervalos de confianza, tamaño de muestra efectivo, entre otros sin tener que ser un experto en metodología de estimación de varianzas y remuestreo. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metasurvey y su implementación de estimaciones puntuales y sus errores asociados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#definición-del-alcance",
    "href": "chapters/chapter1.html#definición-del-alcance",
    "title": "1  Introducción",
    "section": "1.5 Definición del Alcance",
    "text": "1.5 Definición del Alcance\nmetasurvey está diseñado para científicos sociales, estadísticos y economistas que trabajan con encuestas por muestreo. Permite a estos usuarios manejar y transformar microdatos en indicadores de manera transparente, flexible y reproducible.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#desarrollo-del-paquete-metasurvey",
    "href": "chapters/chapter1.html#desarrollo-del-paquete-metasurvey",
    "title": "1  Introducción",
    "section": "1.6 Desarrollo del paquete metasurvey",
    "text": "1.6 Desarrollo del paquete metasurvey\nEl desarrollo de un paquete en R es un proceso que requiere contar con una idea bien formada y los medios para llevarla a cabo, es por esto que es importante contar con una metodología de trabajo ordenada, heredada del desarrollo de software convencional, ya que para la publicación y difusión del paquete se tienen que cumplir con ciertos estándares de calidad y documentación para que otros usuarios puedan utilizarlo. En este sentido, es importante tener en cuenta que el desarrollo de un paquete en R puede llevar tiempo y esfuerzo, a consecuencia de esto, en el documento se presentarán diferentes conceptos sobre metodología para el desarrollo de paquetes en R y se abordarán ejemplos con la implementación de metasurvey.\nEn este sentido, metasurvey pretende ser una herramienta relevante para el trabajo con encuestas por muestreo en general ya sea en las ciencias sociales o el uso genérico para otras disciplinas, buscando solucionar las limitaciones anteriormente mencionadas. Todo el proceso de transformación de los microdatos a indicadores se realiza a través de una serie de funciones que permiten al usuario tener un control total y transparente sobre el proceso de transformación de los microdatos a indicadores. Además, metasurvey permite que el usuario pueda realizar el proceso de transformación de los microdatos a indicadores de manera reproducible y transparente. El usuario puede compartir el código de una forma entendible, casi como un “recetario de cocina”. El procedimiento aplicado a los datos utilizados para obtener los indicadores se realiza mediante lo que denominamos steps y recipes, conformando así una especie de camino transparente para la construcción de indicadores. Esto permite compartir en forma visual un DAG (Directed Acyclic Graph) que permite visualizar el proceso de construcción de indicadores sin tener que abrir un script de R. En complemento al proceso de creación de variables, metasurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de manera sencilla y brindar recomendaciones sobre la utilidad de la estimación en el caso de que se cuente con una variabilidad alta en la estimación, en base a recomendaciones a su coeficiente de variación o métricas similares.\nEl enfoque que permite la flexibilidad a la hora de construir los indicadores es la meta-programación. La meta-programación es un paradigma de programación que permite que un programa pueda modificar su estructura interna en tiempo de ejecución. En R, la meta-programación se realiza a través de las funciones eval, parse, substitute, do.call y quote, que permiten evaluar y parsear código de manera dinámica. En este sentido, metasurvey utiliza la meta-programación para permitir que el usuario pueda modificar el código que se utiliza para transformar los microdatos a indicadores, teniendo funciones de alto nivel similares a las que se utilizan en el paquete recipes de la librería tidymodels (Kuhn, Wickham, y Hvitfeldt 2024).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#esquema-del-documento",
    "href": "chapters/chapter1.html#esquema-del-documento",
    "title": "1  Introducción",
    "section": "1.7 Esquema del documento",
    "text": "1.7 Esquema del documento\nEl documento se estructura de la siguiente manera: en el siguiente capítulo se presentará un marco conceptual básico sobre el muestreo de poblaciones finitas, diferentes paradigmas de programación como puede ser la programación orientada a objetos, programación funcional y la meta-programación y como se utilizan en el desarrollo del paquete. Luego, se ahondará en antecedentes previos tanto en la parte de metodología de estimación de varianzas y paquetes e ideas similares donde se basa el desarrollo del paquete. Finalmente, se presentarán ejemplos de cómo utilizar el paquete metasurvey para construir indicadores de mercado laboral a partir de los microdatos de la ECH y para mostrar su flexibilidad, se incluirá un ejemplo con la EPH.\nEste documento puede leerse en su formato de pagina web o en su formato de documento PDF. Tanto el código fuente del paquete se encuentran disponibles de forma pública en el repositorio de Github y el código fuente de este documento se encuentra disponible en el repositorio. Para la realización de este documento se utilizó quarto (Publishing 2024) para la generación de documentos dinámicos que permiten escribir texto junto con código R.\nPara finalizar, es importante mencionar que el paquete metasurvey es un proyecto en desarrollo y se encuentra en una etapa temprana de desarrollo, por lo que se espera que en el futuro se realicen mejoras y se agreguen nuevas funcionalidades, por lo que se invita a la comunidad a colaborar en el desarrollo del paquete a través de la creación de issues en el repositorio de GitHub o mediante pull requests con mejoras o nuevas funcionalidades.\nPara poder continuar con el documento, se recomienda instalar metasurvey en su versión de desarrollo, para ello se puede ejecutar el siguiente código 1.1\n\n\n\nCódigo 1.1: Instalación de metasurvey\n\n\n\n\nbranch &lt;- \"develop\"\n\nis_available &lt;- \"metasurvey\" %in% rownames(\n  available.packages(\n    repos = \"https://cloud.r-project.org/\"\n  )\n)\n\nif (is_available) {\n  install.packages(\"metasurvey\")\n} else {\n  remotes::install_github(\n    \"metasurveyr/metasurvey\",\n    ref = branch,\n    force = TRUE\n  )\n  message(\"Se instaló la versión de desarrollo de metasurvey\")\n}\n\n\n\n\n\n\n\n\nBreidaks, Juris, Martins Liberts, y Santa Ivanova. 2020. vardpoor: Estimation of indicators on social exclusion and poverty and its linearization, variance estimation. Riga, Latvia: Central Statistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChevalier, Martin. 2023. gustave: A User-Oriented Statistical Toolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCook, Di. 2014. «Statistical Computing Research |». http://dicook.org/2014/10/05/content/post/2014-10-5-statistical-computing/.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. «ech: Caja de herramientas para procesar la Encuesta Continua de Hogares». https://github.com/calcita/ech.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, y Natsumi Shokida. 2020. eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, y Emil Hvitfeldt. 2024. recipes: Preprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLumley, Thomas. 2011. Complex Surveys: A Guide to Analysis Using R. John Wiley & Sons.\n\n\n———. 2024. «survey: analysis of complex survey samples».\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nSchneider, Benjamin. 2023. «svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights». https://CRAN.R-project.org/package=svrep.\n\n\nVargas, Mauricio. 2024. casen: Metodos De Estimacion Con Disenio Probabilistico y Estratificado en Encuesta CASEN (Estimation Methods with Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, y Matt Herman. 2024. tidycensus: Load US Census Boundary and Attribute Data as ’tidyverse’ and ’sf’-Ready Data Frames. https://walker-data.com/tidycensus/.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html",
    "href": "chapters/chapter2.html",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1 Inferencia en muestreo de poblaciones finitas\nEl objetivo principal de este capítulo es presentar los conceptos básicos que se utilizarán a lo largo de este trabajo, en específico en el capítulo 3. Se introducirán ejemplos prácticos para facilitar la comprensión de inferencia en muestreo de poblaciones finitas.\nComo fue mencionado anteriormente las encuestas por muestreo son la principal fuente de información para la construcción de indicadores socio-demográficos y económicos, en este sentido, es importante tener en cuenta un marco teórico para realizar estas inferencias. Es sumamente sencillo obtener estimaciones puntuales de un determinado estadístico aunque es importante considerar la variabilidad de los estimadores, tanto para poder realizar un proceso de inferencia completo así como también para poder cuantificar la confiabilidad de la estimación.\nA continuación, se definen los conceptos básicos de inferencia en muestreo de poblaciones finitas como son el diseño muestral, probabilidades de inclusión basadas en el diseño, estimadores de Horvitz-Thompson HT, ponderación, medidas de incertidumbre y errores estándar basados en (Särndal, Swensson, y Wretman 2003).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "href": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1.1 Diseño muestral\nEl concepto de diseño muestral refiere al mecanismo mediante el cual se selecciona una muestra e inducen propiedades estadísticas claves como puede ser la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. En diseños sencillos es posible calcular la función de diseño o encontrar una expresión analítica con facilidad mientras que en diseños mas complejos como pueden ser los multietapicos es necesario abordar el problema de otra forma y asumir ciertas hipótesis para poder construir probabilidades de inclusión tanto de primer orden como segundo orden el cual sera abordado en la sección 2.1.2\nLa definición matemática se basa en que dado un universo \\(U\\) de \\(N\\) elementos (puede ser conocido o no) \\(\\{u_{1},u_{2}, \\cdots, u_{N}\\}\\) y se considera un conjunto de tamaño \\(n\\) de elementos de \\(U\\) que se denota como \\(s = \\{u_{1},u_{2}, \\cdots, u_{n}\\}\\) al cual comúnmente denominamos muestra, el diseño muestral puede definirse de la siguiente forma:\n\\[\nPr(S = s) = p(s)\n\\]\nRealizando un poco de inspección en la definición anterior se puede observar que el diseño muestral es una función de probabilidad que asigna una probabilidad a cada subconjunto de \\(U\\) de tamaño \\(n\\). En este sentido, es posible definir diferentes tipos de diseño, entre ellos los mas comunes:.\n\nDiseño Aleatorio Simple (SI)\n\nEl diseño aleatorio simple es el diseño más sencillo y se define de la siguiente forma:\n\\[\np(s) = \\frac{1}{\\binom{N}{n}}\n\\]\nEjemplo: Si se tiene una población de 1000 individuos y se desea seleccionar una muestra de 100 de manera aleatoria, cada combinación de 100 individuos tiene la misma probabilidad de ser seleccionada.\n\nDiseño Bernoulli (BE)\n\nEl (BE) es un diseño sencillo que se utiliza cuando se desea seleccionar una muestra de un universo de tamaño \\(N\\) además de considerar una una probabilidad de inclusión \\(\\pi\\) para cada elemento de \\(U\\). Se define el diseño Bernoulli de la siguiente forma:\n\\[\np(s) = \\underbrace{\\pi \\times \\pi \\times \\cdots \\times \\pi}_{n_{s}} \\times \\underbrace{(1-\\pi) \\times (1-\\pi) \\times \\cdots \\times (1-\\pi)}_{N-n_{s}} = \\pi ^{n_{s}} (1-\\pi)^{N-n_{s}}\n\\]\nUna diferencia fundamental entre el diseño (BE) y el diseño SI es que en el BE el tamaño de muestra es aleatorio y su distribución es binomial, mientras que en el diseño SI el tamaño de muestra es fijo.\n\nDiseño Estratificado (ST)\n\nEl diseño estratificado es un diseño que se utiliza cuando se desea seleccionar una muestra de tamaño \\(n\\) de un universo de tamaño \\(N\\) donde además se quiere dividir el universo en \\(H\\) estratos \\(U_{1}, U_{2}, \\cdots, U_{H}\\). Dentro de cada estrato se selecciona una muestra de tamaño \\(n_{h}\\) y se define el diseño estratificado de la siguiente forma:\n\\[\np(s) = \\prod_{l=1}^{H} p(s_{H})\n\\]\nEn cada estrato se puede utilizar un diseño diferente pero en general se utiliza el diseño SI, mas conocido STSI (Stratified Simple Random Sampling). En este caso cada \\(p_{h}(s_{h})\\) es el diseño aleatorio simple en el estrato \\(h\\).\n\n\n2.1.2 Probabilidades de inclusión y estimador de Horvitz-Thompson\nUna vez definido el concepto de diseño muestral es posible definir la probabilidad de que un elemento de la población sea seleccionado en la muestra, esta probabilidad se conoce como probabilidad de inclusión y se define de la siguiente forma:\n\nProbabilidad de inclusión de primer orden\n\n\\[\n\\pi_{k} = Pr(u_{k} \\in s) = Pr(I_{k} = 1)\n\\]\nDonde \\(I_{k}\\) es una variable aleatoria que toma el valor de 1 si el elemento \\(u_{k}\\) es seleccionado en la muestra y 0 en caso contrario. Definir estas variables indicadoras son de utilizada para entender el comportamiento de los estimadores bajo el diseño muestral y nos permite definir los estimadores en \\(U\\) y no en \\(S\\). Es claro que \\(I_{k} \\sim Bernoulli(\\pi_{k})\\) y \\(E(I_{k}) = Pr(I_{k}) = \\pi_{k}\\).\nEsta probabilidad es importante ya que es la la base para la construcción de estimadores insesgados y eficientes, en este sentido, es posible definir el estimador de Horvitz-Thompson (HT) para estimar un total \\(t = \\sum_{U} {t_{k}}\\) de la siguiente forma:\n\\[\n\\hat{t}_{y} = \\sum_{k=1}^{N} \\frac{y_{k}}{\\pi_{k}} \\times I_{k}\n\\]\nEste estimador es propuesto por Horvitz y Thompson en 1952 y es un estimador insesgado en el diseño, en el sentido de que \\(E(\\hat{t}_{y}) = t\\) y es eficiente en el sentido de que \\(Var(\\hat{t}_{y})\\) es el menor posible entre los estimadores insesgados. Este estimador es muy utilizado en la práctica y es la base para la construcción de otros estadísticos,como medias, proporciones, varianzas, entre otros. Para mas detalles sobre las propiedades de Horvitz-Thompson (HT) se puede consultar en (Särndal, Swensson, y Wretman 2003) y (Horvitz y Thompson 1952).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#diseños-muestrales-conceptos-clave",
    "href": "chapters/chapter2.html#diseños-muestrales-conceptos-clave",
    "title": "2  Marco conceptual",
    "section": "2.2 2.1 Diseños muestrales: conceptos clave",
    "text": "2.2 2.1 Diseños muestrales: conceptos clave\n\n2.2.1 Ponderación basada en el diseño y estimadores más comunes\nEn general es utilizado el concepto de ponderador para realizar estimaciones de totales, medias, proporciones, varianzas, entre otros. En este sentido, es posible definir el ponderador inducido por el diseño muestral de la siguiente forma:\n\\[\nw_{k} = \\frac{1}{\\pi_{k}}\n\\]\nEste ponderador puede interpretarse como el número individuos que representa el individuo \\(k\\) en la población. Este valor es el que comúnmente se publica junto a los microdatos y el estándar en los diferentes softwares para procesar encuestas. Junto al estimador de un total es posible definir el estimador de un promedio, proporción o razón en el contexto de la $-expansión.\n\nEstimador de un promedio\n\\[\n\\hat{\\bar{y}} = \\frac{\\sum_{k=1}^{N} w_{k} I_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}}\n\\]\nEste estimador puede ser utilizados en encuestas de hogares, donde se desea estimar el ingreso promedio de los hogares de una región de forma anual, o mensual.\n\n\nEstimador de una proporción\n\\[\n\\hat{p} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\hat{N}}\n\\]\nPuede ser de interés estimar la proporción de hogares que tienen acceso a internet en una región, en este caso se puede utilizar el estimador de proporción.\n\n\nEstimador de una razón\nSe quiere estimar la razón \\(R = \\frac{\\sum_{k=1}^{N} y_{k}}{\\sum_{k=1}^{N} z_{k}}\\). En este caso se puede definir el estimador de la razón de la siguiente forma:\n\\[\n\\hat{R} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k}z_{k}} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\hat{N}}\n\\]\nEl estimador de razón es utilizado para construir variables de mercado de trabajo como la tasa de desempleo, tasa de ocupación, entre otros.\n\n\nInferencia sobre el tamaño de la población\nUna vez definidos los estimadores, podemos ver que los estimadores de medias y proporciones son un caso particular del estimador de razón. Un detalle no menor es que asumimos \\(N\\) fijo pero desconocido, por esto al realizar proporciones se ajusta el total sobre un estimador del tamaño de la población:\n\\[\n\\hat{N} = \\sum_{k=1}^{N} I_{k}w_{k}\n\\]\nExisten diseños denominados auto-ponderados donde por definición \\(\\sum_{k=1}^{N} w_{k} = N\\), en este caso particular el estimador de medidas y proporciones es un caso particular del estimador de total, ya que el estadístico puede definirse de la siguiente forma:\n\\[\n\\hat{\\bar{y}}_{s} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{N} = \\frac{1}{N} \\times \\sum_{k=1}^{N} I_{k} w_{k} y_{k} = a \\times \\hat{t}_{y}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#ponderadores-y-estimadores-comunes",
    "href": "chapters/chapter2.html#ponderadores-y-estimadores-comunes",
    "title": "2  Marco conceptual",
    "section": "2.3 2.2 Ponderadores y estimadores comunes",
    "text": "2.3 2.2 Ponderadores y estimadores comunes\n\n2.3.1 Medidas de incertidumbre y errores estándar\nSe puede medir la variabilidad de los estimadores y calcular su varianza. Para detalles completos de los cálculos de varianza, consulte el Apéndice A.\n\n2.3.1.1 Momentos muéstrales y estimadores de varianza\nPara un estadístico \\(\\theta\\), su varianza bajo un diseño muestral \\(p(s)\\) se define como:\n\\[\nV(\\hat{\\theta}) = E((\\theta - E(\\hat{\\theta}))^{2}) = \\sum_{s \\in S}{p(s)\\left(\\hat{\\theta}_{s} - E(\\hat{\\theta}_{s})\\right)}\n\\]\nLa forma de calcular la varianza depende del estimador \\(\\hat{\\theta}\\). Por ejemplo, para el estimador de varianza de un total, se utiliza la siguiente fórmula:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k} \\times y_{k} \\times w_{k})} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k} \\times y_{k} \\times w_{k}, I_{l} \\times y_{l} \\times w_{l})}}\n\\]\nDespués de simplificar, obtenemos:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k}) \\times w_{k} \\times y_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k}, I_{l}) \\times y_{k} \\times w_{k} \\times y_{l}  \\times w_{l} }}\n\\]\nDonde definimos las siguientes identidades para simplificar cálculos:\n\\[\nCov(I_{k}, I_{l}) = \\Delta_{kl} = \\pi_{kl} - \\pi_{k} \\times \\pi_{l}\n\\]\n\\[\n\\check{y}_{k} = y_{k} \\times w_{k}\n\\]\n\\[\n\\check{\\Delta}_{kl} = \\Delta_{kl} \\times \\frac{1}{\\pi_{kl}} = \\Delta_{kl} \\times w_{kl}\n\\]\nUna vez definida la varianza del estimador, necesitamos estimar su varianza. Para esto, utilizamos la técnica de \\(\\pi\\)-expansión. Después de algunas manipulaciones algebraicas, obtenemos la varianza del estimador:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{\\check{y}_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} } = \\sum_{U}{\\sum{\\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }}\n\\]\nPodemos verificar que este estimador de varianza es insesgado con las definiciones de \\(E(I_{k}I_{l})\\) y tomando esperanzas. Es decir, se verifica que \\(E(\\hat{V}(\\hat{t}_{y})) = V(\\hat{t}_{y})\\). Al ser un estimador insesgado, su eficiencia depende del diseño muestral y de la varianza de los ponderadores, es decir, de la varianza de las probabilidades de inclusión. En algunos casos, es donde entra en juego dividir grupos heterogéneos en estratos o realizar muestreos en varias etapas.\nPara el caso de un estimador de un promedio, la varianza se define de la siguiente forma: \\[\nV(\\hat{\\bar{y}}) = \\frac{1}{N^{2}} \\times \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }\n\\]\nEsto es válido en el caso de contar con un tamaño de población conocido. En otro caso, el estimador de la media no es un estimador lineal y para calcular su varianza deben optarse por métodos de estimación de varianzas más complejos como el de linealización de Taylor.\nEs importante considerar que en esta sección se presenta un caso ideal donde la muestra es obtenida de un listado perfecto de la población objetivo denominado marco de muestreo. En la práctica, el marco de muestreo es imperfecto y se debe considerar la no respuesta, la cobertura y la falta de actualización del marco de muestreo. En general, para la publicación de microdatos se publican ciertos ponderadores que no son precisamente los ponderadores originales definidos en la sección anterior, sino que son sometidos a un proceso de calibración donde se intenta ajustar a ciertas variables de control y mejorar problemas causados por la no respuesta. Al realizar el proceso de calibración, los ponderadores calibrados son lo más cercano posible a los ponderadores originales, de forma que si los ponderadores originales son insesgados, los ponderadores calibrados serán próximos a ser insesgados.\nEn la práctica, para diseños complejos no se dispone de las probabilidades de selección de segundo orden, insumo principal para calcular los errores estándar. Por esto, se requiere optar por metodologías alternativas como el método del último conglomerado, método de replicación jackknife, método de bootstrap, entre otros. En este sentido, es importante tener en cuenta que la varianza de los estimadores es un componente fundamental para realizar inferencias y cuantificar la confiabilidad de los resultados.\nEn resumen, para realizar estimaciones puntuales ya sean totales, medias, proporciones o razones, simplemente debemos ponderar los datos con los estadísticos anteriormente mencionados. Pero para realizar un proceso de inferencia completo se requiere calcular sus errores estándar, construir intervalos de confianza y/o poder medir la estabilidad de nuestros resultados. En este sentido, es importante tener al alcance herramientas que permitan realizar este tipo de cálculos, ya que en diferentes softwares estadísticos junto a la estimación puntual se presentan los errores estándar asumiendo diseños sencillos, lo cual puede ser erróneo.\nUna vez presentados los conceptos básicos de muestreo, es importante entender cómo esto estará disponible en el paquete metasurvey. Se presentarán los conceptos básicos de programación funcional y orientada a objetos en R, para luego enfocarnos en la meta-programación.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#sec-developmentR",
    "href": "chapters/chapter2.html#sec-developmentR",
    "title": "2  Marco conceptual",
    "section": "2.4 Desarrollo de paquetes en R",
    "text": "2.4 Desarrollo de paquetes en R\nR es un lenguaje de código abierto con una gran comunidad de usuarios en diversas áreas de investigación. Esto ha permitido el desarrollo de una gran cantidad de paquetes que facilitan tareas de análisis de datos, visualización, bioinformática, aprendizaje automático y otras ramas afines a la estadística. Dentro de la comunidad, existen organizaciones que se encargan de mantener la calidad de los paquetes y asegurar que cumplan con ciertos estándares. Una de estas organizaciones es el Comprehensive R Archive Network (CRAN), un repositorio de paquetes de R que contiene versiones estables de los mismos. También existen otros repositorios como Bioconductor, que se especializa en análisis de datos biológicos, y rOpenSci, que se enfoca en la ciencia abierta.\n\n2.4.1 ¿Por qué desarrollar un paquete en R?\nDesarrollar un paquete en R tiene varias ventajas:\n\nReutilización de código: Es posible que alguien ya haya escrito una función que uno necesita. Por lo tanto, siempre es bueno buscar si existe algún paquete que ya tenga las funcionalidades requeridas.\nCompartir código: La comunidad de R es muy activa y siempre está dispuesta a compartir código, lo que fomenta el desarrollo continuo de paquetes.\nColaboración: El trabajo colaborativo es esencial en el desarrollo de paquetes en R, permitiendo que diferentes personas aporten nuevas funcionalidades, correcciones de errores, entre otros.\n\n\n\n2.4.2 Elementos básicos de un paquete en R\nPara que un conjunto de funciones, datos y documentación sea considerado un paquete en R, debe cumplir con ciertos requisitos mínimos:\n\nDirectorio: Un paquete en R debe estar contenido en un directorio que incluya al menos los siguientes archivos y directorios:\n\nR/: Contiene los archivos con las funciones del paquete.\nman/: Contiene los archivos con la documentación de las funciones. Generalmente se utiliza Roxygen2 (Wickham et al. 2024) para generar la documentación.\nDESCRIPTION: Describe el paquete, incluyendo nombre, versión, descripción, autor, entre otros.\nNAMESPACE: Contiene información sobre las funciones que se exportan y las dependencias del paquete.\nLICENSE: Contiene la licencia bajo la cual se distribuye el paquete.\nREADME.md: Proporciona información general sobre el paquete.\n\nDocumentación: Es esencial para que los usuarios puedan entender el funcionamiento de las funciones del paquete. Se realiza utilizando el sistema de documentación de R, basado en comentarios en el código fuente.\nPruebas: Es importante que el paquete tenga pruebas que verifiquen que las funciones se comportan como se espera. Las pruebas se realizan utilizando el paquete testthat (Wickham 2011).\nControl de versiones: Permite llevar un registro de los cambios realizados en el paquete. El sistema de control de versiones más utilizado en la comunidad de R es git.\nLicencia: Permite a los usuarios utilizar, modificar y distribuir el paquete. La licencia más utilizada en la comunidad de R es la licencia MIT.\n\nEl proceso de subir un paquete a CRAN puede ser tedioso, ya que se deben cumplir ciertos requisitos revisados por los mantenedores de CRAN. Sin embargo, es un proceso que vale la pena, ya que permite que el paquete sea utilizado por una gran cantidad de usuarios.\nEl proceso de chequeo fue automatizado con GitHub Actions, por lo que cada vez que se realiza un cambio en el repositorio, se ejecutan los chequeos de CRAN y se notifica si el paquete cumple con los requisitos para ser publicado. En caso de que no cumpla con los requisitos, se notifica el error y no puede ser incluido en la rama principal del repositorio hasta que se corrija.\nTodo el proceso y código fuente del paquete se encuentra disponible en el repositorio de GitHub del paquete. Si está interesado en colaborar con el desarrollo del paquete, puede consultar la guía de contribución.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "href": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "title": "2  Marco conceptual",
    "section": "2.5 Paradigmas de programación en R",
    "text": "2.5 Paradigmas de programación en R\nR es un lenguaje de programación que permite realizar programación funcional y orientada a objetos (Chambers 2014), lo que permite que los usuarios puedan utilizar diferentes paradigmas de programación para resolver problemas. A continuación, se presentan los conceptos básicos de la programación funcional y orientada a objetos en R.\n\n2.5.1 Programación funcional\nLa programación funcional es un paradigma de programación que se basa en el uso de funciones para resolver problemas. En R, las funciones son objetos de primera clase, lo que significa que se pueden utilizar como argumentos de otras funciones, se pueden asignar a variables, entre otros (Wickham 2019, 204-81). A continuación, se presentan los conceptos básicos de la programación funcional en R.\n\nFunciones de orden superior: En R, las funciones de orden superior son funciones que toman como argumento una o más funciones y/o retornan una función. Un ejemplo de una función de orden superior en R es la función lapply que toma como argumento una lista y una función y retorna una lista con los resultados de aplicar la función a cada elemento de la lista.\nFunciones anónimas: En R, las funciones anónimas son funciones que no tienen nombre y se crean utilizando la función function. Un ejemplo de una función anónima en R es la función function(x) x^2 que toma como argumento x y retorna x^2.\nFunciones puras: En R, las funciones puras son funciones que no tienen efectos secundarios y retornan el mismo resultado para los mismos argumentos. Un ejemplo de una función pura en R es la función sqrt que toma como argumento un número y retorna la raíz cuadrada de ese número.\n\nEste paradigma de programación es muy útil para realizar análisis de datos, ya que permite que los usuarios puedan utilizar funciones para realizar operaciones sobre los datos de manera sencilla y eficiente. Dentro de metasurvey no existe una presencia fuerte de programación funcional, sin embargo, se utilizan algunas funciones de orden superior para realizar operaciones sobre los datos.\n\n\n2.5.2 Programación orientada a objetos\nLa programación orientada a objetos es un paradigma de programación que se basa en el uso de objetos para resolver problemas. En R, los objetos son instancias de clases que tienen atributos y métodos (Wickham 2019, 285-370; Mailund 2017). A continuación, se presentan los conceptos básicos de la programación orientada a objetos en R.\n\nClases y objetos: En R, las clases son plantillas que definen la estructura y el comportamiento de los objetos y los objetos son instancias de clases. En R, las clases más utilizadas provienen del sistema de programación orientada a objetos llamado S3. Las clases se definen utilizando la función setClass y los objetos se crean utilizando la función new. También se pueden utilizar las clases del sistema S4, aunque este tiene una sintaxis más compleja y no es tan utilizado.\nAtributos y métodos: En R, los atributos son variables que almacenan información sobre el estado de un objeto y los métodos son funciones que permiten modificar el estado de un objeto. En R, los atributos se definen utilizando la función setClass y los métodos se definen utilizando la función setMethod.\n\nDentro de metasurvey se utiliza la programación orientada a objetos para definir las clases de los objetos que se utilizan para representar los datos de las encuestas mediante la creación de una clase específica llamada Survey que permite, además de almacenar los datos de la encuesta, añadir atributos y métodos que permiten realizar operaciones sobre los datos de manera sencilla y eficiente.\nDe forma similar se modelan las clases Step, Recipe y Survey, entre otras, elementos cruciales en el ecosistema de metasurvey donde se definen los pasos de preprocesamiento, recetas de preprocesamiento y flujos de trabajo respectivamente. En este caso particular se utiliza el paquete R6 (Chang 2022) que permite definir clases de manera intuitiva y eficiente, además de permitir la herencia de clases y la definición de métodos y atributos de manera sencilla.\n\n\n2.5.3 Meta-programación\nLa meta-programación es un paradigma de programación que se basa en el uso de código para manipular código (Wickham 2019, 373-500; Thomas Mailund 2017). En R, la meta-programación se realiza utilizando el sistema de meta-programación de R que se basa en el uso de expresiones, llamadas y funciones. A continuación, se presentan los conceptos básicos de la meta-programación en R.\n\nExpresiones: En R, las expresiones son objetos que representan código y se crean utilizando la función quote. Un ejemplo de una expresión en R es la expresión quote(x + y) que representa el código x + y.\nLlamadas: En R, las llamadas son objetos que representan la aplicación de una función a sus argumentos y se crean utilizando la función call. Un ejemplo de una llamada en R es la llamada call(\"sum\", 1, 2, 3) que representa la aplicación de la función sum a los argumentos 1, 2 y 3.\nFunciones: En R, las funciones son objetos que representan código y se crean utilizando la función function. Un ejemplo de una función en R es la función function(x, y) x + y que representa el código x + y.\n\nEn metasurvey se utiliza la meta-programación para generar código de manera dinámica y realizar operaciones sobre los datos de manera eficiente. En particular, se utiliza la función eval para evaluar expresiones y la función substitute para reemplazar variables en expresiones. Además, se utilizan las funciones lapply, sapply, mapply y do.call para aplicar funciones a listas y vectores de manera eficiente. En general, la meta-programación es una técnica muy útil para realizar operaciones sobre los datos de manera eficiente y sencilla.\nEn el capítulo 3 se presentarán los antecedentes de metodologías de estimación de varianzas, revisión de medidas de incertidumbre, paquetes similares y mejoras que son incorporadas en el paquete metasurvey. En el capítulo 4 se hablará sobre la implementación de las diferentes partes que conforman el paquete, una breve reseña del esquema de test, la API para almacenar las recetas junto a su interacción con el usuario. Posteriormente se mostrará un ejemplo de uso del paquete y se presentarán las conclusiones y trabajos futuros.\n\n\n\n\nChambers, John M. 2014. «Object-Oriented Programming, Functional Programming and R». Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nHorvitz, D. G., y D. J. Thompson. 1952. «A Generalization of Sampling Without Replacement From a Finite Universe». Journal of the American Statistical Association 47 (260): 663-85. https://doi.org/10.2307/2280784.\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in R: Statistical Programming for Data Science, Analysis and Finance. SPRINGER.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nThomas Mailund. 2017. Metaprogramming in R. 1.ª ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nWickham, Hadley. 2011. «testthat: Get Started with Testing». The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced R, Second Edition. CRC Press.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, y Manuel Eugster. 2024. roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html",
    "href": "chapters/chapter3.html",
    "title": "3  Marco teórico",
    "section": "",
    "text": "3.1 Orden Lógico de la Reproducibilidad en el Análisis de Encuestas\nEn este capítulo se presentan los antecedentes y conceptos aplicados en el desarrollo de metasurvey. Se abordan conceptos de investigación reproducible, la importancia de R como herramienta, la revisión de paquetes para el procesamiento de encuestas por muestreo y la relevancia del diseño muestral. También se analiza la importancia de la estimación de las varianzas en la generación de indicadores y los trabajos previos en los que se basa el paquete. Estos conceptos son fundamentales para comprender el desarrollo y la importancia de establecer un flujo de trabajo sistemático en la generación de indicadores sociales.\nEn la actualidad, la generación de indicadores sociales se ha convertido en una tarea fundamental tanto para la toma de decisiones como para la investigación. Sin embargo, este proceso puede resultar complejo, ya que requiere conocimiento específico sobre el formulario de la encuesta y formas de construir ciertos índices o variables auxiliares que no necesariamente son triviales y dependen de la experiencia del usuario.\nEste proceso de generación de indicadores frecuentemente carece de transparencia o documentación adecuada, en parte por la ausencia de herramientas apropiadas y en parte por la falta de una cultura de reproducibilidad, ya que generalmente solo se hace referencia a los datos y no al proceso completo de generación de los indicadores.\nEl concepto de investigación reproducible ha cobrado relevancia en los últimos años, tanto en la academia como en la industria y esto se debe a la fricción que puede llegar a existir al momento de presentar resultados de investigación o generación indicadores relevantes para la toma de decisiones debido al proceso de generación de los mismos. Dentro de las diferentes disciplinas generar ambientes de trabajo reproducibles puede llegar a ser un desafío, ya que en la mayoría de los casos se utilizan diferentes herramientas, lenguajes de programación y bases de datos.\nEn la actualidad existen diferentes revistas científicas que promueven la investigación reproducible, herramientas, guías para buenas prácticas para trabajar con datos y código fuente como Sumatra (Davison y Huth 2012), implementaciones de programación literal (Knuth 1984) como RMarkdown (Allaire et al. 2024) o Jupyter Notebook (Kluyver et al. 2024) y diferentes implementaciones para gestionar dependencias de software como Anaconda (Anaconda 2024), aunque algunas de ellas se han vuelto herramientas de pago o ya no existen en la actualidad, mas referencias y casos de uso pueden encontrarse en (Stodden, Leisch, y Peng 2014).\nAntes de continuar es necesario definir conceptos fundamentales en el ámbito de la investigación reproducible, tales como la Reproducibilidad que refiere a la capacidad de poder repetir los resultados de un estudio, experimento o la obtención de un indicador. Si bien la reproducibilidad es considerada en un artículo de investigación científica al utilizar indicadores tanto en contextos académicos como en aplicaciones de monitoreo o divulgación de información, rara vez se documenta o se menciona de que manera se generó ese resultado haciendo referencia únicamente a los datos y rara vez al código fuente. Aún compartiendo el código fuente, esto aún no suficiente para poder reproducir un estudio o un indicador por incompatibilidades de versiones de software, cambios en la estructura de los datos interpretaciones de los datos, estilos de programación, entre otros pudiendo llevar mucho tiempo y esfuerzo para poder replicar un resultado.\nEl proceso de tratamiento de datos y limpieza forma parte de lo que se conoce como publicaciones grises (Vilhuber 2020). Este concepto se refiere a la publicación de datos, código y reportes que no son publicaciones formales, pero son esenciales para generar conocimiento científico. En su mayoría al no tener una revisión por pares o una forma estandarizada esto se incluye de forma muy dispar o sin ningún tipo de documentación para poder ser reproducido y esto forma una gran parte de la investigación científica que no se encuentra aprovechada.\nExisten diversas iniciativas destinadas a fomentar la reproducibilidad en la ciencia, lo que ha llevado a las revistas a establecer políticas de datos y código abierto. Sin embargo, persisten desafíos en la generación de indicadores sociales, ya que como se menciono anteriormente no basta con hacer referencia a los datos, como se señala en (Bechhofer et al. 2013); además de publicar el artículo junto a los datos, es necesario vincular los objetos de investigación (Research Objects RO), existen diferentes plataformas que permiten la publicación de estos objetos como Zenodo y Figshare o OSF que permiten la integración de datos, código e interacción con repositorios con control de versiones como GitHub o GitLab.\nDe conceptos generales sobre reproducibilidad es importante contar con un flujo de trabajo (Workflow managment System (Prabhu y Fox 2020)) para la obtención de estimadores en el procesamiento de encuestas por muestreo ya que el indicador final es el resultado de una serie de pasos que se deben seguir de manera ordenada y documentada para poder ser auditados y replicados en diferentes contextos, inspirado en (Sandve et al. 2013) se pueden considerar algunas buenas prácticas para la generación de indicadores:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#orden-lógico-de-la-reproducibilidad-en-el-análisis-de-encuestas",
    "href": "chapters/chapter3.html#orden-lógico-de-la-reproducibilidad-en-el-análisis-de-encuestas",
    "title": "3  Marco teórico",
    "section": "",
    "text": "Para cada resultado, se debe tener un respaldo de como fue construido: Al trabajar con lenguajes de programación como R, los script de código fuente son un respaldo de como obtener cierto resultado, sin embargo, esto puede estar ligado a tu estilo de programación y la versión de los paquetes que se utilizan.\nCrear manuales en la manipulación de datos: Es importante resumir cada paso por mas mínimo que sea en la transformación de variables, esto permite entender todo el proceso de generación de un indicador.\nGuardar las versiones de los paquetes utilizados: Al trabajar con R, es importante guardar las versiones de los paquetes que se utilizan, esto permite que en un futuro se pueda replicar el proceso de generación de indicadores, para esto puede utilizarse herramientas como renv (Ushey y Wickham 2023) un paquete que permite crear ambientes locales con versiones especificas de paquetes de R, venv (Python Software Foundation 2024) que son ambientes virtuales en python o Docker (Merkel 2014) para poder emular un ambiente de trabajo en diferentes sistemas operativos.\nGuardar pasos intermedios, en un formato estándar: Al trabajar con encuestas por muestreo y para crear indicadores sencillos se realizan dos grandes tipos de operaciones: crear grupos o categorías o realizar operaciones matemáticas, es importante guardar estos pasos en un formato estándar para poder ser reutilizados en diferentes contextos.\nCompartir las ejecuciones y scripts: Es importante que los scripts de código fuente estén disponibles para que puedan ser auditados y replicados en diferentes contextos.\n\n\n3.1.1 Conceptos clave\nmetasurvey se basa en las buenas prácticas mencionadas anteriormente y permite crear herramientas de flujo de trabajo siguiendo los siguientes principios:\n\nReusable: Se separa el proceso de transformación de variables en Steps que refiere a transformaciones de columnas, estos procedimientos pueden ser comunes tanto en diferentes encuestas como en diferentes indicadores. Estos Steps pueden ser reutilizados en diferentes Recipes para calcular indicadores de mercados de trabajo, pobreza, e incluso aplicarlos en varias encuestas simultáneamente mediante un Workflow.\nRepetible: Al tener un proceso definido en un Workflow, es posible repetir el proceso de generación de indicadores de la misma manera y automatizar la generación de reportes.\nReferenciable y Acreditable: Al contar con un Workflow, es posible hacer referencia al proceso de generación de indicadores indicando todos los pasos seguidos y el autor o equipo que lo realizó. Además, se puede acreditar a los autores de los Steps y Recipes que se utilizaron en el proceso.\n\n\n\n3.1.2 Workflow reproducible\nEl concepto de Workflow no es nuevo y exclusivo en la comunidad científica, en la actualidad en la industria de la ciencia de datos se han desarrollado diferentes herramientas para la gestión de flujos de trabajo para el procesamiento de datos, con diferentes enfoques y objetivos. metasurvey se inspira en diferentes herramientas como Apache AirFlow («Apache Airflow Documentation», s. f.) que es una plataforma de orquestación de flujos de trabajo de código abierto, Great Expectations (Expectations 2024) que es una biblioteca de validación de datos para la generación de reportes de calidad de datos y Make que es una herramienta de automatización de flujos de trabajo que se basa en la definición de reglas y dependencias.\nEn el ámbito del aprendizaje automático existe un gran esfuerzo para poder desgranar y documentar los modelos conocido como Model Cards (Mitchell et al. 2019) donde se hace un detalle de los algoritmos utilizados, las métricas de evaluación, los datos utilizados y su procesamiento, siendo esto el análogo a los Steps y Recipes de metasurvey. Este concepto se ha extendido siendo un estándar en la industria y siendo adoptado por diferentes organizaciones como Google y Hugging Face.\nTomando en cuenta estos conceptos, metasurvey tiene disponible la posibilidad de generar, compartir y visualizar los flujos de trabajo de manera gráfica permitiendo la transparencia y auditabilidad de los procesos de generación de indicadores.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#investigación-reproducible-en-r",
    "href": "chapters/chapter3.html#investigación-reproducible-en-r",
    "title": "3  Marco teórico",
    "section": "3.2 Investigación reproducible en R",
    "text": "3.2 Investigación reproducible en R\nDentro de CRAN existe una guía sobre conjunto de paquetes y herramientas con objetivos comunes denominado Task Views que agrupa paquetes de R que se utilizan para un propósito específico. En el Task View de Reproducible Research se encuentran diferentes paquetes que permiten la generación de reportes dinámicos, la gestión de flujos de trabajo y la generación de documentos interactivos aunque también existen herramientas para la gestión de flujos de trabajo generales como targets (Landau 2021) y drake (Landau 2018), metasurvey fue inspirado en los conceptos y la forma de trabajo de estos paquetes.\nLos conceptos de meta-programación y programación orientada a objetos fue inspirado en el paquete mlr3pipelines (Binder et al. 2021) que permite la creación de flujos de trabajo para el preprocesamiento de datos y la generación de modelos de aprendizaje automático, aquí se definen PipeOps que son operaciones que se pueden aplicar a los datos y se pueden combinar en un Graph que define el flujo de trabajo para ello se definen clases y métodos que permiten una fácil extensión por parte del usuario y la creación de flujos de trabajo complejos.\nDentro de la comunidad existen organizaciones como rOpenSci que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R. Esta organización promueve la creación de paquetes donde además de la guías sobre el desarrollo de paquetes y la revisión de los mismos, se promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación. Para formar parte de rOpenSci, se sigue una evaluación entre pares y una revisión de la calidad del paquete, además de la documentación y la calidad del código complementado con tests automatizados.\n\n3.2.1 Herramientas para el procesamiento de encuestas\nEn el ámbito de las encuestas por muestreo, existen diferentes paquetes que permiten el procesamiento de encuestas por muestreo o la generación de estadísticas oficiales, esto se puede ver en el Task View de Official Statistics & Survey Methodology donde se encuentran diferentes tipos de paquetes desde la preparación de formularios, calibración, análisis de datos, acceso a datos oficiales, entre otros.\nPara el procesamiento de encuestas por muestreo, existe una serie de paquetes que permiten implementar la metodología de encuestas por muestreo como puede ser el caso de survey (Lumley 2024) que permite el análisis de encuestas complejas, srvyr (Ellis y Schneider 2023) aunque estos son utilizados en el proceso final o de inferencia y no en el proceso de la construcción y limpieza de los datos como si lo hace ech (Detomasi 2020) que tiene diferentes funciones para la ECH y permite al usuario crear variables referidas a Vivienda, Educación, Mercado de Trabajo, Ingresos y Pobreza algo similar con eph (Kozlowski et al. 2020) que permite la descarga de datos de la EPH y la creación de variables para analizar la pobreza y el mercado de trabajo.\nEste ultimo grupo de paquetes o caja de herramientas tienen la limitación que no permiten la reutilización de los pasos de limpieza y transformación de los datos de forma sencilla y nativa, además de no poder visualizar el flujo de trabajo de manera gráfica, lo que dificulta la auditoría y la replicabilidad de los procesos de generación indicadores, metasurvey busca llenar este vacío permitiendo la reutilización de los pasos de limpieza y transformación de los datos, la visualización del flujo de trabajo y la generación de reportes de manera sencilla.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#comparación-de-paquetes-para-el-análisis-de-encuestas",
    "href": "chapters/chapter3.html#comparación-de-paquetes-para-el-análisis-de-encuestas",
    "title": "3  Marco teórico",
    "section": "3.3 Comparación de Paquetes para el Análisis de Encuestas",
    "text": "3.3 Comparación de Paquetes para el Análisis de Encuestas\n\nResumen de las implementaciones\nEn la Tabla 3.1 a continuación se presenta un resumen de las implementaciones de los paquetes mencionados anteriormente:\n\n\n\n\nTabla 3.1: Comparación de paquetes para análisis de encuestas\n\n\n\n\n\n\n\n\n\n\nComo se puede observar en la Tabla 3.1, metasurvey busca llenar el vacío de la reutilización de los pasos de limpieza y transformación de los datos de manera sencilla y visualizar el flujo de trabajo, aprovechando como dependencia survey y svrep para la estimación de varianzas y la generación de indicadores sociales, permitiendo la generación de reportes de manera sencilla y visualizar el flujo de trabajo de manera gráfica.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#diseño-de-encuestas-y-estimación-de-varianza",
    "href": "chapters/chapter3.html#diseño-de-encuestas-y-estimación-de-varianza",
    "title": "3  Marco teórico",
    "section": "3.4 Diseño de encuestas y estimación de varianza",
    "text": "3.4 Diseño de encuestas y estimación de varianza\nComo fue introducido en el capitulo anterior y en la sección de antecedentes es sencillo obtener estimaciones puntuales, sin embargo, es necesario presentar una medida de precisión de la estimación ya que en algunos casos puede ser que el tamaño de la muestra no sea suficiente para obtener estimaciones precisas. En el caso de las encuestas por muestreo, es necesario tener en cuenta el diseño de la encuesta, la estratificación, la ponderación y el efecto de conglomerados, ya que estos factores influyen en la precisión de la estimación. Para ello, es necesario contar con alguna metodología que permita estimar varianzas ya que para diseños complejos o estadísticos no lineales, la estimación de varianzas no es trivial.\nEn la actualidad, existen diferentes métodos para la estimación de varianzas, aunque en la mayoría de los casos se utilizan métodos de remuestreo como el Boostrap o el Jackknife, sin embargo existen diferentes ideas o propuestas como se menciona en (Deville y Tille 1998) y (Deville y Tillé 2005) que demuestran con resultados numéricos estimadores del tipo H-T bajo un diseño balanceado puede aproximarse desde el enfoque de regresión o calibración. Además existen estimadores alternativos donde complementan métodos de remuestreo para aproximar probabilidades de inclusión de segundo orden (Emilio L. Escobar y Berger 2013) utilizando ciertas aproximaciones límites (Hajek 1964).\nCada metodología depende de cada diseño y variables a estimar, por esto es que existen diferentes metodologías y paquetes como gustave (Chevalier 2023) , vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023) y samplingVarEst (Emilio Lopez Escobar, Zamudio, y Rosas 2023), aunque existen similitudes entre implementaciones y métodos es difícil encontrar una implementación que permita la estimación de varianzas de manera sencilla y que permita la reutilización de los pasos de limpieza y transformación de los datos, esto puede ser complicado para usuarios que no tienen experiencia en el procesamiento de encuestas por muestreo y que buscan una herramienta que les permita realizar este tipo de análisis de manera sencilla y visual.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#herramientas-para-el-desarrollo-de-paquetes-en-r",
    "href": "chapters/chapter3.html#herramientas-para-el-desarrollo-de-paquetes-en-r",
    "title": "3  Marco teórico",
    "section": "3.5 Herramientas para el desarrollo de paquetes en R",
    "text": "3.5 Herramientas para el desarrollo de paquetes en R\nCualquier usuario puede desarrollar un paquete en R, aunque existen diferentes guías y estándares para el desarrollo de paquetes en R, como se menciona en («R Packages (2e)», s. f.) , además de la guía de rOpenSci (rOpenSci et al. 2024) que promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación.\nPara el desarrollo de metasurvey se utilizaron paquetes como usethis (Wickham, Bryan, et al. 2024) que permite la creación de paquetes en R, roxygen2 (Wickham, Danenberg, et al. 2024) que permite la documentación de funciones y la creación de manuales, testthat (Wickham 2011) que permite la creación de tests automatizados, pkgdown (Wickham, Hesselberth, et al. 2024) que permite la creación de sitios web para paquetes de R, devtools (Wickham et al. 2022) que permite la instalación y la carga de paquetes en R, renv (Ushey y Wickham 2023) que permite la creación de ambientes locales con versiones especificas de paquetes de R junto a herramientas herramientas como pre-commit (Sottile y Contributors 2024) que permite la ejecución de scripts antes de realizar un commit en un repositorio de git esto con el fin de mantener la calidad del código y la documentación antes de realizar un cambio en el repositorio. De forma conjunta se utilizó GitFlow (Driessen 2010) que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git. Para la automatización de los tests en diferentes sistemas operativos se utilizó GitHub Actions (GitHub Actions: Automate Your Workflow 2024) que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov (Codecov: Code Coverage Insights 2024).\nTodo estas herramientas permiten que la creación de paquetes sea sencilla y permita a los usuarios enfocarse en la implementación con cierto grado de calidad y documentación, además de permitir la colaboración y la integración continua de los cambios en un repositorio de git.\n\nImplementación de tests automatizados\nEl paquete incluye tests automatizados creados con testthat, lo que asegura la robustez del código fuente al ser utilizado en diversos contextos. Un ejemplo es el test de la función extract_time_pattern, que analiza el nombre de una encuesta y retorna su tipo, año y periodicidad. Esta función clave utiliza expresiones regulares para manejar distintos formatos de tiempo y es fundamental para tareas como definir la edición de encuestas o emparejar réplicas bootstrap. Su implementación completa puede encontrarse aquí: extract_time_pattern.\n\n\n\nCódigo 3.1: Ejemplo de un test automatizado para verificar el correcto funcionamiento de la función extract_time_pattern.\n\n\n\n\nCódigo\ntest_that(\n  \"Probar extraer time pattern anual\",\n  {\n    testthat::expect_equal(\n      metasurvey:::extract_time_pattern(\"ECH_2023\"),\n      list(\n        type = \"ECH\",\n        year = 2023,\n        periodicity = \"Annual\"\n      )\n    )\n  }\n)\n\n\n\n\n\nAl tener una serie de test automatizados como el presentado en el código 3.1 se realice antes de realizar cambios en el código fuente pueda el desarrollador ejecutar los tests y verificar que no existan problemas ante un cambio o una refactorización del código fuente. Para el envió a CRAN se realizan estos test automático y una serie de pruebas de calidad y documentación para que el paquete sea aceptado en CRAN. Actualmente metasurvey no tiene errores, mensajes de advertencia o notas en CRAN, la cobertura del código es baste baja ya que realizar test para todas las funciones es un trabajo arduo y que requiere tiempo, sin embargo en futuras versiones se espera tener una cobertura del código mayor al 80%. La cobertura puede ser verificada en el siguiente enlace: codecov.\n\n\nDocumentación\nPara la documentación se utilizó roxygen2 que permite la documentación de funciones y la creación de manuales, además de pkgdown que permite la creación de sitios web para paquetes de R, esto permite que los usuarios puedan tener una guía de referencia para utilizar el paquete y que los desarrolladores puedan tener una guía de referencia para la implementación de nuevas funciones o la modificación de las existentes.\n\n\n\nCódigo 3.2: Extracto de la documentación de la función load_survey con las etiquetas necesarias para la generación de la documentación.\n\n\n\n\nCódigo\n#' @title Load survey\n#' @param path Path to the survey file\n#' @param svy_type Type of survey\n#' @param svy_edition Edition of the survey\n#' @param svy_weight Weight of the survey\n#' @param svy_psu Primary sampling unit\n#' @param ... Additional arguments\n#' @param bake Logical\n#' @return Survey object\n#' @keywords preprocessing\n#' @export\nload_survey &lt;- function(\n    path = NULL,\n    svy_type = NULL,\n    svy_edition = NULL,\n    svy_weight = NULL,\n    svy_psu = NULL,\n    ..., bake = FALSE) {\n      # Ejemplo no mostrado debido a la extensión del\n      # código puede ser consultado en \n      # el repositorio de GitHub\n}\n\n\n\n\n\nComo se puede observar en el código 3.2, la documentación de las funciones se realiza con comentarios en el código fuente, esto permite que roxygen2 pueda generar la documentación de las funciones y los manuales de manera automática, simplemente hay que añadir comentarios con ciertas etiquetas que dependiendo si la función es exportada o no, es un requisito para la aceptación en CRAN que las funciones que se exporten estén documentadas y que la documentación sea clara y concisa. La documentación puede ser consultada en el siguiente enlace: Documentación de metasurvey o en la ayuda de R con ?load_survey.\n\n\n\nPruebas en diferentes sistemas operativos y versiones de R junto a GitHub Actions\nEn muchos casos, los paquetes de R pueden tener problemas de compatibilidad con diferentes versiones de R o con diferentes sistemas operativos, para evitar estos problemas se utilizó GitHub Actions que permite la ejecución de scripts en diferentes sistemas operativos y la generación de reportes de cobertura de código con Codecov. En el caso de metasurvey se realizan pruebas en diferentes versiones de R y en diferentes sistemas operativos como Windows, MacOS y Linux, esto permite que el paquete sea compatible con diferentes versiones de R y sistemas operativos.\nTodo esto fue realizado en GitHub Actions donde se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R. En este caso al utilizar GitFlow que es una metodología de trabajo con git que permite la colaboración y la integración continua de los cambios en un repositorio de git, se puede tener una rama de desarrollo y una rama de producción, donde en la rama de desarrollo se realizan los cambios y se ejecutan los test y en la rama de producción se realiza la publicación en CRAN. Todo esto permite que el paquete sea robusto y que los cambios sean integrados de manera continua en el repositorio. Para la integración de una nueva versión se realizan pull request que son un pedido de integración de cambios en la rama de desarrollo, esto permite que los cambios sean revisados y auditados antes de ser integrados en la rama principal.\n\n\n\nCódigo 3.3: Archivo de configuración de GitHub Actions para la ejecución de tests en diferentes sistemas operativos y versiones de R.\n\n\n\n\nCódigo\non:\n  push:\n    branches: \n      - main\n      - develop\n  pull_request:\n    branches: [develop]\n\nname: R-CMD-check\n\njobs:\n  R-CMD-check:\n    runs-on: ${{ matrix.config.os }}\n\n    name: ${{ matrix.config.os }} (${{ matrix.config.r }})\n\n    strategy:\n      fail-fast: false\n      matrix:\n        config:\n          - {os: macos-latest,   r: 'release'}\n          - {os: windows-latest, r: 'release'}\n          - {os: ubuntu-latest,   r: 'devel', http-user-agent: 'release'}\n          - {os: ubuntu-latest,   r: 'release'}\n          - {os: ubuntu-latest,   r: 'oldrel-1'}\n\n    env:\n      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}\n      R_KEEP_PKG_SOURCE: yes\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: r-lib/actions/setup-pandoc@v2\n\n      - uses: r-lib/actions/setup-r@v2\n        with:\n          r-version: ${{ matrix.config.r }}\n          http-user-agent: ${{ matrix.config.http-user-agent }}\n          use-public-rspm: true\n\n      - uses: r-lib/actions/setup-r-dependencies@v2\n        with:\n          extra-packages: any::rcmdcheck\n          needs: check\n\n      - uses: r-lib/actions/check-r-package@v2\n        with:\n          upload-snapshots: true\n\n\n\n\n\nComo se puede observar en el código 3.3, se define un archivo de configuración que permite definir en que situaciones se deben de ejecutar los test junto a las diferentes plataformas y versiones de R, esto es lanzado automáticamente cuando se hace un cambio en la rama de desarrollo o en la rama de producción puede aquí verse el historial y ejemplos del mismo paquete.\nEn capítulos posteriores se presentará la implementación de conceptos de workflows, meta-programación y metodologías de estimación de varianzas en metasurvey para la generación de indicadores sociales.\n\n\n\n\nAllaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey, y Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n«Apache Airflow Documentation». s. f. https://airflow.apache.org/docs/latest/.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John Ainsworth, Jiten Bhagat, Philip Couch, et al. 2013. «Why linked data is not enough for scientists». Future Generation Computer Systems, Special section: Recent advances en e-Science, 29 (2): 599-611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars Kotthoff, y Bernd Bischl. 2021. «mlr3pipelines - Flexible Machine Learning Pipelines in R». Journal of Machine Learning Research 22 (184): 1-7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, y Santa Ivanova. 2020. vardpoor: Estimation of indicators on social exclusion and poverty and its linearization, variance estimation. Riga, Latvia: Central Statistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChevalier, Martin. 2023. gustave: A User-Oriented Statistical Toolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCodecov: Code Coverage Insights. 2024. https://about.codecov.io.\n\n\nDavison, Andrew P, y John E Huth. 2012. «Sumatra: A toolkit for reproducible research». arXiv preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. «ech: Caja de herramientas para procesar la Encuesta Continua de Hogares». https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, y Yves Tille. 1998. «Unequal Probability Sampling Without Replacement Through a Splitting Method». Biometrika 85 (1): 89-101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, y Yves Tillé. 2005. «Variance approximation under balanced sampling». Journal of Statistical Planning and Inference 128 (2): 569-91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nDriessen, Vincent. 2010. «A Successful Git Branching Model». https://nvie.com/posts/a-successful-git-branching-model/.\n\n\nEllis, Greg Freedman, y Ben Schneider. 2023. srvyr: ’dplyr’-Like Syntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nEscobar, Emilio L., y Yves G. Berger. 2013. «A new replicate variance estimator for unequal probability sampling without replacement». The Canadian Journal of Statistics / La Revue Canadienne de Statistique 41 (3): 508-24. https://www.jstor.org/stable/43186201.\n\n\nEscobar, Emilio Lopez, Ernesto Barrios Zamudio, y Juan Francisco Munoz Rosas. 2023. samplingVarEst: Sampling Variance Estimation.\n\n\nExpectations, Great. 2024. Great Expectations Documentation. Superconductive. https://docs.greatexpectations.io.\n\n\nGitHub Actions: Automate Your Workflow. 2024. GitHub. https://github.com/features/actions.\n\n\nHajek, Jaroslav. 1964. «Asymptotic Theory of Rejective Sampling with Varying Probabilities from a Finite Population». The Annals of Mathematical Statistics 35 (4): 1491-1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024. Jupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. «Literate programming». The Computer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, y Natsumi Shokida. 2020. eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nLandau, William Michael. 2018. «The drake R package: a pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. «The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2024. «survey: analysis of complex survey samples».\n\n\nMerkel, Dirk. 2014. «Docker: lightweight linux containers for consistent development and deployment». Linux journal 2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, y Timnit Gebru. 2019. «Model Cards for Model Reporting». En, 220-29. https://doi.org/10.1145/3287560.3287596.\n\n\nPrabhu, Anirudh, y Peter Fox. 2020. «Reproducible Workflow», diciembre. http://arxiv.org/abs/2012.13427.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: venv - Creation of virtual environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\n«R Packages (2e)». s. f. https://r-pkgs.org/.\n\n\nrOpenSci, Brooke Anderson, Scott Chamberlain, Laura DeCicco, Julia Gustavsen, Anna Krystalli, Mauro Lepore, et al. 2024. «rOpenSci Packages: Development, Maintenance, and Peer Review». Zenodo. https://doi.org/10.5281/zenodo.10797633.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, y Eivind Hovig. 2013. «Ten Simple Rules for Reproducible Computational Research». PLOS Computational Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSchneider, Benjamin. 2023. «svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights». https://CRAN.R-project.org/package=svrep.\n\n\nSottile, Anthony, y Contributors. 2024. pre-commit: A framework for managing and maintaining multi-language pre-commit hooks. https://pre-commit.com.\n\n\nStodden, Victoria, Friedrich Leisch, y Roger D. Peng. 2014. Implementing Reproducible Research. CRC Press.\n\n\nUshey, Kevin, y Hadley Wickham. 2023. renv: Project Environments. https://CRAN.R-project.org/package=renv.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWickham, Hadley. 2011. «testthat: Get Started with Testing». The R Journal 3: 5-10. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, y Andy Teucher. 2024. usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, y Manuel Eugster. 2024. roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, Maëlle Salmon, Olivier Roy, y Salim Brüggemann. 2024. pkgdown: Make Static HTML Documentation for a Package. https://CRAN.R-project.org/package=pkgdown.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, y Jennifer Bryan. 2022. devtools: Tools to Make Developing R Packages Easier. https://CRAN.R-project.org/package=devtools.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html",
    "href": "chapters/chapter4.html",
    "title": "4  Desarrollo y metodología",
    "section": "",
    "text": "4.1 Estimación de los errores estándar\nEn este capítulo se divide en dos partes, la primera parte se centra en la metodología de los métodos de estimación de varianzas y errores estándar, donde se describen los diferentes métodos de remuestreo y se explican las ventajas de los pesos replicados. La segunda parte se centra en el desarrollo e implementación de las diferentes partes del paquete así como también . Los ejemplos de código se muestran con código real del paquete metasurvey y donde allí se explican las diferentes partes del código y su funcionamiento intentando ser lo más expositivo posible para que el lector pueda entender el funcionamiento de la meta-programación aunque estos no sean los ejemplos más complejos que se encuentran en el paquete.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Como se presentó en el capítulo 2, la estimación de errores estándar es fundamental para cuantificar la incertidumbre en las estimaciones. En este capítulo nos centraremos en la implementación práctica de estos métodos en el paquete metasurvey. ======= Como se presentó en el Capítulo 2, la estimación de errores estándar es fundamental para cuantificar la incertidumbre en las estimaciones. En este capítulo nos centraremos en la implementación práctica de estos métodos en el paquete metasurvey. &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\nCada estimador tiene asociado un error estándar que permite cuantificar la variabilidad de la estimación, debido a que la muestra es aleatoria esta medida es una variable aleatoria. Dentro de la incertidumbre puede separarse en errores muestrales y no muestrales. Los primeros refieren a la variabilidad de la estimación debido a la selección de la muestra y los segundos refieren a la variabilidad de la estimación debido a errores de medición, errores de no respuesta, entre otros (Särndal, Swensson, y Wretman 2003).\nEn este trabajo se centra en la estimación de los errores muestrales, ya que los errores no muestrales son difíciles de cuantificar. Los errores muestrales se pueden cuantificar mediante la varianza de la estimación. Esta varianza depende del diseño muestral ya que, como se mencionó anteriormente, el diseño muestral induce propiedades estadísticas claves como la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. El paquete survey permite estimar la varianza de la estimación de forma sencilla y eficiente, sin embargo, en algunos casos la estimación de la varianza no es correcta, ya que el paquete survey asume un muestreo simple con probabilidades de inclusión desiguales y con reposición, es decir, con una fracción de muestreo \\(f = \\frac{n}{N} \\approx 0\\) (Lumley 2004).\nPara diseños multietápicos, las probabilidades de segundo orden son muy complejas de calcular, por lo que una estimación directa no es muy factible. Además, estos ponderadores no son exactamente los pesos muestrales definidos en los capítulos anteriores, ya que se ajustan para tener en cuenta la no respuesta y la calibración, lo cual permite una estimación más precisa de ciertas variables de interés. En el caso de que se cuente con un mecanismo para obtener las probabilidades de inclusión de segundo orden, este no tendría en cuenta el proceso posterior de calibración, por lo que la estimación de la varianza no sería correcta.\nEn general, para este tipo de casos se utilizan principalmente las siguientes estrategias: el método del último conglomerado, donde se asume que la variabilidad proviene únicamente de la selección en la primera etapa, y métodos de remuestreo como el Bootstrap o Jackknife. En este trabajo se propone la implementación de forma nativa de diferentes métodos utilizando solamente un argumento al cargar la encuesta, permitiendo a usuarios no expertos en metodología de muestreo obtener estimaciones de varianzas correctas y confiables.\nAdicionalmente, para estimadores no lineales se utiliza el método de Linearización de Taylor, que permite aproximar el estimador como función de estimadores lineales. Un caso típico es la tasa de desempleo, que se calcula como el cociente entre la población desocupada y la población económicamente activa. En este caso, se puede aproximar la tasa de desempleo como función de estimadores lineales y obtener una estimación de la varianza de la tasa de desempleo o, de forma similar, un estimador de medias o proporciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#estimación-de-los-errores-estándar",
    "href": "chapters/chapter4.html#estimación-de-los-errores-estándar",
    "title": "4  Desarrollo y metodología",
    "section": "",
    "text": "4.1.1 Métodos de remuestreo\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Mientras que en el capítulo 2 se presentó la teoría detrás de los métodos de remuestreo, aquí nos enfocamos en su implementación práctica y las ventajas que ofrece el enfoque de pesos replicados: ======= Mientras que en el Capítulo 2 se presentó la teoría detrás de los métodos de remuestreo, aquí nos enfocamos en su implementación práctica y las ventajas que ofrece el enfoque de pesos replicados: &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\nLa estimación del error estándar de una media u otros resúmenes poblacionales se basa en la desviación estándar de dicho estimador a través de múltiples muestras independientes. Sin embargo, en encuestas reales solo se cuenta con una muestra. El enfoque de pesos replicados ofrece una alternativa, al calcular la variabilidad del estimador a partir de múltiples subconjuntos que se comportan de manera parcialmente independiente, y luego extrapolar esta variabilidad para obtener una estimación que se asemeje a la que se obtendría si se tuvieran múltiples muestras independientes.\n\nRéplicas de Mitad de Muestra\nPara entender mejor este método, se puede considerar un diseño estratificado en el que se seleccionan dos unidades por estrato. Si se dividen los datos en dos mitades, tomando una unidad de cada estrato, se crean subconjuntos que se pueden considerar como “mitades” independientes. Si la corrección por población finita no es relevante, la varianza de un estimador basado en una mitad de muestra es aproximadamente el doble de la varianza de la muestra completa. Dado que se tienen dos mitades, se puede usar la diferencia entre sus estimaciones para calcular la varianza:\n\\[\n\\text{Var}(\\hat{\\theta}) \\approx \\frac{1}{2} (\\hat{\\theta}_A - \\hat{\\theta}_B)^2,\n\\]\ndonde \\(\\hat{\\theta}_A\\) y \\(\\hat{\\theta}_B\\) son las estimaciones de cada mitad de la muestra. Este enfoque es sencillo pero puede ser inestable, por lo que se suelen usar múltiples conjuntos de divisiones para obtener un promedio más preciso.\n\n\nBalanced Repeated Replication (BRR)\nEl método de Balanced Repeated Replication (BRR) es una forma sistemática de elegir subconjuntos de la muestra, garantizando que cada unidad se incluya de manera equilibrada en las réplicas. Esto se logra mediante un balanceo ortogonal, donde cada observación está presente en aproximadamente la mitad de las réplicas, y cada par de unidades de diferentes estratos aparece en las réplicas de forma equilibrada. Con (K) estratos, se puede generar un conjunto de hasta (K + 4) réplicas que produzca una estimación de la varianza que es prácticamente idéntica a la que se obtendría usando todas las (2^K) combinaciones posibles.\nLa varianza utilizando BRR se calcula así:\n\\[\n\\text{Var}_{\\text{BRR}}(\\hat{\\theta}) = \\frac{1}{R} \\sum_{r=1}^R (\\hat{\\theta}_r - \\hat{\\theta})^2,\n\\]\ndonde \\(R\\) es el número de réplicas seleccionadas y \\(\\hat{\\theta}_r\\) es el estimador obtenido de cada réplica.\n\n\nPesos Replicados en Diseños Multietápicos y Complejos\nEl enfoque de pesos replicados no solo se aplica a diseños simples, sino que también se adapta a diseños de muestreo multietápicos y diseños complejos. En estos casos, la estructura de la muestra se complica, ya que puede involucrar varias etapas de selección (por ejemplo, seleccionar primero conglomerados como municipios, luego hogares dentro de los municipios, y finalmente personas dentro de los hogares). Esto hace que la varianza deba considerar la correlación entre unidades seleccionadas en cada etapa.\nPara estos diseños, se utilizan métodos como el Jackknife y el Bootstrap, que permiten manejar la estructura multietápica. Por ejemplo:\n\nEn un diseño Jackknife, se ajustan los pesos eliminando una observación o un conglomerado completo en cada réplica, y recalculando el estimador con los datos restantes. Esto puede ajustarse para considerar la estructura de estratos y conglomerados.\n\n\\[\n\\text{Var}_{\\text{Jackknife}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\theta}_i - \\hat{\\theta})^2\n\\]\ndonde (n) es el número de observaciones o conglomerados, \\(\\hat{\\theta}_i\\) es la estimación obtenida cuando se omite la \\(i\\)-ésima unidad, y \\(\\hat{\\theta}\\) es la estimación con todos los datos.\n\nEn el Bootstrap, se seleccionan subconjuntos con reemplazo de cada conglomerado, y se ajustan los pesos según el número de veces que cada unidad aparece en la réplica. Esto es especialmente útil cuando las unidades de muestreo tienen una estructura jerárquica, como es el caso de los diseños multietápicos.\n\n\\[\n\\text{Var}_{\\text{Bootstrap}}(\\hat{\\theta}) = \\frac{1}{B} \\sum_{b=1}^B (\\hat{\\theta}_b - \\hat{\\theta})^2,\n\\]\ndonde \\(B\\) es el número de réplicas y \\(\\hat{\\theta}_b\\) es el estimador obtenido en la \\(b\\)-ésima réplica.\n\n\nVentajas de los Pesos Replicados\nAunque estos métodos requieren más esfuerzo computacional comparados con métodos tradicionales como el estimador de Horvitz-Thompson, son muy versátiles. Facilitan la estimación de errores estándar para diferentes tipos de estadísticas, no solo para medias o totales, y son especialmente útiles cuando se trabaja con diseños de muestreo complejos. Además, permiten obtener errores estándar precisos para estimaciones de subpoblaciones sin necesidad de ajustes adicionales. Esto los convierte en una herramienta poderosa para el análisis de encuestas complejas, especialmente con el soporte de software estadístico moderno.\nEl paquete survey con svrep proporciona una implementación robusta de varios métodos de pesos replicados, incluyendo Balanced Repeated Replication (BRR), Jackknife, y Bootstrap. Sin embargo, el uso adecuado de estos métodos a menudo no es tan conocido por usuarios que no son expertos en muestreo. La correcta especificación del diseño y la interpretación de los resultados pueden ser complejas, especialmente en el caso de diseños de muestreo multietápicos o aquellos que requieren calibración.\nDentro de metasurvey se busca simplificar el uso de estos métodos, pudiendo especificar el tipo de réplica deseado con un solo argumento al cargar la encuesta o utilizar réplicas brindadas por la institución que publica los microdatos. Además, se busca incorporar medidas de calidad de las estimaciones como el coeficiente de variación, el error relativo y el error absoluto, para facilitar la interpretación de los resultados y la comparación entre diferentes estimaciones y subpoblaciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#desarrollo-e-implementación",
    "href": "chapters/chapter4.html#desarrollo-e-implementación",
    "title": "4  Desarrollo y metodología",
    "section": "4.2 Desarrollo e Implementación",
    "text": "4.2 Desarrollo e Implementación\nEl desarrollo de metasurvey se fundamenta en tres pilares principales: una gestión eficiente de dependencias, una arquitectura modular basada en clases, y el uso de técnicas avanzadas de meta-programación. A continuación, se detalla cada uno de estos aspectos.\n\n4.2.1 Gestión de Dependencias\nEl diseño de metasurvey prioriza la eficiencia y minimalismo en sus dependencias externas. El núcleo del paquete se apoya en survey para el procesamiento de encuestas complejas, data.table para la manipulación eficiente de datos mediante referencias, y R6 para la implementación orientada a objetos. Para mejorar la legibilidad del código se utiliza glue, mientras que jsonlite y httr facilitan la comunicación con la API. Esta selección cuidadosa contrasta con versiones anteriores que incluían dependencias más pesadas como tidyverse y rlang, priorizando ahora la eficiencia y ligereza del paquete.\n\n\n4.2.2 Arquitectura y Diseño de Clases\nEl paquete utiliza una arquitectura orientada a objetos mediante R6, implementando las siguientes clases principales:\n\nClase Survey\n\nAlmacena la encuesta, metadatos y diseño muestral\nMantiene registro de recetas y pasos aplicados\n\nClase Step\n\nDefine transformaciones individuales\nGestiona dependencias y evaluación perezosa\n\nClase Recipe\n\nAgrupa steps y metadatos del proceso\nFacilita compartir flujos de trabajo\nIncluye DOI para citación académica\n\nClase RotativePanelSurvey y PoolSurvey\n\nExtensiones para casos específicos (paneles rotativos y combinación de encuestas)\nImplementan estimadores especializados\n\n\nLa arquitectura modular facilita la extensión del paquete y protege los objetos mediante encapsulamiento.\n\n\n4.2.3 Implementación de Meta-programación\nLa meta-programación en metasurvey cumple tres objetivos principales:\n\nRegistro Automático de Transformaciones\n\nCada operación realizada en una encuesta se registra automáticamente\nFacilita la replicabilidad y transparencia de los análisis\n\nEvaluación Perezosa\n\nLas transformaciones se aplican solo cuando es necesario\nOptimiza el rendimiento y uso de memoria\n\nGestión de Dependencias\n\nIdentificación automática de variables dependientes\nAsegura la correcta aplicación de transformaciones en el orden adecuado\n\n\nImplementar la evaluación perezosa y dependencias fue un gran desafío, ya que requirió un diseño cuidadoso de los métodos para poder trabajar con las expresiones de R y extraer información de las mismas. La meta-programación se encuentra en casi toda la implementación de los Step y de las funciones auxiliares que permiten la creación y aplicación de recetas y pasos. Dentro de esta misma sintaxis se permite extraer las expresiones para luego poder compartir las recetas o poder decidir en que momento se aplican los pasos y recetas a la encuesta.\n\n\n4.2.4 Ejemplos de la implementación\n\nCarga de una encuesta\nEl paquete puede dividirse en dos partes principales: la carga y procesamiento de encuestas, y la estimación de errores estándar. Dentro de lo que es la carga y procesamiento de encuestas, se incluyen funciones para cargar encuestas en diferentes formatos, como SPSS, STATA, CSV, y RDS, y para realizar operaciones básicas como la selección de variables, la recodificación de categorías, y la creación de indicadores.\nEsta implementación puede verse en load_survey.R donde aquí se define la función principal load_survey esta misma se encarga de cargar la encuesta y realizar las operaciones básicas mencionadas anteriormente. Dentro de ella podemos ver que es simplemente un wrapper de diferentes paquetes para cargar la encuesta ya sea read.spss del paquete foregin (R Core Team 2023) para cargar encuestas provenientes en formato SAV o DTA, fread de data.table (Barrett et al. 2024) para archivos CSV y por último loadWorkbook del paquete openxlsx (Schauberger y Walker 2024), todas estas funciones se encargan de cargar la encuesta en base a la extensión del archivo, el usuario puede modificar cambiando el engine como por ejemplo a tidyverse donde la lectura CSV se realiza con read_csv del paquete readr (Wickham 2023), o haven (Wickham, Miller, y Smith 2023) para cargar encuestas en formato SPSS o STATA.\nAl cargar la encuesta el usuario debe de especificar el tipo de encuesta que está cargando y la edición de la misma, estos metadatos serán cruciales para poder obtener recetas y pasos de la API de metasurvey. Además, se puede especificar el tipo de réplica que se desea utilizar, por defecto se utiliza el método de BRR, pero el usuario puede especificar el método de réplica que desee, ya sea Jackknife o Bootstrap, en el capítulo 5 se menciona como utilizar replicas brindadas por la institución que publica los microdatos y estimadores de cambios netos compuestos.\nUna vez definida la carga de datos dentro de la misma implementación de crea un objeto de la clase Survey la cual se encuentra definida en survey.R. Esta clase es realizada con el paquete R6 (Chang 2022) y se encarga de almacenar la encuesta, los metadatos, las recetas y los pasos junto al diseño muestral, el usuario puede obtener información con wrappers de cada método para que sea más sencillo de utilizar, como por ejemplo cat_steps donde se obtiene todos los pasos que fueron aplicados a la encuesta, cat_recipes donde se obtienen todas las recetas que fueron aplicadas a la encuesta, cat_design donde se obtiene el diseño muestral, entre otros.\nEn el código 4.1 se muestra un ejemplo de cómo se carga una encuesta y se obtiene la información de la misma.\n\n\n\nCódigo 4.1: Lectura de la encuesta ECH 2022, fijación del ponderador y obtención de recetas.\n\n\n\n\nCódigo\nlibrary(metasurvey)\n\n# Cargar encuesta\n\n## Encuesta ECH 2022\n## Se fija el ponderador de la encuesta\n## Se obtienen las recetas de la encuesta\n\nech_2022 &lt;- load_survey(\n  metasurvey::load_survey_example(\n    \"ech\",\n    \"ech_2022\"\n  ),\n  svy_edition = \"2022\",\n  svy_type = \"ech\",\n  svy_weight = add_weight(annual = \"w_ano\"),\n  recipes = get_recipe(\n    \"ech\",\n    \"2022\"\n  )\n)\n\n\n\n\n\nDentro de este mismo ejemplo se puede ver que se fija el ponderador de la encuesta, en este caso se fija el ponderador w_ano que es el ponderador anual de la encuesta ECH 2022, este ponderador es crucial para la estimación de errores estándar y para la obtención de recetas y pasos de la encuesta.\n\n\nClase Step\nLa clase Step es una clase que se encarga de almacenar los pasos que se aplican a la encuesta, esta clase se encuentra definida en step.R y se encarga de almacenar los pasos que se aplican a la encuesta, los pasos se aplican a través de recetas que se obtienen de la API de metasurvey, los pasos pueden ser de diferentes tipos, como por ejemplo step_compute que se encarga de calcular una variable, step_recode que se encarga de recodificar una variable, entre otros.\nEn el código 4.2 se muestra un ejemplo de cómo se crea un objeto de la clase Step con una clase de R6 (Chang 2022) paquete que permite la programación orientada a objetos en R donde tiene aquí se encuentran los atributos de la clase Step como name, edition, survey_type, type, new_var, exprs, call, svy_before, default_engine, depends_on, comments, bake en conjunto con el método initialize que se encarga de inicializar la clase Step con los atributos mencionados anteriormente. Los objetos Survey, Recipe, PanelRotativeSurvey y PoolSurvey son clases que se encuentran definidas en el paquete metasurvey donde modelar en una clase los diferentes objetos que se utilizan en el paquete permite una mejor organización y estructura del código y facilita la implementación de la meta-programación.\nEs importante mencionar que la clase Step es una clase que se utiliza internamente en el paquete y no es necesario que el usuario la utilice directamente, sin embargo, es importante mencionarla ya que es una parte esencial del paquete y es utilizada en la implementación de las recetas y pasos de la encuesta, además de que es un ejemplo claro de cómo se puede utilizar la programación orientada a objetos en R para modelar diferentes objetos y clases.\n\n\n\nCódigo 4.2: Definición de la clase Step con sus atributos y método initialize para inicializar la clase. Las clases de R6 son encapsuladas y permiten que los métodos y atributos sean privados o públicos.\n\n\n\n\nCódigo\nstep &lt;- R6Class(\n  \"Step\",\n  public = list(\n    name = NULL,\n    edition = NULL,\n    survey_type = NULL,\n    type = NULL,\n    new_var = NULL,\n    exprs = NULL,\n    call = NULL,\n    svy_before = NULL,\n    default_engine = NULL,\n    depends_on = list(),\n    comments = NULL,\n    bake = NULL,\n    initialize = function(...args) {\n      self$name &lt;- name\n      # Inicialización de los atributos de la clase\n      # Se omiten por la extensión del código\n      # Definir un constructor permite que siempre\n      # se inicialicen los atributos de la clase\n      # de forma correcta\n    },\n    method1 = function(...) {\n      # Método 1 (Método generico no se muestra por extensión)\n    },\n    method2 = function(...) {\n      # Método 2 (Método generico no se muestra por extensión)\n    }\n  )\n)\n\n\n\n\n\nEl principal uso de R6 y no de S3 o S4 es que R6 permite la creación de objetos con estado en conjunto con su propiedad de encapsulamiento, lo cual es esencial para la implementación de la meta-programación, ya que permite almacenar el estado de los objetos y modificarlos a través de métodos, lo cual es esencial para la implementación de las recetas y pasos de la encuesta. Además se puede manejar las copias de los objetos de forma mas sencilla siendo algo que mejora el rendimiento y la eficiencia del paquete.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD #### Lazy evaluation {#sec-lazy-evaluation .unnumbered} ======= #### Lazy evaluation {#sec-lazy-evaluation} {.unnumbered} &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\nLa evaluación perezosa es una técnica de programación que consiste en retrasar la evaluación de una expresión hasta que sea necesaria. En el contexto de metasurvey, la evaluación perezosa se utiliza para retrasar la aplicación de recetas y pasos a la encuesta hasta que sea necesario, lo cual permite optimizar el rendimiento y la eficiencia del paquete. Esto hace que los Steps se ejecuten con una validación mínima en base a las dependencias de las variables, y se ejecuten solo cuando se necesiten o al cocinar la receta.\nEl paquete tiene por defecto la evaluación perezosa de los pasos y recetas, lo cual hace que sea más eficiente y rápido el procesamiento de las encuestas aunque puede llevar a confusiones al usuario cuando revisa los datos de forma manual ya que si bien se aplican los Step los mismos no tienen efecto hasta que se cocine la receta, el usuario puede desactivar (código 4.3) la evaluación perezosa de los pasos y recetas si lo desea. La evaluación perezosa se implementa a través de la clase Step y de la función bake que se encarga de aplicar los pasos y recetas a la encuesta.\n\n\n\nCódigo 4.3: Forma de desactivar la evaluación perezosa de los pasos y recetas. Esto hace que los pasos y recetas se apliquen de forma inmediata.\n\n\n\n\nCódigo\nmetasurvey::set_lazy_processing(FALSE)\n\n\n\n\n\n\n\nUso de copias y referencias\nEl paquete data.table (Barrett et al. 2024) logra una eficiencia en la manipulación de datos al utilizar referencias en lugar de copias, lo cual permite que las operaciones se realicen de forma más rápida y eficiente. Dentro de metasurvey al utilizar como motor data.table permite que sea eficiente y rápido aunque puede llevar a confusiones al usuario donde se modifican las referencias de los objetos algo que no es común en R, sin embargo, se puede utilizar la función copy para realizar copias de los objetos y no modificar las referencias de los mismos código 4.4.\n\n\n\nCódigo 4.4: Desactivar el uso de referencias y utilizar copias de los objetos.\n\n\n\n\nCódigo\nmetasurvey::set_use_copy(TRUE)\n\n\n\n\n\n\n\n\n4.2.5 Meta-programación\nLa meta-programación fue un aspecto clave en el desarrollo de metasurvey, ya que permitió que al realizar una operación en una encuesta, se generara un registro de los pasos y recetas aplicados, lo cual es esencial para la replicabilidad y la transparencia de los análisis. La meta-programación se implementó a través de la clase Survey y de las funciones auxiliares que permiten la creación y aplicación de recetas y pasos.\n\n\n\nCódigo 4.5: Ejemplo de función para encontrar dependencias de variables en una expresión de un step. Puede encontrar mas ejemplos en el código fuente en la implementación de los Steps.\n\n\n\n\nCódigo\nfind_dependencies &lt;- function(call_expr, survey) {\n  dependencies &lt;- character()\n\n  if (is.call(call_expr)) {\n    for (i in seq_along(call_expr)) {\n      result &lt;- find_dependencies(call_expr[[i]], survey)\n      if (!is.null(result)) {\n        dependencies &lt;- unique(c(dependencies, result))\n      }\n    }\n  } else if (\n    is.name(call_expr) && as.character(call_expr) %in% names(survey)\n  ) {\n    dependencies &lt;- unique(c(dependencies, as.character(call_expr)))\n  }\n\n  return(unique(dependencies))\n}\n\n\n\n\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD En el código 4.5 se muestra una función auxiliar que permite encontrar las dependencias de variables en una expresión de un Step. Esta función se utiliza para identificar las variables que se utilizan en un paso y que deben ser incluidas en el registro de recetas. La función find_dependencies recibe una expresión de un paso y un objeto de la clase Survey, y devuelve un vector con las variables que se utilizan en el paso. Esta función se utiliza de forma interna en las implementaciones de step_compute y step_recode para registrar las dependencias esto es un ejemplo claro de como con código se puede extraer información del mismo y utilizarla para otros fines. ======= En el código Código 4.5 se muestra una función auxiliar que permite encontrar las dependencias de variables en una expresión de un Step. Esta función se utiliza para identificar las variables que se utilizan en un paso y que deben ser incluidas en el registro de recetas. La función find_dependencies recibe una expresión de un paso y un objeto de la clase Survey, y devuelve un vector con las variables que se utilizan en el paso. Esta función se utiliza de forma interna en las implementaciones de step_compute y step_recode para registrar las dependencias esto es un ejemplo claro de como con código se puede extraer información del mismo y utilizarla para otros fines. &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\nLa meta-programación también fue utilizada para que el usuario utilice la misma sintaxis del paquete survey para definir los estadísticos a estimar y no deba de incluir el diseño el cual ya se encuentra dentro del objeto Survey, donde aquí también se encuentran diferentes diseños en base a la periodicidad de la encuesta, algo que es útil cuando se trabaja con encuestas de panel rotativos como la ECH luego de cambio de metodología en 2021, en el capítulo 5 se menciona como se puede utilizar diferentes diseños en base a la periodicidad de la encuesta y un ejemplo con la encuesta ECH.\n\nEjemplos Avanzados de Meta-programación\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD La meta-programación avanzada en R permite manipular ambientes y expresiones de forma dinámica, lo cual es esencial para la implementación de recetas y pasos en metasurvey. A continuación, se presentan casos típicos de meta-programación, la manipulación de ambientes y expresiones, y el uso de substitute y bquote para evaluar expresiones de forma parcial. ======= Para ilustrar conceptos más avanzados de meta-programación, veamos algunos ejemplos del libro Advanced R: &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\n\nAmbientes y Evaluación\n\n\n\nCódigo 4.6: En este ejemplo se crea un nuevo ambiente env y se asignan valores a las variables x\n\n\n\n\nCódigo\n# Crear un nuevo ambiente\nenv &lt;- new.env()\n\n# Asignar valores en el nuevo ambiente\nassign(\"x\", 10, envir = env)\nassign(\"y\", 20, envir = env)\n\n# Evaluar una expresión en el nuevo ambiente\neval(quote(x + y), envir = env)\n\n\n\n\n\n\n\nManipulación de Expresiones\n\n\n\nCódigo 4.7\n\n\n\n\nCódigo\n# Crear una expresión\nexpr &lt;- quote(x + y)\n\n# Modificar la expresión\nexpr[[1]] &lt;- quote(`*`)\nexpr[[2]] &lt;- quote(x)\nexpr[[3]] &lt;- quote(y)\n\n# Evaluar la nueva expresión\neval(expr, envir = env)\n\n\n\n\n\n\n\nUso de substitute y bquote\n\n\n\nCódigo 4.8: En este ejemplo se muestra cómo se pueden reemplazar variables en una expresión utilizando substitute y cómo se puede evaluar parcialmente una expresión utilizando bquote.\n\n\n\n\nCódigo\n# Usar substitute para reemplazar variables en una expresión\nexpr &lt;- quote(a + b)\nsubstitute(expr, list(a = 1, b = 2))\n\n# Usar bquote para evaluar parcialmente una expresión\nbquote(a + .(b))\n\n\n\n\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Estos ejemplos muestran cómo se pueden manipular ambientes y expresiones en R para realizar meta-programación avanzada. La capacidad de modificar y evaluar expresiones dinámicamente es una herramienta poderosa que se utiliza en metasurvey para registrar y aplicar transformaciones y brindar la flexibilidad necesaria para adaptarse a diferentes tipos de encuestas y diseños muestrales. ======= Estos ejemplos muestran cómo se pueden manipular ambientes y expresiones en R para realizar meta-programación avanzada. La capacidad de modificar y evaluar expresiones dinámicamente es una herramienta poderosa que se utiliza en metasurvey para registrar y aplicar transformaciones de manera eficiente. &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\n\n\n\n\n4.2.6 Sistema de Comunicación y Optimización\nEl paquete implementa una API REST desarrollada en Node.js que permite compartir y gestionar recetas entre usuarios. La API proporciona endpoints para obtener, crear y actualizar recetas, almacenadas en MongoDB. El sistema incluye autenticación mediante tokens JWT, con planes futuros para implementar un portal web de registro automático.\nMongoDB se eligió por su flexibilidad y escalabilidad, permitiendo almacenar recetas de forma estructurada y eficiente. Es un sistema de base de datos NoSQL (Not Only SQL) enfocada en documentos, en lugar de tablas, se agrupan en colecciones y se almacenan en formato JSON. Esto permite almacenar recetas de forma flexible y escalable, sin necesidad de definir un esquema fijo.\nSi bien la dentro de la configuración de la API se define un esquema semi-estructurado para las recetas, se permite la flexibilidad de agregar nuevos campos y estructuras de datos pero se mantiene una estructura mínima para mantener la consistencia de los datos. La API se comunica con el paquete metasurvey a través de solicitudes HTTP el usuario no necesita interactuar directamente con la API ya que el paquete se encarga de la comunicación con la misma.\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD \n======= ::: {#fig-api}  API de metasurvey con MongoDB. La API permite compartir y gestionar recetas entre usuarios, almacenadas en MongoDB. ::: &gt;&gt;&gt;&gt;&gt;&gt;&gt; main\nPara optimizar el rendimiento, se implementó un sistema de cache que gestiona proactivamente la memoria mediante liberación de recursos y reutilización de cálculos intermedios. El sistema aprovecha la paralelización automática y el procesamiento por lotes cuando es posible.\nLa arquitectura modular del sistema facilita la incorporación de nuevos tipos de encuestas y diseños muestrales, permitiendo adaptarse a diferentes necesidades sin modificar el núcleo del paquete.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#síntesis-del-capítulo",
    "href": "chapters/chapter4.html#síntesis-del-capítulo",
    "title": "4  Desarrollo y metodología",
    "section": "4.3 Síntesis del capítulo",
    "text": "4.3 Síntesis del capítulo\nEn este capítulo se ha presentado una revisión detallada de los métodos de estimación de varianzas y errores estándar, así como su implementación en el paquete metasurvey. Se han descrito las ventajas de utilizar métodos de remuestreo como Bootstrap y Jackknife, y se ha destacado la importancia de los pesos replicados en diseños de muestreo complejos. Además, se ha mostrado cómo metasurvey facilita la creación y el manejo de encuestas, permitiendo a los usuarios obtener transformaciones transparentes y reproducibles.\n\n\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, Toby Hocking, y Benjamin Schwendinger. 2024. data.table: Extension of ‘data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nLumley, Thomas. 2004. «Analysis of Complex Survey Samples». Journal of Statistical Software 9 (abril): 1-19. https://doi.org/10.18637/jss.v009.i08.\n\n\nR Core Team. 2023. foreign: Read Data Stored by ’Minitab’, ’S’, ’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, y Alexander Walker. 2024. openxlsx: Read, Write and Edit xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nWickham, Hadley. 2023. httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Evan Miller, y Danny Smith. 2023. haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html",
    "href": "chapters/chapter5.html",
    "title": "5  Casos de uso",
    "section": "",
    "text": "5.1 Encuesta Continua de Hogares con Paneles Rotativos\nPara este capítulo se presentan dos casos de uso que demuestran la versatilidad y eficacia de metasurvey en el análisis de encuestas de hogares en América Latina. Se abordarán dos encuestas representativas de la región: la Encuesta Continua de Hogares (ECH) de Uruguay y la Encuesta Permanente de Hogares (EPH) de Argentina. Estas encuestas son fuentes clave de información sobre el mercado laboral en sus respectivos países y han sido utilizadas en diversos estudios y análisis socioeconómicos.\nEl paquete metasurvey facilita el procesamiento y análisis de encuestas de hogares a través de una interfaz unificada. Este capítulo presenta dos casos de uso que demuestran su versatilidad: el análisis de la Encuesta Continua de Hogares (ECH) de Uruguay y la Encuesta Permanente de Hogares (EPH) de Argentina.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#encuesta-continua-de-hogares-con-paneles-rotativos",
    "href": "chapters/chapter5.html#encuesta-continua-de-hogares-con-paneles-rotativos",
    "title": "5  Casos de uso",
    "section": "",
    "text": "5.1.1 Contexto y Cambios Metodológicos\nEn 2021, la ECH adoptó un diseño de panel rotativo, reemplazando su diseño cross-section anterior. Este cambio permite el seguimiento de hogares durante seis meses, tras lo cual se incorporan nuevos grupos de rotación en el panel, como se muestra en la Figura 5.1 (Instituto Nacional de Estadı́stica 2021). Esto mejora:\n\nLa precisión de las estimaciones\nEl análisis de dinámicas laborales\nLa medición de indicadores socioeconómicos\nEl estudio de transiciones en el mercado laboral\n\n\n\n\n\n\n\nFigura 5.1: Paneles Rotativos, extraído de documento metodológico de la ECH 2023\n\n\n\n\n\n5.1.2 Carga y Procesamiento de Datos\nLa ECH ha sido la principal fuente de información sobre el mercado laboral uruguayo desde 1968 y expandió su cobertura nacional en 1980. Los microdatos están disponibles desde 2006 en el portal ANDA del INE.\nPara trabajar con la ECH 2023, se requieren:\n\nECH_implantacion_2023.csv\nECH Seguimiento[1-12].csv\nArchivos de pesos replicados Bootstrap mensuales (enero-diciembre 2023)\n\nUn aspecto técnico importante es el manejo eficiente de los pesos muestrales replicados. metasurvey optimiza este proceso convirtiendo automáticamente los archivos Excel de pesos bootstrap a formato CSV, mejorando significativamente el rendimiento en análisis posteriores.\n\n\n\nCódigo 5.1: Carga de la encuesta continua de hogares en 2023, se carga la implantación y el seguimiento de la encuesta, se especifica el tipo de encuesta, el peso de la implantación y el peso del seguimiento, en este caso se utilizan pesos replicados bootstrap para el seguimiento de la encuesta.\n\n\n\n\nCódigo\npath_dir &lt;- here::here(\"example-data\", \"ech\", \"ech_2023\")\nech_2023 &lt;- load_panel_survey(\n  path_implantation = file.path(\n    path_dir,\n    \"ECH_implantacion_2023.csv\"\n  ),\n  path_follow_up = file.path(\n    path_dir,\n    \"seguimiento\"\n  ),\n  svy_type = \"ECH_2023\",\n  svy_weight_implantation = add_weight(\n    annual = \"W_ANO\"\n  ),\n  svy_weight_follow_up = add_weight(\n    monthly = add_replicate(\n      \"W\",\n      replicate_path = file.path(\n        path_dir,\n        c(\n          \"Pesos replicados Bootstrap mensuales enero_junio 2023\",\n          \"Pesos replicados Bootstrap mensuales julio_diciembre 2023\"\n        ),\n        c(\n          \"Pesos replicados mensuales enero_junio 2023\",\n          \"Pesos replicados mensuales Julio_diciembre 2023\"\n        )\n      ),\n      replicate_id = c(\"ID\" = \"ID\"),\n      replicate_pattern = \"wr[0-9]+\",\n      replicate_type = \"bootstrap\"\n    )\n  )\n)\n\n\n\n\n\n\n\n5.1.3 Construcción de Variables e Indicadores\nEl paquete permite dos enfoques para la construcción de variables:\n\nUtilizar recetas predefinidas disponibles a través de la API de metasurvey\nCrear recetas personalizadas según necesidades específicas\n\nPor ejemplo, para calcular indicadores del mercado laboral:\n\n\n\nCódigo 5.2: Se puede ver las variables que dependen de la receta de ingreso compatibilizado para la ECH 2022.\n\n\n\n\nCódigo\ningreso_compatibilizado &lt;- get_recipe(\n  svy_type = \"ech\",\n  svy_edition = \"2022\",\n  topic = \"ingreso\"\n)\ningreso_compatibilizado$depends_on\n\n\n\n\n\nA continuación se presentan algunas recetas que se pueden utilizar para calcular las tasas de mercado de trabajo a nivel mensual, trimestral y anual.\n\n\n\nCódigo 5.3: Creación de variables para el cálculo de tasas de mercado de trabajo en los microdatos de seguimiento de la ECH 2023.\n\n\n\n\nCódigo\nech_2023 &lt;- ech_2023 %&gt;%\n  step_recode(\n    \"pea\",\n    POBPCOAC %in% 2:5 ~ 1,\n    .default = 0,\n    comment = \"Población Económicamente Activa\",\n    .level = \"follow_up\"\n  ) %&gt;%\n  step_recode(\n    \"pet\",\n    e27 &gt;= 14 ~ 1,\n    .default = 0,\n    comment = \"Población Empleada\",\n    .level = \"follow_up\"\n  ) %&gt;%\n  step_recode(\n    \"po\",\n    POBPCOAC == 2 ~ 1,\n    .default = 0,\n    comment = \"Población Ocupada\",\n    .level = \"follow_up\"\n  ) %&gt;%\n  step_recode(\n    \"pd\",\n    POBPCOAC %in% 3:5 ~ 1,\n    .default = 0,\n    comment = \"Población Desocupada\",\n    .level = \"follow_up\"\n  )\n\nech_2023_bake &lt;- bake_steps(ech_2023)\n\n\n\n\n\nEn el código 5.3 se crean las variables necesarias para el cálculo de las tasas de mercado de trabajo a partir de los microdatos de seguimiento de la ECH 2023. Las variables creadas son: Población Económicamente Activa (PEA), Población Empleada (PET), Población Ocupada (PO) y Población Desocupada (PD). Una cosa importante es que la variable POBPCOAC es una variable construida por el INE que indica la condición de actividad, esta variable se construye a partir de los formularios dentro de metasurvey se encuentra a modo de receta la sintaxis publicada hasta la versión 2019 de la ECH, la misma fue basado en archivos PDF donde incluían un script de SPSS para la construcción de la variable. Para años posteriores no fue publicado este documento, se espera en breve dejar disponible la receta para los años 2020 considerando el nuevo formulario y revisando las versiones anteriores.\n\n\n5.1.4 Estimación de Tasas de Mercado de Trabajo\nUna vez creadas las variables básicas, podemos calcular las tasas de actividad, empleo y desempleo utilizando la función workflow. Esta función permite realizar estimaciones a diferentes niveles temporales (mensual, trimestral, anual) y con distintos tipos de agregación.\n\nEstimación por trimestre\n\n\n\nCódigo 5.4: Estimación de tasas de mercado de trabajo a nivel trimestral a partir de las estimaciones mensuales.\n\n\n\n\nCódigo\nmercado_trabajo_mensual &lt;-\n  workflow(\n    survey = extract_surveys(\n      ech_2023_bake,\n      quarterly = 1:4\n    ),\n    survey::svyratio(\n      ~ pea,\n      denominator = ~ pet\n    ),\n    survey::svyratio(\n      ~ po,\n      denominator = ~ pet\n    ),\n    survey::svyratio(\n      ~ pd,\n      denominator = ~ pea\n    ),\n    estimation_type = \"quarterly:monthly\"\n  )\n\n\n\n\n\n\n\n\nTabla 5.1: Tasas de mercado de trabajo a nivel trimestral a partir de las estimaciones mensuales de la ECH 2023 con sus respectivos errores estándar y coeficientes de variación.\n\n\n\n\n\n\n\n\n\n\n\nComo se puede ver en el código 5.4 se pueden realizar estimaciones a diferentes niveles temporales y con distintos tipos de agregación, en este caso se realizan estimaciones a nivel trimestral a partir de las estimaciones mensuales, el resultado de la estimación se puede ver en la Tabla 5.1.\n\n\nEstimación de valores anuales\nTambién es posible realizar estimaciones a nivel anual, para esto se debe de considerar las medias de las estimaciones mensuales para cada trimestre y luego realizar la estimación anual.\nLa nueva metodología puede dar confusiones sobre que microdatos utilizar ya que para estimaciones anuales se consideran los microdatos de implantación y las referidas a mercado de trabajo se consideran los microdatos de seguimiento esto se debe a que el hogar luego de ser seleccionado en la implantación el formulario se realiza por vía telefónica y se centra unicamente a variables referidas al situación de empleo del hogar. Para realizar estimaciones por ejemplo de cantidad de personas que finalizaron un ciclo educativo se debe de considerar los microdatos de implantación a nivel anual.\nSi bien dentro de metasurvey se pueden realizar estimaciones en diferentes años, es necesario tener cierta consideración del cambio metodológico al momento de interpretar los resultados, situaciones que también ocurrieron en la edición de 2012 y 2006 («Comunicado Encuesta Continua de Hogares», s. f.).\n\n\n\nCódigo 5.5: Estimación de tasas de mercado de trabajo a nivel anual a partir de las estimaciones mensuales.\n\n\n\n\nCódigo\nmercado_trabajo_anual = workflow(\n  survey = extract_surveys(\n    ech_2023_bake,\n    annual = 2023\n  ),\n  survey::svyratio(\n    ~ pea,\n    denominator = ~ pet\n  ),\n  survey::svyratio(\n    ~ po,\n    denominator = ~ pet\n  ),\n  survey::svyratio(\n    ~ pd,\n    denominator = ~ pea\n  ),\n  estimation_type = \"annual:monthly\"\n)\n\n\n\n\n\n\n\\newpage\n\n::: {#tbl-ech-mercado-trabajo-anual}\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n&lt;div class=\"reactable html-widget html-fill-item\" id=\"htmlwidget-56698225c3e940e68595\" style=\"width:auto;height:auto;\"&gt;&lt;/div&gt;\n&lt;script type=\"application/json\" data-for=\"htmlwidget-56698225c3e940e68595\"&gt;{\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"tasa\":[\"Tasa de Desempleo\",\"Tasa de Actividad\",\"Tasa de Ocupación\"],\"stat\":[\"survey::svyratio: pd/pea\",\"survey::svyratio: pea/pet\",\"survey::svyratio: po/pet\"],\"type\":[\"2023\",\"2023\",\"2023\"],\"value\":[0.0832850312206756,0.633717371796529,0.580942308612143],\"se\":[0.0249243524346522,0.018112808144419,0.017773076723754],\"cv\":[0.299192969024257,0.0285957691561238,0.0306167791984376],\"evaluate\":[\"Excelente\",\"Excelente\",\"Excelente\"]},\"columns\":[{\"id\":\"tasa\",\"name\":\"tasa\",\"type\":\"list\",\"header\":\"Indicador\"},{\"id\":\"stat\",\"name\":\"stat\",\"type\":\"character\",\"header\":\"Llamada\"},{\"id\":\"type\",\"name\":\"type\",\"type\":\"character\",\"header\":\"Periodo\"},{\"id\":\"value\",\"name\":\"value\",\"type\":\"numeric\",\"format\":{\"cell\":{\"digits\":1,\"percent\":true},\"aggregated\":{\"digits\":1,\"percent\":true}},\"header\":\"Valor\"},{\"id\":\"se\",\"name\":\"se\",\"type\":\"numeric\",\"format\":{\"cell\":{\"digits\":1,\"percent\":true},\"aggregated\":{\"digits\":1,\"percent\":true}},\"header\":\"Error Estándar\"},{\"id\":\"cv\",\"name\":\"cv\",\"type\":\"numeric\",\"format\":{\"cell\":{\"digits\":4},\"aggregated\":{\"digits\":4}},\"header\":\"CV\"},{\"id\":\"evaluate\",\"name\":\"evaluate\",\"type\":\"character\",\"header\":\"Evaluación\"}],\"highlight\":true,\"striped\":true,\"dataKey\":\"e98095f1c287770c5f530b4f1fa1944c\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]}&lt;/script&gt;\n::: :::\nTasas de mercado de trabajo a nivel anual a partir de las estimaciones mensuales de la ECH 2023 con sus respectivos errores estándar y coeficientes de variación considerando las replicas bootstrap.\n:::\nPodemos ver que se obtiene un objeto donde se tiene las estimaciones de las tasas de mercado de trabajo a nivel mensual, trimestral y anual. En este caso se utilizan las replicas bootstrap para calcular los errores estándar de las estimaciones y se incluye una recomendación sobre la confiabilidad de las estimaciones en base al coeficiente de variación de las estimaciones.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#encuesta-permanente-de-hogares-de-argentina",
    "href": "chapters/chapter5.html#encuesta-permanente-de-hogares-de-argentina",
    "title": "5  Casos de uso",
    "section": "5.2 Encuesta Permanente de Hogares de Argentina",
    "text": "5.2 Encuesta Permanente de Hogares de Argentina\nPara demostrar la versatilidad de metasurvey, se presenta un segundo caso de uso con la Encuesta Permanente de Hogares (EPH) de Argentina. La EPH es una encuesta continua de hogares que se realiza en el país desde 1985 y es la principal fuente de información sobre el mercado laboral argentino. Los microdatos de la EPH están disponibles en el portal del INDEC.\nPodemos hacer algo similar a lo que hicimos con la ECH, en este caso cargamos los microdatos de la EPH 2022 trimestre 3 y creamos las variables necesarias para el cálculo de las tasas de mercado de trabajo. Estos steps fueron basados en base al formulario de la encuesta y la documentación disponible.\n\n\n\nCódigo 5.6: Carga de la encuesta permanente de hogares en el tercer trimestre de 2022, se crean las variables necesarias para el cálculo de tasas de mercado de trabajo.\n\n\n\neph2022_3 &lt;- metasurvey::load_survey(\n  path = metasurvey::load_survey_example(\n    \"eph\",\n    \"eph2022_3\"\n  ),\n  svy_type = \"eph\",\n  svy_edition = \"eph_202302\",\n  svy_weight = add_weight(\n    monthly = \"PONDERA\"\n  )\n) |&gt;\n  metasurvey::step_recode(\n    \"pea\",\n    ESTADO %in% 1:2 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pet\",\n    ESTADO != 4 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"po\",\n    ESTADO == 1 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pd\",\n    ESTADO == 2 ~ 1,\n    .default = 0\n  )\n\n\n\n\n\n5.2.1 Visualización de las recetas\nAlgo interesante que se puede hacer con metasurvey es visualizar las recetas que se utilizan para la construcción de las variables, esto puede ser útil para entender como se construyen las variables y que variables dependen de otras. En este caso se muestra la visualización para la creación de la variable POBPCOAC en la ECH 2019, si bien el INE ya incorpora esta variable en los microdatos, se puede ver como se construye la variable en base a otras variables del formulario.\n\n\n\nCódigo 5.7: Carga de la encuesta y se obtienen las recetas disponibles referidas al tópico de mercado de trabajo.\n\n\n\nech_2019 &lt;- load_survey(\n    path = \"https://metasurvey-example-data.s3.us-east-2.amazonaws.com/ech/ech_2019.csv\",\n    svy_type = \"ech\",\n    svy_edition = \"2019\",\n    svy_weight = add_weight(\n      annual = \"pesoano\"\n    ),\n    recipes = get_recipe(\n      svy_type = \"ECH\",\n      svy_edition = 2019,\n      topic = \"Mercado de trabajo\"\n    )\n)\nech_2019 &lt;- bake_recipes(ech_2019)\n\n\n\n\nSi bien se puede ingresar a los atributos de la receta para ver las variables que dependen de la misma, se puede visualizar de una forma más amigable con la función view_graph como se puede ver en la Figura 5.2.\n\n\n\n\n\n\n\n\n\n\n\nFigura 5.2: Flujo de construcción de la variable POBPCOAC en la ECH 2019 y variables de mercado de trabajo que dependen de la misma.\n\n\n\n\n\n5.2.2 Compartiendo Recetas entre Usuarios\nEn el ejemplo anterior se descargaron recetas ya definidas pero también se pueden compartir recetas entre usuarios, esto puede ser útil para compartir recetas que se han construido en base a la documentación de la encuesta o para compartir recetas que se han construido en base a la experiencia de los usuarios como se ve en el código 5.8.\n\n\n\nCódigo 5.8: Compartir receta de clasificación de la población por condición de actividad en la ECH 2019.\n\n\n\nreceta &lt;- steps_to_recipe(\n    name = \"Población por condición de actividad\",\n    user = \"INE-Uruguay\",\n    svy = ech_2019,\n    description = \"Clasificación de la población por condición de actividad\",\n    steps = ech_2019$steps,\n    topic = \"Mercado de trabajo\"\n)\n\npublish_recipe(receta)\n#&gt; Recipe successfully published to metasurvey API. Thanks for your contribution :). Status code: 201\n#&gt; $insertedId\n#&gt; [1] \"6744c91dbbbfd943831934b8\"",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#resumen",
    "href": "chapters/chapter5.html#resumen",
    "title": "5  Casos de uso",
    "section": "5.3 Resumen",
    "text": "5.3 Resumen\nLos casos de uso presentados demuestran la flexibilidad y potencia de metasurvey para el procesamiento de diferentes encuestas de hogares:\n\nEn el caso de la ECH, se mostró cómo manejar eficientemente el nuevo diseño de panel rotativo y los pesos muestrales replicados bootstrap para generar estimaciones precisas de indicadores del mercado laboral.\nCon la EPH, se evidenció la capacidad del paquete para adaptarse a diferentes estructuras de datos y metodologías de encuestas, manteniendo una interfaz consistente.\nLa visualización de recetas mediante view_graph() facilita la comprensión de las dependencias entre variables y la transparencia en la construcción de indicadores.\nLa posibilidad de compartir recetas entre usuarios permite aprovechar el conocimiento colectivo y acelerar el proceso de análisis de encuestas.\n\nEstas características hacen de metasurvey una herramienta valiosa para investigadores y analistas que trabajan con encuestas de hogares en América Latina, proporcionando un marco unificado y eficiente para el procesamiento y análisis de datos.\n\n\n\n\n«Comunicado Encuesta Continua de Hogares». s. f. https://www.gub.uy/instituto-nacional-estadistica/comunicacion/noticias/comunicado-encuesta-continua-hogares.\n\n\nInstituto Nacional de Estadı́stica. 2021. «Metodologı́a de la Encuesta Continua de Hogares Instituto Nacional de Estadı́stica». https://www.ine.gub.uy.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html",
    "href": "chapters/chapter6.html",
    "title": "6  Pasos a futuro",
    "section": "",
    "text": "6.1 Optimización del rendimiento y escalabilidad\nEl desarrollo de metasurvey ha establecido una base sólida para el procesamiento reproducible y transparente de encuestas por muestreo, pero el camino hacia adelante presenta múltiples oportunidades de mejora y expansión. En este capítulo se enumeran las principales direcciones de desarrollo futuro del paquete, abarcando desde optimizaciones técnicas hasta la construcción de una comunidad activa de usuarios y colaboradores, con el objetivo de consolidar a metasurvey como una herramienta fundamental en el análisis de encuestas.\nUna prioridad inmediata es la implementación de procesamiento paralelo nativo para operaciones con grandes conjuntos de datos. Esta mejora resulta particularmente relevante en dos escenarios principales: cuando se trabaja con encuestas que tienen numerosas réplicas bootstrap, donde el cálculo de errores estándar puede volverse computacionalmente intensivo, y al procesar múltiples años de datos simultáneamente para análisis longitudinales o comparativos.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#expansión-de-funcionalidades-estadísticas",
    "href": "chapters/chapter6.html#expansión-de-funcionalidades-estadísticas",
    "title": "6  Pasos a futuro",
    "section": "6.2 Expansión de funcionalidades estadísticas",
    "text": "6.2 Expansión de funcionalidades estadísticas\nLa expansión de capacidades analíticas incluirá la implementación de los métodos de (Deville y Tillé 2005) para estimación de varianzas en diseños complejos, junto con un soporte ampliado para diseños muestrales sofisticados.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#mejoras-en-la-experiencia-del-usuario",
    "href": "chapters/chapter6.html#mejoras-en-la-experiencia-del-usuario",
    "title": "6  Pasos a futuro",
    "section": "6.3 Mejoras en la experiencia del usuario",
    "text": "6.3 Mejoras en la experiencia del usuario\n\nDocumentación y tutoriales\nLa documentación se expandirá significativamente con casos de uso reales y tutoriales. Se incluirán viñetas temáticas que cubrirán diferentes tipos de análisis, complementadas por ejemplos dentro del paquete y conjuntos de datos de demostración.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#integración-y-extensibilidad",
    "href": "chapters/chapter6.html#integración-y-extensibilidad",
    "title": "6  Pasos a futuro",
    "section": "6.4 Integración y extensibilidad",
    "text": "6.4 Integración y extensibilidad\n\nIncorporación de scripts IECON compatibilizado\nLa integración de los scripts de compatibilización del IECON representa un hito importante en el desarrollo del paquete. Se implementará un sistema completo que incorporará estos scripts como recetas predefinidas, asegurando la consistencia histórica mediante un robusto sistema de versionado. Las validaciones automáticas garantizarán la integridad de las series temporales, mientras que una documentación exhaustiva explicará la metodología subyacente.\nPara facilitar el análisis de consistencia entre períodos, se desarrollarán herramientas de visualización especializadas. Estas permitirán a los usuarios identificar rápidamente anomalías y verificar la calidad de las compatibilizaciones realizadas.\n\n\nSistema de validación de recetas\nEl sistema de validación se estructurará en tres niveles principales:\nCertificación institucional La validación comenzará con un sistema de certificación que otorgará sellos de verificación a instituciones estadísticas nacionales. Las recetas académicas pasarán por un riguroso proceso de revisión por pares, estableciendo diferentes niveles de confianza según su origen institucional.\nValidación comunitaria Se implementará un sistema de reputación basado en la experiencia colectiva de los usuarios. La comunidad podrá votar y comentar sobre las recetas compartidas, generando un ranking dinámico de confiabilidad.\nValidación técnica Un conjunto de métricas automatizadas evaluará aspectos como la consistencia interna, la reproducibilidad y el impacto en las estimaciones. Los administradores institucionales contarán con un panel de control para supervisar y gestionar este proceso.\n\n\nAPI y servicios web\nLa API se expandirá para facilitar el intercambio de recetas entre usuarios, implementando un sistema robusto de versionado que garantice la compatibilidad a largo plazo. El portal web centralizado permitirá explorar y gestionar recetas públicas, facilitando la colaboración en tiempo real entre equipos de investigación.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#invitar-a-colaborar",
    "href": "chapters/chapter6.html#invitar-a-colaborar",
    "title": "6  Pasos a futuro",
    "section": "6.5 Invitar a colaborar",
    "text": "6.5 Invitar a colaborar\nEl desarrollo de metasurvey pretende continuar luego de la finalización de este trabajo intentnado establecer una comunidad activa de usuarios y colaboradores. Se espera que esta comunidad contribuya con nuevas ideas, reporte errores y colabore en la implementación de nuevas funcionalidades. Pueden contribuir a través del repositorio de GitHub.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#control-de-calidad-y-certificación",
    "href": "chapters/chapter6.html#control-de-calidad-y-certificación",
    "title": "6  Pasos a futuro",
    "section": "6.6 Control de calidad y certificación",
    "text": "6.6 Control de calidad y certificación\nEl aseguramiento de la calidad se basará en una estrategia integral que incluirá la ampliación de la cobertura de pruebas automatizadas al 80%, implementación de pruebas end-to-end, y un sistema robusto de validación para recetas compartidas. La certificación de rOpenSci será un objetivo prioritario, respaldado por chequeos y guías detalladas de mejores prácticas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#visión-a-largo-plazo",
    "href": "chapters/chapter6.html#visión-a-largo-plazo",
    "title": "6  Pasos a futuro",
    "section": "6.7 Visión a largo plazo",
    "text": "6.7 Visión a largo plazo\nEn los próximos años, se espera que metasurvey incorpore nuevas metodologías en el análisis de encuestas. En conjunto a una forma de validar y compartir recetas con un sistema de reputación y certificación, se espera que metasurvey se convierta en una herramienta fundamental para el análisis de encuestas por muestreo, facilitando la colaboración entre instituciones y contribuyendo al avance metodológico en el análisis de encuestas.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/chapter6.html#conclusiones-finales-y-visión-de-futuro",
    "href": "chapters/chapter6.html#conclusiones-finales-y-visión-de-futuro",
    "title": "6  Pasos a futuro",
    "section": "6.8 Conclusiones finales y visión de futuro",
    "text": "6.8 Conclusiones finales y visión de futuro\nLas conclusiones de este trabajo se pueden estructurar en tres niveles:\nLogros alcanzados El desarrollo de metasurvey ha demostrado la viabilidad de crear una herramienta que estandariza y hace reproducible el procesamiento de encuestas. Los capítulos anteriores evidencian cómo el diseño modular y el sistema de recetas resuelven problemas fundamentales en el análisis de encuestas.\nDesafíos identificados A lo largo del desarrollo se identificaron retos importantes, como la necesidad de balancear flexibilidad con estandarización, y la importancia de mantener la eficiencia computacional al procesar grandes volúmenes de datos.\nPerspectivas futuras El camino de desarrollo planteado en este capítulo busca no solo mejorar las capacidades técnicas del paquete, sino establecerlo como una herramienta fundamental que facilite la colaboración entre instituciones y contribuya al avance metodológico en el análisis de encuestas.\nEl desarrollo futuro de metasurvey se enfocará en convertir el paquete en una herramienta fundamental para el análisis de encuestas, manteniendo su compromiso con la transparencia y reproducibilidad mientras expande sus capacidades. Las mejoras planificadas en rendimiento, funcionalidades, usabilidad e integración, junto con el desarrollo de una comunidad activa, buscan establecer a metasurvey como una herramienta de referencia en el análisis de encuestas por muestreo.\nEste camino de desarrollo no solo mejorará las capacidades técnicas del paquete, sino que también fortalecerá su rol como herramienta educativa y de investigación, facilitando la colaboración entre instituciones y contribuyendo al avance de la metodología estadística en el análisis de encuestas.\nEl plan de trabajo se encuentra en un proyecto de GitHub, donde se detallan las tareas y responsables de cada etapa. Se invita a la comunidad a participar activamente en el desarrollo de metasurvey, aportando ideas, reportando errores y colaborando en la implementación de nuevas funcionalidades.\n\n\n\n\nDeville, Jean-Claude, y Yves Tillé. 2005. «Variance approximation under balanced sampling». Journal of Statistical Planning and Inference 128 (2): 569-91. https://doi.org/10.1016/j.jspi.2003.11.011.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Pasos a futuro</span>"
    ]
  },
  {
    "objectID": "chapters/bibliography.html",
    "href": "chapters/bibliography.html",
    "title": "Biblografía",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey,\nand Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n“Apache Airflow Documentation.” n.d. https://airflow.apache.org/docs/latest/.\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael\nChirico, Toby Hocking, and Benjamin Schwendinger. 2024. Data.table:\nExtension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John\nAinsworth, Jiten Bhagat, Philip Couch, et al. 2013. “Why Linked\nData Is Not Enough for Scientists.” Future Generation\nComputer Systems, Special section: Recent advances in e-science, 29\n(2): 599–611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars\nKotthoff, and Bernd Bischl. 2021. “Mlr3pipelines - Flexible\nMachine Learning Pipelines in r.” Journal of Machine Learning\nResearch 22 (184): 1–7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, and Santa Ivanova. 2020. Vardpoor:\nEstimation of Indicators on Social Exclusion and Poverty and Its\nLinearization, Variance Estimation. Riga, Latvia: Central\nStatistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChambers, John M. 2014. “Object-Oriented Programming, Functional\nProgramming and r.” Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference\nSemantics.\n\n\nChevalier, Martin. 2023. Gustave: A User-Oriented Statistical\nToolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCodecov: Code Coverage Insights. 2024. https://about.codecov.io.\n\n\n“Comunicado Encuesta Continua de Hogares.” n.d. https://www.gub.uy/instituto-nacional-estadistica/comunicacion/noticias/comunicado-encuesta-continua-hogares.\n\n\nCook, Di. 2014. “Statistical Computing Research |.” http://dicook.org/2014/10/05/content/post/2014-10-5-statistical-computing/.\n\n\nDavison, Andrew P, and John E Huth. 2012. “Sumatra: A Toolkit for\nReproducible Research.” arXiv Preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. “Ech: Caja de\nHerramientas Para Procesar La Encuesta Continua de Hogares.” https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, and Yves Tille. 1998. “Unequal Probability\nSampling Without Replacement Through a Splitting Method.”\nBiometrika 85 (1): 89–101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, and Yves Tillé. 2005. “Variance\nApproximation Under Balanced Sampling.” Journal of\nStatistical Planning and Inference 128 (2): 569–91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nDriessen, Vincent. 2010. “A Successful Git Branching\nModel.” https://nvie.com/posts/a-successful-git-branching-model/.\n\n\nEllis, Greg Freedman, and Ben Schneider. 2023. Srvyr: ’Dplyr’-Like\nSyntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nEscobar, Emilio L., and Yves G. Berger. 2013. “A New Replicate\nVariance Estimator for Unequal Probability Sampling Without\nReplacement.” The Canadian Journal of Statistics / La Revue\nCanadienne de Statistique 41 (3): 508–24. https://www.jstor.org/stable/43186201.\n\n\nEscobar, Emilio Lopez, Ernesto Barrios Zamudio, and Juan Francisco Munoz\nRosas. 2023. samplingVarEst: Sampling Variance Estimation.\n\n\nExpectations, Great. 2024. Great Expectations Documentation.\nSuperconductive. https://docs.greatexpectations.io.\n\n\nGitHub Actions: Automate Your Workflow. 2024. GitHub. https://github.com/features/actions.\n\n\nHajek, Jaroslav. 1964. “Asymptotic Theory of Rejective Sampling\nwith Varying Probabilities from a Finite Population.” The\nAnnals of Mathematical Statistics 35 (4): 1491–1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nHorvitz, D. G., and D. J. Thompson. 1952. “A Generalization of\nSampling Without Replacement from a Finite Universe.” Journal\nof the American Statistical Association 47 (260): 663–85. https://doi.org/10.2307/2280784.\n\n\nInstituto Nacional de Estadı́stica. 2021. “Metodologı́a\nde La Encuesta Continua de\nHogares Instituto Nacional de\nEstadı́stica.” https://www.ine.gub.uy.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger,\nMatthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024.\nJupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” The\nComputer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, and\nNatsumi Shokida. 2020. Eph: Argentina’s Permanent Household Survey\nData and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, and Emil Hvitfeldt. 2024. Recipes:\nPreprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLandau, William Michael. 2018. “The Drake r Package: A Pipeline\nToolkit for Reproducibility and High-Performance Computing.”\nJournal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. “The Targets r Package: A Dynamic Make-Like\nFunction-Oriented Pipeline Toolkit for Reproducibility and\nHigh-Performance Computing.” Journal of Open Source\nSoftware 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2004. “Analysis of Complex Survey Samples.”\nJournal of Statistical Software 9 (April): 1–19. https://doi.org/10.18637/jss.v009.i08.\n\n\n———. 2011. Complex Surveys: A Guide to Analysis Using R. John\nWiley & Sons.\n\n\n———. 2024. “Survey: Analysis of Complex Survey Samples.”\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in r:\nStatistical Programming for Data Science, Analysis and Finance.\nSPRINGER.\n\n\nMerkel, Dirk. 2014. “Docker: Lightweight Linux Containers for\nConsistent Development and Deployment.” Linux Journal\n2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy\nVasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and\nTimnit Gebru. 2019. “Model Cards for Model Reporting.” In,\n220–29. https://doi.org/10.1145/3287560.3287596.\n\n\nPrabhu, Anirudh, and Peter Fox. 2020. “Reproducible\nWorkflow,” December. http://arxiv.org/abs/2012.13427.\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: Venv -\nCreation of Virtual Environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\nR Core Team. 2023a. Foreign: Read Data Stored by ’Minitab’, ’s’,\n’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\n———. 2023b. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\n“R Packages (2e).” n.d. https://r-pkgs.org/.\n\n\nrOpenSci, Brooke Anderson, Scott Chamberlain, Laura DeCicco, Julia\nGustavsen, Anna Krystalli, Mauro Lepore, et al. 2024. “rOpenSci Packages: Development, Maintenance, and Peer\nReview.” Zenodo. https://doi.org/10.5281/zenodo.10797633.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig.\n2013. “Ten Simple Rules for Reproducible Computational\nResearch.” PLOS Computational Biology 9 (10): e1003285.\nhttps://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSärndal, Carl-Erik, Bengt Swensson, and Jan Wretman. 2003. Model\nAssisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, and Alexander Walker. 2024. Openxlsx: Read,\nWrite and Edit Xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nSchneider, Benjamin. 2023. “Svrep: Tools for Creating, Updating,\nand Analyzing Survey Replicate Weights.” https://CRAN.R-project.org/package=svrep.\n\n\nSottile, Anthony, and Contributors. 2024. Pre-Commit: A Framework\nfor Managing and Maintaining Multi-Language Pre-Commit Hooks. https://pre-commit.com.\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D. Peng. 2014.\nImplementing Reproducible Research. CRC Press.\n\n\nThomas Mailund. 2017. Metaprogramming in r. 1st ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nUshey, Kevin, and Hadley Wickham. 2023. Renv: Project\nEnvironments. https://CRAN.R-project.org/package=renv.\n\n\nVargas, Mauricio. 2024. Casen: Metodos de Estimacion Con Disenio\nProbabilistico y Estratificado En Encuesta CASEN (Estimation Methods\nwith Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. “Reproducibility and Replicability in\nEconomics.” Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, and Matt Herman. 2024. Tidycensus: Load US Census\nBoundary and Attribute Data as ’Tidyverse’ and ’Sf’-Ready Data\nFrames. https://walker-data.com/tidycensus/.\n\n\nWickham, Hadley. 2011b. “Testthat: Get Started with\nTesting.” The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2011a. “Testthat: Get Started with Testing.” The R\nJournal 3: 5–10. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced r, Second Edition. CRC Press.\n\n\n———. 2023. Httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher.\n2024. Usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster.\n2024. Roxygen2: In-Line\nDocumentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Jay Hesselberth, Maëlle Salmon, Olivier Roy, and Salim\nBrüggemann. 2024. Pkgdown: Make Static HTML Documentation for a\nPackage. https://CRAN.R-project.org/package=pkgdown.\n\n\nWickham, Hadley, Jim Hester, Winston Chang, and Jennifer Bryan. 2022.\nDevtools: Tools to Make Developing r Packages Easier. https://CRAN.R-project.org/package=devtools.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2023. Haven: Import\nand Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "Biblografía"
    ]
  }
]