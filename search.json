[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "metasurvey",
    "section": "",
    "text": "Descripción del proyecto\n\n\n\n\n\n\n\nAdvertencia\n\n\n\nEste capítulo está en proceso de escritura. Consulte la rama de desarrollo para ver el avance del capítulo\n\n\n\n\n\nmetasurvey",
    "crumbs": [
      "Descripción del proyecto"
    ]
  },
  {
    "objectID": "chapters/chapter1.html",
    "href": "chapters/chapter1.html",
    "title": "1  Introducción",
    "section": "",
    "text": "1.1 Motivación\nLas encuestas por muestreo son una herramienta fundamental para la obtención de información sobre cierta población de interés, ya que permiten obtener información a partir de una muestra representativa de la misma. Cada encuesta por muestreo tiene una estructura y un proceso generador de datos que permite obtener estimaciones puntuales y sus errores asociados. En general, el procesamiento de encuestas puede ser tedioso y propenso a errores o difíciles de brindar transparencia y reproducibilidad, especialmente si se quiere obtener indicadores que requieren varios pasos como tasas de mercado laboral, ingreso salarial, índices de pobreza, entre otros (Vilhuber 2020).\nEn general, el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Si bien existen diferentes esfuerzos para facilitar el procesamiento de encuestas, en general estos paquetes tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés. Estas implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica.\nEn este sentido, es importante construir una herramienta que permita al usuarios tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, de una forma totalmente desacoplada dentro de las implementaciones de cada función.\nDentro de este documento se detalla el desarrollo de una herramienta que permita al usuario con simples pasos poder construir indicadores junto a una forma de obtener metodologías brindadas por la comunidad científica pudiendo reproducir los resultados o incluir de forma sencilla la metodología en su propio código. Esta herramienta debe permitir al usuario tener un control total sobre el proceso de transformación de los microdatos a indicadores, permitiendo que el usuario pueda validar y entender el proceso de construcción de indicadores, todo esto estará disponible en forma de paquete en R (R Core Team 2023).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#contexto",
    "href": "chapters/chapter1.html#contexto",
    "title": "1  Introducción",
    "section": "1.2 Contexto",
    "text": "1.2 Contexto\nA lo que refire a la teoría de la inferencia de poblaciones en muestreo de poblaciones finitas, es importante tener en cuenta la incertidumbre y errores asociados a las estimaciones producidas, en general esto no es considerado por los usuarios no expertos en metodología de muestreo. Esto puede llevar a conclusiones erróneas ya que en algunos casos el estimador asociado a la estimación cuenta con una alta variabilidad o fue calculado sin tener en cuenta el diseño muestral correcto.\nAntes de continuar, es importante distinguir dentro de la inferencia estadística el enfoque model-based inference y desing-based inference (Lumley 2011). En el primer enfoque, se asume que la población de interés se puede modelar mediante un modelo probabilístico y se pueden obtener estimaciones de los parámetros del modelo mediante técnicas de inferencia estadística. En el segundo enfoque, se asume que la población de interés es finita y se puede obtener estimaciones de los parámetros de la población mediante técnicas de muestreo.\nDentro de este trabajo se mencionara de forma intensiva el concepto de peso o ponderador y su importancia en la estimación de varianzas y errores asociados a las estimaciones. Dentro de la estadística existen diferentes conceptos referidos a ponderadores o pesos, entre ellos (en base (Lumley 2011)):\n\nPesos muestrales: Los pesos muestrales refiere a la cantidad de veces que un individuo de la población de interés está representado en la muestra. Estos pesos muestrales son los que provienen del diseño muestral, ya sea por el inverso de las probabilidades de selección, ajustes por no respuesta, entre otros.\nPesos de precisión: El concepto de precisión puede relacionarse con la variabilidad que tiene una observación sobre la estimación de un parámetro.\nPesos de frecuencia: Refire a la cantidad de veces que aparece un individuo en una muestra y este es resumido para incluir en un único registro.\n\nEs importante hacer esta distinción ya que tomando en cuenta los pesos en cualquiera de sus definiciones o consideraciones, en la mayoría de los casos se puede obtener estimaciones puntuales correctas, sin embargo como se mencionó anteriormente llegar a medidas de incertidumbre como errores estándar, intervalos de confianza totalmente incorrectos.\nUna vez considerado el proceso de inferencia también es crucial tener en cuenta el proceso de transformación de los microdatos a indicadores ya que es importante para interpretar los indicadores de manera correcta y realizar comparaciones a lo largo del tiempo para formalizar la metodología de su construcción. Muchas veces, diferentes usuarios hacen el mismo esfuerzo de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.\nEn los últimos años, el uso de R (R Core Team 2023) ha crecido exponencialmente en la comunidad científica, en especial en el área de la estadística y la ciencia de datos. R es un lenguaje de programación de código abierto ampliamente utilizado en la comunidad científica para el análisis de datos, estadística y aprendizaje automático, y en general se utiliza el concepto paquete para referirse a una colección de funciones, métodos y clases que extienden las funcionalidades de R propuestas por la misma comunidad de usuarios. En este sentido, metasurvey busca ser una herramienta relevante para el trabajo con encuestas por muestreo en general ya sea en las ciencias sociales o el uso genérico para otras disciplinas, buscando solucionar las limitaciones anteriormente mencionadas.\nAntes de continuar es importante definir el concepto de Estadística Computacional y su diferencia con Computación Estadística (Cook 2014), siendo este trabajo un aporte a la Estadística Computacional. La Estadística Computacional se refiere a la implementación de algoritmos y métodos estadísticos en un lenguaje de programación, mientras que la Computación Estadística se refiere a la utilización de herramientas computacionales para resolver problemas estadísticos. En este sentido, R es un lenguaje de programación que permite realizar Estadística Computacional y Computación Estadística, ya que cuenta con una amplia variedad de paquetes que permiten implementar algoritmos y métodos estadísticos y realizar análisis de datos de manera eficiente y reproducible.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#antecedentes-e-implementaciones-similares",
    "href": "chapters/chapter1.html#antecedentes-e-implementaciones-similares",
    "title": "1  Introducción",
    "section": "1.3 Antecedentes e implementaciones similares",
    "text": "1.3 Antecedentes e implementaciones similares\nActualmente existen varios esfuerzos para facilitar el procesamiento de encuestas, entre ellos existen principalmente dos tipos de paquetes, aquellos que implementan la metodología de inferencia en muestreo de poblaciones finitas como puede ser el paquete survey (Lumley 2024), gustave (Chevalier 2023), vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023), weights y aquellos que permiten acceder y manipular encuestas específicas como ech (Detomasi 2020), eph (Kozlowski et al. 2020), tidycensus (Walker y Herman 2024), casen (Vargas 2024) entre otros. Sin embargo, estos últimos tienen limitaciones en cuanto a la flexibilidad y transparencia del proceso de transformación de los microdatos a indicadores de interés, como puede ser el indice de pobreza, tasas del mercado laboral, ingreso salarial, etc. En general, sus implementaciones son muy sensibles a la estructura y las variables que componen la encuesta, un cambio en la estructura de la encuesta suele implicar una actualización del paquete utilizado para obtener los indicadores en la nueva edición de la encuesta, lo que resulta poco flexible ante cambios en la estructura, que pueden ser frecuentes en la práctica. Además en las implementaciones actuales, el usuario cuenta con una función de alto nivel que actúa como una caja negra, donde no se permite modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin tener que leer el código fuente o la documentación adjunta.\nEste tipo de problemas puede verse en ech (Detomasi 2020), donde existen funciones para crear variables de mercado laboral, educación o ingresos, pero estas funciones dependen de la existencia de ciertas variables en la encuesta, cuya estructura puede cambiar de una versión a otra de la encuesta. Sin revisar el cuerpo de la función, no se conoce el proceso de construcción de variables. Algo similar ocurre con eph (Kozlowski et al. 2020), donde se tienen funciones de alto nivel que no permiten modificar el código para adaptarlo a sus necesidades o entender cada paso que se realiza para obtener el indicador sin inspeccionar a fondo cómo se construyen las funciones del paquete. Esta inspección del código fuente, como consultar el repositorio de GitHub del paquete o revisar la definición de la función, puede ser una tarea tediosa y no garantiza que el usuario pueda entender el proceso de construcción de variables. Esto se debe a que el código puede ser muy extenso o que el usuario no tenga el conocimiento suficiente para entender el código o se empleen ciertos frameworks que el usuario no conozca, como el uso de las librerías dplyr (Wickham et al. 2023) o tidyr (Wickham, Vaughan, y Girlich 2024), muy populares en R para el manejo de datos. También puede ser difícil aislar el proceso de manipulación de la encuesta de la implementación específica de la función para manejar la forma de presentación, estructura del objeto a devolver, etc. Un claro ejemplo de esto puede verse en tidycensus (Walker y Herman 2024), donde existe una función para obtener datos sobre la migración de la comunidad estadounidense, y en la misma implementación se encuentran pasos para mejorar la estructura del conjunto de datos a devolver. En este sentido, el usuario no puede aislar el proceso de re-codificación/construcción de variables sobre variables originales y la obtención de datos geográficos y presentación.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#propuesta",
    "href": "chapters/chapter1.html#propuesta",
    "title": "1  Introducción",
    "section": "1.4 Propuesta",
    "text": "1.4 Propuesta\nPara científicos sociales, es importante tener en cuenta que el proceso de transformación de los microdatos a indicadores requiere de un conocimiento profundo de la encuesta y en su mayoría no es de conocimiento general. Es de interés obtener información histórica de indicadores y en general es un proceso tedioso y propenso a errores, especialmente si proviene de encuestas donde su estructura y/o forma de preguntar o su codificación puede cambiar con el tiempo. Esto resulta en un proceso extenso y difícil de entender hasta llegar a la construcción de esta serie de indicadores. Muchas veces, diferentes usuarios hacen el mismo proceso de construcción de indicadores de manera independiente y sin compartir el código fuente o la metodología de construcción de indicadores, ya que cada uno utiliza su propio estilo de programación o hasta diferentes paquetes estadísticos, en su mayoría propietarios como SPSS, SAS o STATA, donde si bien el usuario puede compartir la sintaxis para su construcción, esta está ligada al software y depende de que el usuario tenga el software instalado con una licencia activa y pueda correr el código.\nEn este sentido, es importante que el usuario pueda tener un control total sobre el proceso de transformación de los microdatos a indicadores, ya que esto permite que el usuario pueda validar y entender el proceso de construcción de indicadores, además de brindar una herramienta común libre de estilos de programación y definiendo con simples pasos el proceso de construcción de variables sintéticas, como recodificar variables creando grupos en base a criterios complejos, tratamiento de variables continuas como el ingreso salarial en base a una metodología rigurosa y fácil de referenciar en la implementación. Es crucial que este proceso sea transparente y entendible para el usuario. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metasurvey y su implementación de recetas para la construcción de indicadores mediante la meta-programación.\nAl trabajar con encuestas por muestreo, es importante tener en cuenta la forma en la que se obtuvieron los datos y su proceso generador para poder realizar inferencias sobre la población de interés. En general, obtener estimaciones puntuales de estadísticos de totales, promedios o proporciones es relativamente sencillo, pero puede ser que se reporte una estimación donde no exista un tamaño de muestra suficiente para obtener una estimación confiable y/o que la variabilidad de la estimación sea alta y no sea recomendable su uso. En este sentido, es importante que el usuario no experto tenga de forma nativa una forma de obtener estimaciones puntuales y sus errores asociados de manera sencilla. Es común utilizar estimaciones puntuales sin tener una medida de incertidumbre o aún peor incluir una estimación del error estándar sin tener en cuenta el diseño muestral correcto, lo que puede llevar a conclusiones erróneas sobre la variabilidad de la estimación. metasurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de forma nativa y con estos resultados hacer recomendaciones sobre la utilidad y confianza de la estimación mediante coeficientes de variación, intervalos de confianza, tamaño de muestra efectivo, entre otros sin tener que ser un experto en metodología de estimación de varianzas y remuestreo. En capítulos posteriores se abordarán ejemplos con los paquetes mencionados anteriormente y se presentará el paquete metasurvey y su implementación de estimaciones puntuales y sus errores asociados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#desarrollo-del-paquete-metasurvey",
    "href": "chapters/chapter1.html#desarrollo-del-paquete-metasurvey",
    "title": "1  Introducción",
    "section": "1.5 Desarrollo del paquete metasurvey",
    "text": "1.5 Desarrollo del paquete metasurvey\nEl desarrollo de un paquete en R es un proceso que requiere contar con una idea bien formada y los medios para llevarla a cabo es por esto que es importante contar con una metodología de trabajo ordenada, heredada del desarrollo de software convencional ya que para la publicación y difusión del paquete se tiene que cumplir con ciertos estándares de calidad y documentación para que otros usuarios puedan utilizarlo. En este sentido, es importante tener en cuenta que el desarrollo de un paquete en R puede llevar tiempo y esfuerzo, a consecuencia de esto, en el documento se presentarán diferentes conceptos sobre metodología para el desarrollo de paquetes en R y se abordaran ejemplos con la implementación de metasurvey.\nEn este sentido, metasurvey pretende ser una herramienta relevante para el trabajo con encuestas por muestreo en general ya sea en las ciencias sociales o el uso genérico para otras disciplinas, buscando solucionar las limitaciones anteriormente mencionadas. Todo el proceso de transformación de los microdatos a indicadores se realiza a través de una serie de funciones que permiten al usuario tener un control total y transparente sobre el proceso de transformación de los microdatos a indicadores. Además, metasurvey permite que el usuario pueda realizar el proceso de transformación de los microdatos a indicadores de manera reproducible y transparente. El usuario puede compartir el código de una forma entendible, casi como un “recetario de cocina”. El procedimiento aplicado a los datos utilizados para obtener los indicadores se realiza mediante lo que denominamos steps y recipes, conformando así una especie de camino transparente para la construcción de indicadores. Esto permite compartir en forma visual un DAG (Directed Acyclic Graph) que permite visualizar el proceso de construcción de indicadores sin tener que abrir un script de R. En complemento al proceso de creación de variables, metasurvey permite que el usuario pueda obtener estimaciones puntuales y sus errores asociados de manera sencilla y brindar recomendaciones sobre la utilidad de la estimación en el caso de que se cuente con una variabilidad alta en la estimación, en base a recomendaciones a su coeficiente de variación o métricas similares.\nEl enfoque que permite la flexibilidad a la hora de construir los indicadores es la meta-programación. La meta-programación es un paradigma de programación que permite que un programa pueda modificar su estructura interna en tiempo de ejecución. En R, la meta-programación se realiza a través de las funciones eval, parse, substitute, do.call y quote, que permiten evaluar y parsear código de manera dinámica. En este sentido, metasurvey utiliza la meta-programación para permitir que el usuario pueda modificar el código que se utiliza para transformar los microdatos a indicadores, teniendo funciones de alto nivel similares a las que se utilizan en el paquete recipes de la librería tidymodels (Kuhn, Wickham, y Hvitfeldt 2024).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter1.html#esquema-del-documento",
    "href": "chapters/chapter1.html#esquema-del-documento",
    "title": "1  Introducción",
    "section": "1.6 Esquema del documento",
    "text": "1.6 Esquema del documento\nEl documento se estructura de la siguiente manera: en el siguiente capítulo se presentará un marco conceptual básico sobre el muestreo de poblaciones finitas, diferentes paradigmas de programación como puede ser la programación orientada a objetos, programación funcional y la meta-programación y como se utilizan en el desarrollo del paquete. Luego, se ahondará en antecedentes previos tanto en la parte de metodología de estimación de varianzas y paquetes e ideas similares donde se basa el desarrollo del paquete. Finalmente, se presentarán ejemplos de cómo utilizar el paquete metasurvey para construir indicadores de mercado laboral a partir de los microdatos de la ECH y para mostrar su flexibilidad, se incluirá un ejemplo con la EPH.\nEste documento puede leerse en su formato de pagina web o en su formato de documento PDF. Tanto el código fuente del paquete se encuentran disponibles de forma pública en el repositorio de Github y el código fuente de este documento se encuentra disponible en el repositorio. Para la realización de este documento se utilizó quarto (Publishing 2024) para la generación de documentos dinámicos que permiten escribir texto junto con código R.\nPara finalizar, es importante mencionar que el paquete metasurvey es un proyecto en desarrollo y se encuentra en una etapa temprana de desarrollo, por lo que se espera que en el futuro se realicen mejoras y se agreguen nuevas funcionalidades, por lo que se invita a la comunidad a colaborar en el desarrollo del paquete a través de la creación de issues en el repositorio de GitHub o mediante pull requests con mejoras o nuevas funcionalidades.\nPara poder continuar con el documento, se recomienda instalar metasurvey en su versión de desarrollo, para ello se puede ejecutar el siguiente código:\n\nremotes::install_github(\"metasurveyr/metasurvey\")\n\nAunque también se puede instalar la versión de CRAN con el siguiente código:\n\n\nbranch &lt;- \"develop\"\n\nis_available &lt;- \"metasurvey\" %in% rownames(\n  available.packages(\n    repos = \"https://cloud.r-project.org/\"\n  )\n)\n\nif (is_available) {\n  install.packages(\"metasurvey\")\n} else {\n  remotes::install_github(\n    \"metasurveyr/metasurvey\",\n    ref = branch,\n    force = TRUE\n  )\n  message(\"Se instalo la versión de desarrollo de metasurvey\")\n}\n\n\n\n\n\nBreidaks, Juris, Martins Liberts, y Santa Ivanova. 2020. vardpoor: Estimation of indicators on social exclusion and poverty and its linearization, variance estimation. Riga, Latvia: Central Statistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChevalier, Martin. 2023. gustave: A User-Oriented Statistical Toolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCook, Di. 2014. «Statistical Computing Research |». http://dicook.org/2014/10/05/content/post/2014-10-5-statistical-computing/.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. «ech: Caja de herramientas para procesar la Encuesta Continua de Hogares». https://github.com/calcita/ech.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, y Natsumi Shokida. 2020. eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, y Emil Hvitfeldt. 2024. recipes: Preprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLumley, Thomas. 2011. Complex Surveys: A Guide to Analysis Using R. John Wiley & Sons.\n\n\n———. 2024. «survey: analysis of complex survey samples».\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nR Core Team. 2023. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nSchneider, Benjamin. 2023. «svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights». https://CRAN.R-project.org/package=svrep.\n\n\nVargas, Mauricio. 2024. casen: Metodos De Estimacion Con Disenio Probabilistico y Estratificado en Encuesta CASEN (Estimation Methods with Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, y Matt Herman. 2024. tidycensus: Load US Census Boundary and Attribute Data as ’tidyverse’ and ’sf’-Ready Data Frames. https://walker-data.com/tidycensus/.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, y Davis Vaughan. 2023. dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org.\n\n\nWickham, Hadley, Davis Vaughan, y Maximilian Girlich. 2024. tidyr: Tidy Messy Data. https://tidyr.tidyverse.org.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html",
    "href": "chapters/chapter2.html",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1 Inferencia en muestreo de poblaciones finitas\nComo fue mencionado anteriormente las encuestas por muestreo son la principal fuente de información para la construcción de indicadores socio-demográficos y económicos, en este sentido, es importante tener en cuenta un marco teórico para realizar estas inferencias. Es sumamente sencillo obtener estimaciones puntuales de estadísticos usuales aunque es importante considerar la variabilidad de los estimadores, tanto para poder realizar un proceso de inferencia completo así como también para poder cuantificar la confiabilidad de la estimación. A continuación, se definen los conceptos básicos de inferencia en muestreo de poblaciones finitas como son el diseño muestral, probabilidades de inclusión basadas en el diseño, estimadores de Horvitz-Thompson HT, ponderación, medidas de incertidumbre y errores estándar basados en (Särndal, Swensson, y Wretman 2003).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "href": "chapters/chapter2.html#inferencia-en-muestreo-de-poblaciones-finitas",
    "title": "2  Marco conceptual",
    "section": "",
    "text": "2.1.1 Diseño muestral\nEl concepto de diseño muestral refiere al mecanismo mediante el cual se selecciona una muestra e inducen propiedades estadísticas claves como puede ser la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. En diseños sencillos es posible calcular la función de diseño o encontrar una expresión analítica con facilidad mientras que en diseños mas complejos como pueden ser los multietapicos es necesario abordar el problema de otra forma y asumir ciertas hipótesis para poder construir probabilidades de inclusión tanto de primer orden como segundo orden.\nLa definición matemática se basa en que dado un universo \\(U\\) de \\(N\\) elementos (puede ser conocido o no) \\(\\{u_{1},u_{2}, \\cdots, u_{N}\\}\\) y se considera un conjunto de tamaño \\(n\\) de elementos de \\(U\\) que se denota como \\(s = \\{u_{1},u_{2}, \\cdots, u_{n}\\}\\) al cual comúnmente denominamos muestra, el diseño muestral puede definirse de la siguiente forma:\n\\[\nPr(S = s) = p(s)\n\\]\nRealizando un poco de inspección en la definición anterior se puede observar que el diseño muestral es una función de probabilidad que asigna una probabilidad a cada subconjunto de \\(U\\) de tamaño \\(n\\). En este sentido, es posible definir diferentes tipos de diseño, entre ellos los mas comunes:.\n\nDiseño Aleatorio Simple (SI)\n\nEl diseño aleatorio simple es el diseño más sencillo y se define de la siguiente forma:\n\\[\np(s) = \\frac{1}{\\binom{N}{n}}\n\\]\nDonde \\(\\binom{N}{n}\\) es el número de subconjuntos posibles de \\(U\\) de tamaño \\(n\\).\n\nDiseño Bernoulli (BE)\n\nEl (BE) es un diseño sencillo que se utiliza cuando se desea seleccionar una muestra de un universo de tamaño \\(N\\) además de considerar una una probabilidad de inclusión \\(\\pi\\) para cada elemento de \\(U\\). Se define el diseño Bernoulli de la siguiente forma:\n\\[\np(s) = \\underbrace{\\pi \\times \\pi \\times \\cdots \\times \\pi}_{n_{s}} \\times \\underbrace{(1-\\pi) \\times (1-\\pi) \\times \\cdots \\times (1-\\pi)}_{N-n_{s}} = \\pi ^{n_{s}} (1-\\pi)^{N-n_{s}}\n\\]\nUna diferencia fundamental entre el diseño (BE) y el diseño SI es que en el BE el tamaño de muestra es aleatorio y su distribución es binomial, mientras que en el diseño SI el tamaño de muestra es fijo.\n\nDiseño Estratificado (ST)\n\nEl diseño estratificado es un diseño que se utiliza cuando se desea seleccionar una muestra de tamaño \\(n\\) de un universo de tamaño \\(N\\) donde además se quiere dividir el universo en \\(H\\) estratos \\(U_{1}, U_{2}, \\cdots, U_{H}\\). Dentro de cada estrato se selecciona una muestra de tamaño \\(n_{h}\\) y se define el diseño estratificado de la siguiente forma:\n\\[\np(s) = \\prod_{l=1}^{H} p(s_{H})\n\\]\nEn cada estrato se puede utilizar un diseño diferente pero en general se utiliza el diseño SI, mas conocido STSI (Stratified Simple Random Sampling). En este caso cada \\(p_{h}(s_{h})\\) es el diseño aleatorio simple en el estrato \\(h\\).\n\n\n2.1.2 Probabilidades de inclusión y estimador de Horvitz-Thompson\nUna vez definido el concepto de diseño muestral es posible definir la probabilidad de que un elemento de la población sea seleccionado en la muestra, esta probabilidad se conoce como probabilidad de inclusión y se define de la siguiente forma:\n\nProbabilidad de inclusión de primer orden\n\n\\[\n\\pi_{k} = Pr(u_{k} \\in s) = Pr(I_{k} = 1)\n\\]\nDonde \\(I_{k}\\) es una variable aleatoria que toma el valor de 1 si el elemento \\(u_{k}\\) es seleccionado en la muestra y 0 en caso contrario. Definir estas variables indicadoras son de utilizada para entender el comportamiento de los estimadores bajo el diseño muestral y nos permite definir los estimadores en \\(U\\) y no en \\(S\\). Es claro que \\(I_{k} \\sim Bernoulli(\\pi_{k})\\) y \\(E(I_{k}) = Pr(I_{k}) = \\pi_{k}\\).\nEsta probabilidad es importante ya que es la la base para la construcción de estimadores insesgados y eficientes, en este sentido, es posible definir el estimador de Horvitz-Thompson (HT) para estimar un total \\(t = \\sum_{U} {t_{k}}\\) de la siguiente forma:\n\\[\n\\hat{t}_{y} = \\sum_{k=1}^{N} \\frac{y_{k}}{\\pi_{k}} \\times I_{k}\n\\]\nEste estimador es propuesto por Horvitz y Thompson en 1952 y es un estimador insesgado en el diseño, en el sentido de que \\(E(\\hat{t}_{y}) = t\\) y es eficiente en el sentido de que \\(Var(\\hat{t}_{y})\\) es el menor posible entre los estimadores insesgados. Este estimador es muy utilizado en la práctica y es la base para la construcción de otros estadísticos,como medias, proporciones, varianzas, entre otros. Para mas detalles sobre las propiedades de Horvitz-Thompson (HT) se puede consultar en (Särndal, Swensson, y Wretman 2003) y (Horvitz y Thompson 1952).\n\n\n2.1.3 Ponderación basada en el diseño y estimadores más comunes\nEn general es utilizado el concepto de ponderador para realizar estimaciones de totales, medias, proporciones, varianzas, entre otros. En este sentido, es posible definir el ponderador inducido por el diseño muestral de la siguiente forma:\n\\[\nw_{k} = \\frac{1}{\\pi_{k}}\n\\]\nEste ponderador puede interpretarse como el número individuos que representa el individuo \\(k\\) en la población. Este valor es el que comúnmente se publica junto a los microdatos y el estándar en los diferentes softwares para procesar encuestas. Junto al estimador de un total es posible definir el estimador de un promedio, proporción o razón en el contexto de la $-expansión.\n\nEstimador de un promedio\n\\[\n\\hat{\\bar{y}} = \\frac{\\sum_{k=1}^{N} w_{k} I_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}}\n\\]\nEste estimador puede ser utilizados en encuestas de hogares, donde se desea estimar el ingreso promedio de los hogares de una región de forma anual, o mensual.\n\n\nEstimador de una proporción\n\\[\n\\hat{p} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\hat{N}}\n\\]\nPuede ser de interés estimar la proporción de hogares que tienen acceso a internet en una región, en este caso se puede utilizar el estimador de proporción.\n\n\nEstimador de una razón\nSe quiere estimar la razón \\(R = \\frac{\\sum_{k=1}^{N} y_{k}}{\\sum_{k=1}^{N} z_{k}}\\). En este caso se puede definir el estimador de la razón de la siguiente forma:\n\\[\n\\hat{R} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k}z_{k}} = \\frac{\\sum_{k=1}^{N} w_{k} y_{k}}{\\hat{N}}\n\\]\nEl estimador de razón es utilizado para construir variables de mercado de trabajo como la tasa de desempleo, tasa de ocupación, entre otros.\n\n\nInferencia sobre el tamaño de la población\nUna vez definidos los estimadores, podemos ver que los estimadores de medias y proporciones son un caso particular del estimador de razón. Un detalle no menor es que asumimos \\(N\\) fijo pero desconocido, por esto al realizar proporciones se ajusta el total sobre un estimador del tamaño de la población:\n\\[\n\\hat{N} = \\sum_{k=1}^{N} I_{k}w_{k}\n\\]\nExisten diseños denominados auto-ponderados donde por definición \\(\\sum_{k=1}^{N} w_{k} = N\\), en este caso particular el estimador de medidas y proporciones es un caso particular del estimador de total, ya que el estadístico puede definirse de la siguiente forma:\n\\[\n\\hat{\\bar{y}}_{s} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{\\sum_{k=1}^{N} w_{k} I_{k}} = \\frac{\\sum_{k=1}^{N} I_{k} w_{k} y_{k}}{N} = \\frac{1}{N} \\times \\sum_{k=1}^{N} I_{k} w_{k} y_{k} = a \\times \\hat{t}_{y}\n\\]\n\n\n\n2.1.4 Medidas de incertidumbre y errores estándar\nSe puede medir la variabilidad de los estimadores y calcular su varianza. Esto es útil para entender cuán confiables son estos estimadores. Veamos cómo se calcula la varianza de diferentes tipos de estimadores, como el total, promedio, proporción o razón.\n\n2.1.4.1 Momentos muéstrales y estimadores de varianza\nPara un estadístico \\(\\theta\\), su varianza bajo un diseño muestral \\(p(s)\\) se define como:\n\\[\nV(\\hat{\\theta}) = E((\\theta - E(\\hat{\\theta}))^{2}) = \\sum_{s \\in S}{p(s)\\left(\\hat{\\theta}_{s} - E(\\hat{\\theta}_{s})\\right)}\n\\]\nLa forma de calcular la varianza depende del estimador \\(\\hat{\\theta}\\). Por ejemplo, para el estimador de varianza de un total, se utiliza la siguiente fórmula:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k} \\times y_{k} \\times w_{k})} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k} \\times y_{k} \\times w_{k}, I_{l} \\times y_{l} \\times w_{l})}}\n\\]\nDespués de simplificar, obtenemos:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{V(I_{k}) \\times w_{k} \\times y_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l }{Cov(I_{k}, I_{l}) \\times y_{k} \\times w_{k} \\times y_{l}  \\times w_{l} }}\n\\]\nDonde definimos las siguientes identidades para simplificar cálculos:\n\\[\nCov(I_{k}, I_{l}) = \\Delta_{kl} = \\pi_{kl} - \\pi_{k} \\times \\pi_{l}\n\\]\n\\[\n\\check{y}_{k} = y_{k} \\times w_{k}\n\\]\n\\[\n\\check{\\Delta}_{kl} = \\Delta_{kl} \\times \\frac{1}{\\pi_{kl}} = \\Delta_{kl} \\times w_{kl}\n\\]\nUna vez definida la varianza del estimador, necesitamos estimar su varianza. Para esto, utilizamos la técnica de \\(\\pi\\)-expansión. Después de algunas manipulaciones algebraicas, obtenemos la varianza del estimador:\n\\[\nV(\\hat{t}_{y}) = \\sum_{U}{\\check{y}_{k}^{2}} + \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} } = \\sum_{U}{\\sum{\\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }}\n\\]\nPodemos verificar que este estimador de varianza es insesgado con la definiciones de \\(E(I_{k}I_{l})\\) y tomando esperanzas. Es decir, se verifica que \\(E(\\hat{V}(\\hat{t}_{y})) = V(\\hat{t}_{y})\\). Al ser un estimador insesgado, su eficiencia depende del diseño muestral y de la varianza de los ponderadores, es decir, de la varianza de las probabilidades de inclusión. En algunos casos es donde entra en juego dividir grupos heterogéneos en estratos o realizar muestreos en varias etapas.\nPara el caso de un estimador de un promedio, la varianza se define de la siguiente forma: \\[\nV(\\hat{\\bar{y}}) = \\frac{1}{N^{2}} \\times \\sum_{U}{\\sum_{k \\not{=} l } \\Delta_{kl} \\times \\check{y}_{k} \\times \\check{y}_{l} }\n\\]\nEsto es válido en el caso de contar con un tamaño de población conocido, en otro caso el estimador de la media no es un estimador lineal y para calcular su varianza deben optar por métodos de estimación de varianzas más complejos como el de linealización de Taylor.\nEs importante considerar que en esta sección se presenta un caso ideal donde la muestra es obtenida de un listado perfecto de la población objetivo denominado marco de muestreo. En la práctica, el marco de muestreo es imperfecto y se debe considerar la no respuesta, la cobertura y la falta de actualización del marco de muestreo. En general para la publicación de microdatos se publican ciertos ponderadores que no son precisamente los ponderadores originales definidos en la sección anterior sino que son sometidos a un proceso de calibración donde se intenta ajustar a ciertas variables de control y mejorar problemas causados por la no respuesta. Al realizar el proceso de calibración los ponderadores calibrados son lo mas cercano posible a los ponderadores originales, de forma que si los ponderadores originales son insesgados, los ponderadores calibrados serán próximos a ser insesgados.\nEn la practica para diseños complejos no se dispone de las probabilidades de selección de segundo orden insumo principal para calcular los errores estándar, por esto es que se requiere optar con metodologías alternativas como el método del ultimo conglomerado, método de replicación jackknife, método de bootstrap, entre otros. En este sentido, es importante tener en cuenta que la varianza de los estimadores es un componente fundamental para realizar inferencias y cuantificar la confiabilidad de los resultados.\nEn resumen, para realizar estimaciones puntuales ya sean totales, medias, proporciones o razones, simplemente debemos ponderar los datos con los estadísticos anteriormente mencionadas pero para realizar un proceso de inferencia completo se requiere calcular sus errores estándar, construir intervalos de confianza y/o poder medir estabilidad de nuestros resultados. En este sentido, es importante tener al alcance herramientas que permitan realizar este tipo de cálculos, ya que si bien en diferentes softwares estadísticos junto a la estimación puntual se presentan los errores estándar aunque por defecto se asumen diseños sencillos como por ejemplo, el diseño BE donde la probabilidad de inclusión de segundo orden es sencilla de calcular y unicamente es necesario las probabilidades de inclusión de primer orden para computar estimadores del error estándar, siendo un valor completamente erróneo.\nUna vez presentado conceptos básicos de muestreo es importante entender como esto estará disponible en el paquete metasurvey, en este sentido, se presentarán los conceptos básicos de programación funcional y orientada a objetos en R para luego enfocarnos en la meta-programación.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#sec-developmentR",
    "href": "chapters/chapter2.html#sec-developmentR",
    "title": "2  Marco conceptual",
    "section": "2.2 Desarrollo de paquetes en R",
    "text": "2.2 Desarrollo de paquetes en R\nR es un lenguaje de código abierto y además cuenta con una gran comunidad de usuarios, en diferentes áreas de investigación, esto ha permitido que se desarrollen una gran cantidad de paquetes que permiten realizar diferentes tareas de análisis de datos, visualización, bioinformática, aprendizaje automático y ramas afines a la estadística. Dentro de la comunidad existen diferentes organizaciones que se encargan de mantener la calidad de los paquetes y de asegurar que los paquetes cumplan con ciertos estándares de calidad, una de estas organizaciones es el Comprehensive R Archive Network (CRAN), que es un repositorio de paquetes de R que contiene versiones estables de los paquetes de R, bioconductor, que es un repositorio de paquetes de R que contiene paquetes para el análisis de datos biológicos, y rOpenSci que Para casi cualquier disciplina científica o en la industria se puede encontrar una comunidad de usuarios que desarrollan paquetes en R, en este sentido, el desarrollo de paquetes en R es una tarea que se ha vuelto muy común entre los usuarios de R y es muy sencillo de realizar. A continuación, se presentan los conceptos básicos para el desarrollo de paquetes en R.\n\n2.2.1 ¿Por qué desarrollar un paquete en R?\nDesarrollar un paquete en R tiene varias ventajas, entre las cuales se pueden mencionar las siguientes:\n\nReutilización de código: Es importante tener en cuenta que existe una comunidad que hace cosas similares a las que uno hace, por lo que es posible que alguien ya haya escrito una función que uno necesita. Por lo tanto, siempre es buena buscar si existe algún paquete que ya tenga las funcionalidades que se requieren.\nCompartir código: La comunidad de R es muy activa y siempre está dispuesta a compartir código, por esta razón es que se mantienen en constante desarrollo de paquetes.\nColaboración: El trabajo colaborativo es esencial en el desarrollo de paquetes en R, ya que permite que diferentes personas puedan aportar con nuevas funcionalidades, correcciones de errores, entre otros.\n\n\n\n2.2.2 Elementos básicos de un paquete en R\nPara que nuestro conjunto de funciones, datos y documentación sea considerado un paquete en R, es necesario que cumpla con ciertos requisitos mínimos. A continuación, se presentan los componentes mínimos que debe tener un paquete en R para ser publicado en CRAN.\n\nDirectorio: Un paquete en R debe estar contenido en un directorio que contenga al menos los siguientes archivos y directorios:\n\nR/: Directorio que contiene los archivos con las funciones que se desean incluir en el paquete.\nman/: Directorio que contiene los archivos con la documentación de las funciones que se encuentran en el directorio R/. En general se utiliza Roxygen2 (Wickham et al. 2024) para generar la documentación de las funciones.\nDESCRIPTION: Archivo que contiene la descripción del paquete, incluyendo el nombre, versión, descripción, autor, entre otros.\nNAMESPACE: Archivo que contiene la información sobre las funciones que se exportan y las dependencias del paquete.\nLICENSE: Archivo que contiene la licencia bajo la cual se distribuye el paquete.\nREADME.md: Archivo que contiene información general sobre el paquete.\n\nDocumentación: La documentación de las funciones es un componente esencial de un paquete en R, ya que permite que los usuarios puedan entender el funcionamiento de las funciones que se encuentran en el paquete. La documentación de las funciones se realiza utilizando el sistema de documentación de R, que se basa en el uso de comentarios en el código fuente de las funciones.\nPruebas: Es importante que el paquete tenga pruebas que permitan verificar que las funciones se comportan de la manera esperada. Las pruebas se realizan utilizando el paquete testthat (Wickham 2011) que permite realizar pruebas unitarias.\nControl de versiones: Es importante que el paquete tenga un sistema de control de versiones que permita llevar un registro de los cambios que se realizan en el paquete. El sistema de control de versiones más utilizado en la comunidad de R es git.\nLicencia: Es importante que el paquete tenga una licencia que permita a los usuarios utilizar, modificar y distribuir el paquete. La licencia más utilizada en la comunidad de R es la licencia MIT.\n\nEl proceso de subir un paquete a CRAN es un proceso que puede ser tedioso, ya que se deben cumplir con ciertos requisitos que son revisados por los mantenedores de CRAN, no es trivial y puede tomar tiempo, sin embargo, es un proceso que vale la pena ya que permite que el paquete sea utilizado por una gran cantidad de usuarios.\nEl proceso de chequeo fue automatizado con GitHub actions, por lo que cada vez que se realiza un cambio en el repositorio, se ejecutan los chequeos de CRAN y se notifica si el paquete cumple con los requisitos para ser publicado en caso de que no cumpla con los requisitos se notifica el error y no puede ser incluido en la rama principal del repositorio hasta que se corrija el error.\nTodo el proceso y código fuente del paquete se encuentra disponible en el repositorio de github del paquete. En el caso que este interesado en colaborar con el desarrollo del paquete puede consultar la guía de contribución.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "href": "chapters/chapter2.html#paradigmas-de-programación-en-r",
    "title": "2  Marco conceptual",
    "section": "2.3 Paradigmas de programación en R",
    "text": "2.3 Paradigmas de programación en R\nR es un lenguaje de programación que permite realizar programación funcional y orientada a objetos (Chambers 2014), lo que permite que los usuarios puedan utilizar diferentes paradigmas de programación para resolver problemas. A continuación, se presentan los conceptos básicos de la programación funcional y orientada a objetos en R.\n\n2.3.1 Programación funcional\nLa programación funcional es un paradigma de programación que se basa en el uso de funciones para resolver problemas. En R, las funciones son objetos de primera clase, lo que significa que se pueden utilizar como argumentos de otras funciones, se pueden asignar a variables, entre otros (Wickham 2019, 204-81). A continuación, se presentan los conceptos básicos de la programación funcional en R.\n\nFunciones de orden superior: En R, las funciones de orden superior son funciones que toman como argumento una o más funciones y/o retornan una función. Un ejemplo de una función de orden superior en R es la función lapply que toma como argumento una lista y una función y retorna una lista con los resultados de aplicar la función a cada elemento de la lista.\nFunciones anónimas: En R, las funciones anónimas son funciones que no tienen nombre y se crean utilizando la función function. Un ejemplo de una función anónima en R es la función function(x) x^2 que toma como argumento x y retorna x^2.\nFunciones puras: En R, las funciones puras son funciones que no tienen efectos secundarios y retornan el mismo resultado para los mismos argumentos. Un ejemplo de una función pura en R es la función sqrt que toma como argumento un número y retorna la raíz cuadrada de ese número.\n\nEste paradigma de programación es muy útil para realizar análisis de datos, ya que permite que los usuarios puedan utilizar funciones para realizar operaciones sobre los datos de manera sencilla y eficiente, dentro de metasurvey no existe una presencia fuerte de programación funcional, sin embargo, se utilizan algunas funciones de orden superior para realizar operaciones sobre los datos.\n\n\n2.3.2 Programación orientada a objetos\nLa programación orientada a objetos es un paradigma de programación que se basa en el uso de objetos para resolver problemas. En R, los objetos son instancias de clases que tienen atributos y métodos (Wickham 2019, 285-370; Mailund 2017). A continuación, se presentan los conceptos básicos de la programación orientada a objetos en R.\n\nClases y objetos: En R, las clases son plantillas que definen la estructura y el comportamiento de los objetos y los objetos son instancias de clases. En R, las clases se definen utilizando la función setClass y los objetos se crean utilizando la función new.\nAtributos y métodos: En R, los atributos son variables que almacenan información sobre el estado de un objeto y los métodos son funciones que permiten modificar el estado de un objeto. En R, los atributos se definen utilizando la función setClass y los métodos se definen utilizando la función setMethod.\n\nDentro de metasurvey se utiliza la programación orientada a objetos para definir las clases de los objetos que se utilizan para representar los datos de las encuestas mediante una creación de una clase especifica llamada Survey que permite además de almacenar los datos de la encuesta añadir atributos y métodos que permiten realizar operaciones sobre los datos de manera sencilla y eficiente.\nDe forma similar se modelan las clases Step, Recipe y Survey elementos cruciales en el ecosistema de metasurvey donde se definen los pasos de preprocesamiento, recetas de preprocesamiento y flujos de trabajo respectivamente. En este caso particular se utiliza el paquete R6 (Chang 2022) que permite definir clases de manera sencilla y eficiente además de permitir la herencia de clases y la definición de métodos y atributos de manera sencilla.\n\n\n2.3.3 Meta-programación\nLa meta-programación es un paradigma de programación que se basa en el uso de código para manipular código (Wickham 2019, 373-500; Thomas Mailund 2017) . En R, la meta-programación se realiza utilizando el sistema de meta-programación de R que se basa en el uso de expresiones, llamadas y funciones. A continuación, se presentan los conceptos básicos de la meta-programación en R.\n\nExpresiones: En R, las expresiones son objetos que representan código y se crean utilizando la función quote. Un ejemplo de una expresión en R es la expresión quote(x + y) que representa el código x + y.\nLlamadas: En R, las llamadas son objetos que representan la aplicación de una función a sus argumentos y se crean utilizando la función call. Un ejemplo de una llamada en R es la llamada call(\"sum\", 1, 2, 3) que representa la aplicación de la función sum a los argumentos 1, 2 y 3.\nFunciones: En R, las funciones son objetos que representan código y se crean utilizando la función function. Un ejemplo de una función en R es la función function(x, y) x + y que representa el código x + y.\n\nEn metasurvey se utiliza la meta-programación para generar código de manera dinámica y realizar operaciones sobre los datos de manera eficiente. En particular se utiliza la función eval para evaluar expresiones y la función substitute para reemplazar variables en expresiones. Además, se utilizan las funciones lapply, sapply, mapply y do.call para aplicar funciones a listas y vectores de manera eficiente. En general, la meta-programación es una técnica muy útil para realizar operaciones sobre los datos de manera eficiente y sencilla.\nEn el Capítulo 3 se presentarán los antecedentes de metodologías de estimación de varianzas, revisión de medidas de incertidumbre, paquetes similares y mejoras que son incorporadas en el paquete metasurvey. En el Capítulo 4 se hablara sobre la implementación de las diferentes partes que conforman el paquete, una breve reseña del esquema de test, la API para almacenar las recetas junto a su interacción con el usuario. Posteriormente se mostrara un ejemplo de uso del paquete y se presentarán las conclusiones y trabajos futuros.\n\n\n\n\nChambers, John M. 2014. «Object-Oriented Programming, Functional Programming and R». Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nHorvitz, D. G., y D. J. Thompson. 1952. «A Generalization of Sampling Without Replacement From a Finite Universe». Journal of the American Statistical Association 47 (260): 663-85. https://doi.org/10.2307/2280784.\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in R: Statistical Programming for Data Science, Analysis and Finance. SPRINGER.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nThomas Mailund. 2017. Metaprogramming in R. 1.ª ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nWickham, Hadley. 2011. «testthat: Get Started with Testing». The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced R, Second Edition. CRC Press.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, y Manuel Eugster. 2024. roxygen2: In-Line Documentation for R. https://roxygen2.r-lib.org/.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Marco conceptual</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html",
    "href": "chapters/chapter3.html",
    "title": "3  Marco teórico",
    "section": "",
    "text": "3.1 Investigación reproducible\nEl concepto de investigación reproducible ha cobrado relevancia en los últimos años, tanto en la academia como en la industria y esto se debe a la fricción que puede llegar a existir al momento de presentar resultados de investigación o generación indicadores relevantes para la toma de decisiones debido al proceso de generación de los mismos. Dentro de las diferentes disciplinas generar ambientes de trabajo reproducibles puede llegar a ser un desafío, ya que en la mayoría de los casos se utilizan diferentes herramientas, lenguajes de programación y bases de datos.\nEn la actualidad existen diferentes revistas científicas que promueven la investigación reproducible, herramientas, guías para buenas prácticas para trabajar con datos y código fuente como Sumatra (Davison y Huth 2012), implementaciones de programación literal (Knuth 1984) como RMarkdown (Allaire et al. 2024) o Jupyter Notebook (Kluyver et al. 2024) y diferentes implementaciones para gestionar dependencias de software como Anaconda (Anaconda 2024), aunque algunas de ellas se han vuelto herramientas de pago o ya no existen en la actualidad, mas referencias y casos de uso pueden encontrarse en (Stodden, Leisch, y Peng 2014).\nAntes de continuar es necesario definir conceptos fundamentales en el ámbito de la investigación reproducible, tales como la Reproducibilidad que refiere a la capacidad de poder repetir los resultados de un estudio, experimento o la obtención de un indicador. Si bien la reproducibilidad en un artículo de investigación científica al utilizar indicadores tanto en contextos académicos como en aplicaciones de monitoreo o divulgación de información, rara vez se documenta o se menciona de que manera se generó ese resultado haciendo referencia únicamente a los datos y rara vez al código fuente. Aún compartiendo el código fuente, esto aún no suficiente para poder reproducir un estudio o un indicador por incompatibilidades de versiones de software, cambios en la estructura de los datos interpretaciones de los datos, estilos de programación, entre otros pudiendo llevar mucho tiempo y esfuerzo para poder replicar un resultado.\nEl proceso de tratamiento de datos y limpieza forma parte de lo que se conoce como publicaciones grises (Vilhuber 2020). Este concepto se refiere a la publicación de datos, código y reportes que no son publicaciones formales, pero son esenciales para generar conocimiento científico. En su mayoría al no tener una revisión por pares o una forma estandarizada esto se incluye de forma muy dispar o sin ningún tipo de documentación para poder ser reproducido y esto forma una gran parte de la investigación científica que no se encuentra aprovechada.\nExisten diversas iniciativas destinadas a fomentar la reproducibilidad en la ciencia, lo que ha llevado a las revistas a establecer políticas de datos y código abierto. Sin embargo, persisten desafíos en la generación de indicadores sociales, ya que como se menciono anteriormente no basta con hacer referencia a los datos, como se señala en (Bechhofer et al. 2013); además de publicar el artículo junto a los datos, es necesario vincular los objetos de investigación (Research Objects RO), existen diferentes plataformas que permiten la publicación de estos objetos como Zenodo y Figshare o OSF que permiten la integración de datos, código e interacción con repositorios con control de versiones como GitHub o GitLab.\nDe conceptos generales sobre reproducibilidad es importante contar con un flujo de trabajo (Workflow managment System (Prabhu y Fox 2020)) para la obtención de estimadores en el procesamiento de encuestas por muestreo ya que el indicador final es el resultado de una serie de pasos que se deben seguir de manera ordenada y documentada para poder ser auditados y replicados en diferentes contextos, inspirado en (Sandve et al. 2013) se pueden considerar algunas buenas prácticas para la generación de indicadores:",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#investigación-reproducible",
    "href": "chapters/chapter3.html#investigación-reproducible",
    "title": "3  Marco teórico",
    "section": "",
    "text": "Para cada resultado, se debe tener un respaldo de como fue construido: Al trabajar con lenguajes de programación como R, los script de código fuente son un respaldo de como obtener cierto resultado, sin embargo, esto puede estar ligado a tu estilo de programación y la versión de los paquetes que se utilizan.\nCrear manuales en la manipulación de datos: Es importante resumir cada paso por mas mínimo que sea en la transformación de variables, esto permite entender todo el proceso de generación de un indicador.\nGuardar las versiones de los paquetes utilizados: Al trabajar con R, es importante guardar las versiones de los paquetes que se utilizan, esto permite que en un futuro se pueda replicar el proceso de generación de indicadores, para esto puede utilizarse herramientas como renv (Ushey y Wickham 2023) un paquete que permite crear ambientes locales con versiones especificas de paquetes de R, venv (Python Software Foundation 2024) que son ambientes virtuales en python o Docker (Merkel 2014) para poder emular un ambiente de trabajo en diferentes sistemas operativos.\nGuardar pasos intermedios, en un formato estándar: Al trabajar con encuestas por muestreo y para crear indicadores sencillos se realizan dos grandes tipos de operaciones: crear grupos o categorías o realizar operaciones matemáticas, es importante guardar estos pasos en un formato estándar para poder ser reutilizados en diferentes contextos.\nCompartir las ejecuciones y scripts: Es importante que los scripts de código fuente estén disponibles para que puedan ser auditados y replicados en diferentes contextos.\n\n\n3.1.1 Conceptos clave\nmetasurvey se basa en las buenas prácticas mencionadas anteriormente y permite crear herramientas de flujo de trabajo siguiendo los siguientes principios:\n\nReusable: Se separa el proceso de transformación de variables en Steps que refiere a transformaciones de columnas, estos procedimientos pueden ser comunes tanto en diferentes encuestas como en diferentes indicadores. Estos Steps pueden ser reutilizados en diferentes Recipes para calcular indicadores de mercados de trabajo, pobreza, e incluso aplicarlos en varias encuestas simultáneamente mediante un Workflow.\nRepetible: Al tener un proceso definido en un Workflow, es posible repetir el proceso de generación de indicadores de la misma manera y automatizar la generación de reportes.\nReferenciable y Acreditable: Al contar con un Workflow, es posible hacer referencia al proceso de generación de indicadores indicando todos los pasos seguidos y el autor o equipo que lo realizó. Además, se puede acreditar a los autores de los Steps y Recipes que se utilizaron en el proceso.\n\n\n\n3.1.2 Workflow reproducible\nEl concepto de Workflow no es nuevo y exclusivo en la comunidad científica, en la actualidad en la industria de la ciencia de datos se han desarrollado diferentes herramientas para la gestión de flujos de trabajo para el procesamiento de datos, con diferentes enfoques y objetivos. metasurvey se inspira en diferentes herramientas como Apache AirFlow («Apache Airflow Documentation», s. f.) que es una plataforma de orquestación de flujos de trabajo de código abierto, Great Expectations (Expectations 2024) que es una biblioteca de validación de datos para la generación de reportes de calidad de datos y Make que es una herramienta de automatización de flujos de trabajo que se basa en la definición de reglas y dependencias.\nEn el ámbito del aprendizaje automático existe un gran esfuerzo para poder desgranar y documentar los modelos conocido como Model Cards (Mitchell et al. 2019) donde se hace un detalle de los algoritmos utilizados, las métricas de evaluación, los datos utilizados y su procesamiento, siendo esto el análogo a los Steps y Recipes de metasurvey. Este concepto se ha extendido siendo un estándar en la industria y siendo adoptado por diferentes organizaciones como Google y Hugging Face.\nTomando en cuenta estos conceptos, metasurvey tiene disponible la posibilidad de generar, compartir y visualizar los flujos de trabajo de manera gráfica permitiendo la transparencia y auditabilidad de los procesos de generación de indicadores.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#investigación-reproducible-en-r",
    "href": "chapters/chapter3.html#investigación-reproducible-en-r",
    "title": "3  Marco teórico",
    "section": "3.2 Investigación reproducible en R",
    "text": "3.2 Investigación reproducible en R\nDentro de CRAN existe una guía sobre conjunto de paquetes y herramientas con objetivos comunes denominado Task Views que agrupa paquetes de R que se utilizan para un propósito específico. En el Task View de Reproducible Research se encuentran diferentes paquetes que permiten la generación de reportes dinámicos, la gestión de flujos de trabajo y la generación de documentos interactivos aunque también existen herramientas para la gestión de flujos de trabajo generales como targets (Landau 2021) y drake (Landau 2018), metasurvey fue inspirado en los conceptos y la forma de trabajo de estos paquetes.\nLos conceptos de meta-programación y programación orientada a objetos fue inspirado en el paquete mlr3pipelines (Binder et al. 2021) que permite la creación de flujos de trabajo para el preprocesamiento de datos y la generación de modelos de aprendizaje automático, aquí se definen PipeOps que son operaciones que se pueden aplicar a los datos y se pueden combinar en un Graph que define el flujo de trabajo para ello se definen clases y métodos que permiten una fácil extensión por parte del usuario y la creación de flujos de trabajo complejos.\nDentro de la comunidad existen organizaciones como ROpenSci que promueven la ciencia abierta y la reproducibilidad en la investigación científica, proporcionando herramientas y guías para promover la ciencia abierta mediante R. Esta organización promueve la creación de paquetes donde además de la guías sobre el desarrollo de paquetes y la revisión de los mismos, se promueve la creación de paquetes que sean de utilidad para la comunidad científica definiendo estándares de calidad y documentación. Para formar parte de ROpenSci, se sigue una evaluación entre pares y una revisión de la calidad del paquete, además de la documentación y la calidad del código complementado con tests automatizados.\n\n3.2.1 Herramientas para el procesamiento de encuestas\nEn el ámbito de las encuestas por muestreo, existen diferentes paquetes que permiten el procesamiento de encuestas por muestreo o la generación de estadísticas oficiales, esto se puede ver en el Task View de Official Statistics & Survey Methodology donde se encuentran diferentes tipos de paquetes desde la preparación de formularios, calibración, análisis de datos, acceso a datos oficiales, entre otros.\nPara el procesamiento de encuestas por muestreo, existe una serie de paquetes que permiten implementar la metodología de encuestas por muestreo como puede ser el caso de survey (Lumley 2024) que permite el análisis de encuestas complejas, srvyr (Ellis y Schneider 2023) aunque estos son utilizados en el proceso final o de inferencia y no en el proceso de la construcción y limpieza de los datos como si lo hace ech (Detomasi 2020) que tiene diferentes funciones para la ECH y permite al usuario crear variables referidas a Vivienda, Educación, Mercado de Trabajo, Ingresos y Pobreza algo similar con eph (Kozlowski et al. 2020) que permite la descarga de datos de la EPH y la creación de variables para analizar la pobreza y el mercado de trabajo.\nEste ultimo grupo de paquetes o caja de herramientas tienen la limitación que no permiten la reutilización de los pasos de limpieza y transformación de los datos de forma sencilla y nativa, además de no poder visualizar el flujo de trabajo de manera gráfica, lo que dificulta la auditoría y la replicabilidad de los procesos de generación indicadores, metasurvey busca llenar este vacío permitiendo la reutilización de los pasos de limpieza y transformación de los datos, la visualización del flujo de trabajo y la generación de reportes de manera sencilla.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter3.html#diseño-de-encuestas-y-estimación-de-varianza",
    "href": "chapters/chapter3.html#diseño-de-encuestas-y-estimación-de-varianza",
    "title": "3  Marco teórico",
    "section": "3.3 Diseño de encuestas y estimación de varianza",
    "text": "3.3 Diseño de encuestas y estimación de varianza\nComo fue introducido en el capitulo anterior y en la sección de antecedentes es sencillo obtener estimaciones puntuales, sin embargo, es necesario presentar una medida de precisión de la estimación ya que en algunos casos puede ser que el tamaño de la muestra no sea suficiente para obtener estimaciones precisas. En el caso de las encuestas por muestreo, es necesario tener en cuenta el diseño de la encuesta, la estratificación, la ponderación y el efecto de conglomerados, ya que estos factores influyen en la precisión de la estimación. Para ello, es necesario contar con alguna metodología que permita estimar varianzas ya que para diseños complejos o estadísticos no lineales, la estimación de varianzas no es trivial.\nEn la actualidad, existen diferentes métodos para la estimación de varianzas, aunque en la mayoría de los casos se utilizan métodos de remuestreo como el Boostrap o el Jackknife, sin embargo existen diferentes ideas o propuestas como se menciona en (Deville y Tille 1998) y (Deville y Tillé 2005) que demuestran con resultados numéricos estimadores del tipo H-T bajo un diseño balanceado puede aproximarse desde el enfoque de regresión o calibración. Además existen estimadores alternativos donde complementan métodos de remuestreo para aproximar probabilidades de inclusión de segundo orden (Emilio L. Escobar y Berger 2013) utilizando ciertas aproximaciones límites (Hajek 1964).\nCada metodología depende de cada diseño y variables a estimar, por esto es que existen diferentes metodologías y paquetes como gustave (Chevalier 2023) , vardpoor (Breidaks, Liberts, y Ivanova 2020), svrep (Schneider 2023) y samplingVarEst (Emilio Lopez Escobar, Zamudio, y Rosas 2023), aunque existen similitudes entre implementaciones y métodos es difícil encontrar una implementación que permita la estimación de varianzas de manera sencilla y que permita la reutilización de los pasos de limpieza y transformación de los datos, esto puede ser complicado para usuarios que no tienen experiencia en el procesamiento de encuestas por muestreo y que buscan una herramienta que les permita realizar este tipo de análisis de manera sencilla y visual.\n\n\nResumen de las implementaciones\nEn la tabla a continuación se presenta un resumen de las implementaciones de los paquetes mencionados anteriormente:\n\n\n\n\n\n\nEn capítulos posteriores se presentará la implementación de conceptos de workflows, meta-programación y metodologías de estimación de varianzas en metasurvey para la generación de indicadores sociales.\n\n\n\n\nAllaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey, y Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n«Apache Airflow Documentation». s. f. https://airflow.apache.org/docs/latest/.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John Ainsworth, Jiten Bhagat, Philip Couch, et al. 2013. «Why linked data is not enough for scientists». Future Generation Computer Systems, Special section: Recent advances en e-Science, 29 (2): 599-611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars Kotthoff, y Bernd Bischl. 2021. «mlr3pipelines - Flexible Machine Learning Pipelines in R». Journal of Machine Learning Research 22 (184): 1-7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, y Santa Ivanova. 2020. vardpoor: Estimation of indicators on social exclusion and poverty and its linearization, variance estimation. Riga, Latvia: Central Statistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChevalier, Martin. 2023. gustave: A User-Oriented Statistical Toolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nDavison, Andrew P, y John E Huth. 2012. «Sumatra: A toolkit for reproducible research». arXiv preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. «ech: Caja de herramientas para procesar la Encuesta Continua de Hogares». https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, y Yves Tille. 1998. «Unequal Probability Sampling Without Replacement Through a Splitting Method». Biometrika 85 (1): 89-101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, y Yves Tillé. 2005. «Variance approximation under balanced sampling». Journal of Statistical Planning and Inference 128 (2): 569-91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nEllis, Greg Freedman, y Ben Schneider. 2023. srvyr: ’dplyr’-Like Syntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nEscobar, Emilio L., y Yves G. Berger. 2013. «A new replicate variance estimator for unequal probability sampling without replacement». The Canadian Journal of Statistics / La Revue Canadienne de Statistique 41 (3): 508-24. https://www.jstor.org/stable/43186201.\n\n\nEscobar, Emilio Lopez, Ernesto Barrios Zamudio, y Juan Francisco Munoz Rosas. 2023. samplingVarEst: Sampling Variance Estimation.\n\n\nExpectations, Great. 2024. Great Expectations Documentation. Superconductive. https://docs.greatexpectations.io.\n\n\nHajek, Jaroslav. 1964. «Asymptotic Theory of Rejective Sampling with Varying Probabilities from a Finite Population». The Annals of Mathematical Statistics 35 (4): 1491-1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger, Matthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024. Jupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. «Literate programming». The Computer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, y Natsumi Shokida. 2020. eph: Argentina’s Permanent Household Survey Data and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nLandau, William Michael. 2018. «The drake R package: a pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. «The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing». Journal of Open Source Software 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2024. «survey: analysis of complex survey samples».\n\n\nMerkel, Dirk. 2014. «Docker: lightweight linux containers for consistent development and deployment». Linux journal 2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy Vasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, y Timnit Gebru. 2019. «Model Cards for Model Reporting». En, 220-29. https://doi.org/10.1145/3287560.3287596.\n\n\nPrabhu, Anirudh, y Peter Fox. 2020. «Reproducible Workflow», diciembre. http://arxiv.org/abs/2012.13427.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: venv - Creation of virtual environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, y Eivind Hovig. 2013. «Ten Simple Rules for Reproducible Computational Research». PLOS Computational Biology 9 (10): e1003285. https://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSchneider, Benjamin. 2023. «svrep: Tools for Creating, Updating, and Analyzing Survey Replicate Weights». https://CRAN.R-project.org/package=svrep.\n\n\nStodden, Victoria, Friedrich Leisch, y Roger D. Peng. 2014. Implementing Reproducible Research. CRC Press.\n\n\nUshey, Kevin, y Hadley Wickham. 2023. renv: Project Environments. https://CRAN.R-project.org/package=renv.\n\n\nVilhuber, Lars. 2020. «Reproducibility and Replicability in Economics». Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Marco teórico</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html",
    "href": "chapters/chapter4.html",
    "title": "4  Desarrollo y metodología",
    "section": "",
    "text": "4.1 Estimación de de los errores estándar\nCada estimador tiene asociado un error estándar que permite cuantificar la variabilidad de la estimación, debido a que la muestra es aleatoria esta medida es una variable aleatoria. Dentro de la incertidumbre puede separarse en errores muestrales y no muestrales. Los primeros refieren a la variabilidad de la estimación debido a la selección de la muestra y los segundos refieren a la variabilidad de la estimación debido a errores de medición, errores de no respuesta, entre otros (Särndal, Swensson, y Wretman 2003).\nEn este trabajo vamos a centrarnos en la estimación de los errores muestrales, ya que los errores no muestrales son difíciles de cuantificar. Los errores muestrales se pueden cuantificar mediante la varianza de la estimación. Esta varianza depende del diseño muestral ya que como se mencionó anteriormente, el diseño muestral induce propiedades estadísticas claves como la distribución en el muestreo, valores esperados y varianzas de estimadores poblacionales. El paquete survey permite estimar la varianza de la estimación de forma sencilla y eficiente, sin embargo, en algunos casos la estimación de la varianza no es correcta, ya que el paquete survey asume un muestreo simple con probabilidades de inclusión desiguales y con reposición, es decir, con una fracción de muestreo \\(f = \\frac{n}{N} \\approx 0\\) (Lumley 2004).\nPara diseños multietápicos las probabilidades de segundo órden son muy complejas de calcular por lo que una estimación directa no es muy factible además de que estos ponderadores no son exactamente los pesos muestrales definidos en los capítulos anteriores, ya que se ajustan para tener en cuenta la no respuesta y la calibración, lo cual permite una estimación más precisa de ciertas variables de interés. En el caso de que se cuente con un mecanismo para obtener las probabilidades de inclusión de segundo orden este no tendría en cuenta el proceso posterior de calibración, por lo que la estimación de la varianza no sería correcta.\nEn general para este tipo de casos se utilizan principalmente las siguientes estrategias el método del ultimo conglomerado, donde se asume que la variabilidad proviene unicamente de la selección en la primera etapa y métodos de remuestreo como el Bootstrap o Jackknife. En este trabajo se propone la implementación de forma nativa de diferentes métodos utilizando solamente un argumento al cargar la encuesta permitiendo a usuarios no expertos en metodología de muestreo obtener estimaciones de varianzas correctas y confiables.\nAdicionalmente para estimadores no lineales se utiliza el método de Linearización de Taylor que permite aproximar el estimador como función de estimadores lineales un caso típico es la tasa de desempleo que se calcula como el cociente entre la población desocupada y la población económicamente activa. En este caso se puede aproximar la tasa de desempleo como función de estimadores lineales y obtener una estimación de la varianza de la tasa de desempleo o de forma similar un estimador de medias o proporciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#estimación-de-de-los-errores-estándar",
    "href": "chapters/chapter4.html#estimación-de-de-los-errores-estándar",
    "title": "4  Desarrollo y metodología",
    "section": "",
    "text": "4.1.1 Métodos de remuestreo\nLa estimación del error estándar de una media u otros resúmenes poblacionales se basa en la desviación estándar de dicho estimador a través de múltiples muestras independientes. Sin embargo, en encuestas reales solo contamos con una muestra. El enfoque de pesos replicados ofrece una alternativa, al calcular la variabilidad del estimador a partir de múltiples subconjuntos que se comportan de manera parcialmente independiente, y luego extrapola esta variabilidad para obtener una estimación que se asemeje a la que se obtendría si tuviéramos múltiples muestras independientes.\n\n4.1.1.1 Réplicas de Mitad de Muestra\nPara entender mejor este método, consideremos un diseño estratificado en el que se seleccionan dos unidades por estrato. Si dividimos los datos en dos mitades, tomando una unidad de cada estrato, se crean subconjuntos que se pueden considerar como “mitades” independientes. Si la corrección por población finita no es relevante, la varianza de un estimador basado en una mitad de muestra es aproximadamente el doble de la varianza de la muestra completa. Dado que tenemos dos mitades, podemos usar la diferencia entre sus estimaciones para calcular la varianza:\n\\[\n\\text{Var}(\\hat{\\theta}) \\approx \\frac{1}{2} (\\hat{\\theta}_A - \\hat{\\theta}_B)^2,\n\\]\ndonde \\(\\hat{\\theta}_A\\) y \\(\\hat{\\theta}_B\\) son las estimaciones de cada mitad de la muestra. Este enfoque es sencillo pero puede ser inestable, por lo que se suelen usar múltiples conjuntos de divisiones para obtener un promedio más preciso.\n\n\n4.1.1.2 Balanced Repeated Replication (BRR)\nEl método de Balanced Repeated Replication (BRR) es una forma sistemática de elegir subconjuntos de la muestra, garantizando que cada unidad se incluya de manera equilibrada en las réplicas. Esto se logra mediante un balanceo ortogonal, donde cada observación está presente en aproximadamente la mitad de las réplicas, y cada par de unidades de diferentes estratos aparece en las réplicas de forma equilibrada. Con (K) estratos, se puede generar un conjunto de hasta (K + 4) réplicas que produzca una estimación de la varianza que es prácticamente idéntica a la que se obtendría usando todas las (2^K) combinaciones posibles.\nLa varianza utilizando BRR se calcula así:\n\\[\n\\text{Var}_{\\text{BRR}}(\\hat{\\theta}) = \\frac{1}{R} \\sum_{r=1}^R (\\hat{\\theta}_r - \\hat{\\theta})^2,\n\\]\ndonde \\(R\\) es el número de réplicas seleccionadas y \\(\\hat{\\theta}_r\\) es el estimador obtenido de cada réplica.\n\n\n4.1.1.3 Pesos Replicados en Diseños Multietápicos y Complejos\nEl enfoque de pesos replicados no solo se aplica a diseños simples, sino que también se adapta a diseños de muestreo multietápicos y diseños complejos. En estos casos, la estructura de la muestra se complica, ya que puede involucrar varias etapas de selección (por ejemplo, seleccionar primero conglomerados como municipios, luego hogares dentro de los municipios, y finalmente personas dentro de los hogares). Esto hace que la varianza deba considerar la correlación entre unidades seleccionadas en cada etapa.\nPara estos diseños, se utilizan métodos como el Jackknife y el Bootstrap, que permiten manejar la estructura multietápica. Por ejemplo:\n\nEn un diseño Jackknife, se ajustan los pesos eliminando una observación o un conglomerado completo en cada réplica, y recalculando el estimador con los datos restantes. Esto puede ajustarse para considerar la estructura de estratos y conglomerados.\n\n\\[\n\\text{Var}_{\\text{Jackknife}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\theta}_i - \\hat{\\theta})^2,\n\\]\ndonde (n) es el número de observaciones o conglomerados,\\(\\hat{\\theta}_i\\) es la estimación obtenida cuando se omite la \\(i\\)-ésima unidad, y \\(\\hat{\\theta}\\) es la estimación con todos los datos.\n\nEn el Bootstrap, se seleccionan subconjuntos con reemplazo de cada conglomerado, y se ajustan los pesos según el número de veces que cada unidad aparece en la réplica. Esto es especialmente útil cuando las unidades de muestreo tienen una estructura jerárquica, como es el caso de los diseños multietápicos.\n\n\\[\n\\text{Var}_{\\text{Bootstrap}}(\\hat{\\theta}) = \\frac{1}{B} \\sum_{b=1}^B (\\hat{\\theta}_b - \\hat{\\theta})^2,\n\\]\ndonde \\(B\\) es el número de réplicas y \\(\\hat{\\theta}_b\\) es el estimador obtenido en la \\(b\\)-ésima réplica.\n\n\n4.1.1.4 Ventajas de los Pesos Replicados\nAunque estos métodos requieren más esfuerzo computacional comparados con métodos tradicionales como el estimador de Horvitz-Thompson, son muy versátiles. Facilitan la estimación de errores estándar para diferentes tipos de estadísticas, no solo para medias o totales, y son especialmente útiles cuando se trabaja con diseños de muestreo complejos. Además, permiten obtener errores estándar precisos para estimaciones de subpoblaciones sin necesidad de ajustes adicionales. Esto los convierte en una herramienta poderosa para el análisis de encuestas complejas, especialmente con el soporte de software estadístico moderno.\nEl paquete survey con svrep proporcionan una implementación robusta de varios métodos de pesos replicados, incluyendo Balanced Repeated Replication (BRR), Jackknife, y Bootstrap. Sin embargo, el uso adecuado de estos métodos a menudo no es tan conocido por usuarios que no son expertos en muestreo. La correcta especificación del diseño y la interpretación de los resultados pueden ser complejas, especialmente en el caso de diseños de muestreo multietápicos o aquellos que requieren calibración.\nDentro de metasurvey se busca simplificar el uso de estos métodos, pudiendo especificar el tipo de réplica deseado con un solo argumento al cargar la encuesta o utilizar replicas brindadas por la institución que publica los microdatos. Además, se busca incorporar medidas de calidad de las estimaciones como el coeficiente de variación, el error relativo y el error absoluto, para facilitar la interpretación de los resultados y la comparación entre diferentes estimaciones y subpoblaciones.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter4.html#desarrollo-e-implementación",
    "href": "chapters/chapter4.html#desarrollo-e-implementación",
    "title": "4  Desarrollo y metodología",
    "section": "4.2 Desarrollo e Implementación",
    "text": "4.2 Desarrollo e Implementación\nEn esta sección se describen las diferentes partes del paquete metasurvey y su implementación, incluyendo la estructura del paquete, las funciones principales y la forma en que se implementan los métodos de estimación de varianzas y errores estándar. El repositorio de metasurvey está disponible en GitHub y sigue la estructura estándar de un paquete de R, tal como se menciona en Sección 2.2.\n\n4.2.1 Dependencias\nUn aspecto destacado del paquete metasurvey es su uso limitado de dependencias externas, cada una seleccionada por su propósito específico. Por ejemplo, survey (Lumley 2024) se utiliza para el procesamiento de encuestas, data.table (Barrett et al. 2024) facilita la manipulación eficiente de datos, R6 (Chang 2022) permite la programación orientada a objetos, y glue (Hester y Bryan 2024) contribuye a la interpolación de cadenas, mejorando la legibilidad del código al crear o modificar fragmentos de texto. Además, jsonlite (Ooms 2014) se encarga de la lectura y escritura de archivos JSON, lo cual resulta esencial para compartir las configuraciones obtenidas a través de la API de metasurvey, que emplea una base de datos NoSQL, mientras que httr (Wickham 2023) gestiona las peticiones HTTP.\nTambién se incluyen algunas dependencias adicionales para mejorar la experiencia del usuario, como visNetwork (V., Contributors, y Thieurmel 2022) para la visualización de recetas y pasos, y crayon para la impresión de mensajes en la consola con colores.\nLa optimización de las dependencias es un aspecto importante en el desarrollo de paquetes, ya que influye en la eficiencia y la velocidad de carga. Por lo tanto, se ha procurado mantener un equilibrio entre la funcionalidad y la eficiencia, evitando la inclusión de paquetes innecesarios que puedan ralentizar el rendimiento del paquete.\nExiste una versión previa a metasurvey llamada srvyuRu donde las dependencias eran muy amplias. El uso de dplyr (Wickham et al. 2023) y tidyverse (Wickham et al. 2019) hacía que el paquete fuera muy pesado y lento, junto al paquete rlang (Henry y Wickham 2024), que si bien es muy útil para la implementación de la metaprogramación, incrementaba las dependencias de manera innecesaria.\nDentro de srvyuRu, también se utilizaba shiny (Chang 2022) para la implementación de una interfaz gráfica. Sin embargo, se decidió no incluir esta funcionalidad en metasurvey ya que se consideró que no era esencial y que podía ser implementada en un paquete independiente.\nLa versión anterior fue motivada por la necesidad de contar con una herramienta que automatizara el proceso de recodificación de variables y cálculo de indicadores, para compatibilizar los indicadores de la EAI y ECH para el portal PRISMA en la sección de Innovación y Género respectivamente. Sin embargo, la implementación de la interfaz gráfica no fue exitosa, ya que permitía al usuario crear recetas y pasos de forma gráfica, lo cual llevaba a una complejidad innecesaria y a un paquete muy pesado debido a la inclusión de dependencias innecesarias.\n\n\n4.2.2 Funciones principales\n\n4.2.2.1 Carga inicial de la encuesta\nEl paquete puede dividirse en dos partes principales: la carga y procesamiento de encuestas, y la estimación de errores estándar. Dentro de lo que es la carga y procesamiento de encuestas, se incluyen funciones para cargar encuestas en diferentes formatos, como SPSS, STATA, CSV, y RDS, y para realizar operaciones básicas como la selección de variables, la recodificación de categorías, y la creación de indicadores.\nEsta implementación puede verse en load_survey.R donde aquí se define la función principal load_survey esta misma se encarga de cargar la encuesta y realizar las operaciones básicas mencionadas anteriormente. Dentro de ella podemos ver que es simplemente un wrapper de diferentes paquetes para cargar la encuesta ya sea read.spss del paquete foregin (R Core Team 2023) para cargar encuestas provenientes en formato SAV o DTA, fread de data.table (Barrett et al. 2024) para archivos CSV y por último loadWorkbook del paquete openxlsx (Schauberger y Walker 2024), todas estas funciones se encargan de cargar la encuesta en base a la extensión del archivo, el usuario puede modificar cambiando el engine como por ejemplo a tidyverse donde la lectura CSV se realiza con read_csv del paquete readr (Wickham 2023), o haven (Wickham, Miller, y Smith 2023) para cargar encuestas en formato SPSS o STATA.\nAl cargar la encuesta el usuario debe de especificar el tipo de encuesta que está cargando y la edición de la misma, estos metadatos serán cruciales para poder obtener recetas y pasos de la API de metasurvey. Además, se puede especificar el tipo de réplica que se desea utilizar, por defecto se utiliza el método de BRR, pero el usuario puede especificar el método de réplica que desee, ya sea Jackknife o Bootstrap, en el Capítulo 5 se menciona como utilizar replicas brindadas por la institución que publica los microdatos y estimadores de cambios netos compuestos.\nUna vez definida la carga de datos dentro de la misma implementación de crea un objeto de la clase Survey la cual se encuentra definida en survey.R. Esta clase es realizada con el paquete R6 (Chang 2022) y se encarga de almacenar la encuesta, los metadatos, las recetas y los pasos junto al diseño muestral, el usuario puede obtener información con wrappers de cada método para que sea más sencillo de utilizar, como por ejemplo cat_steps donde se obtiene todos los pasos que fueron aplicados a la encuesta, cat_recipes donde se obtienen todas las recetas que fueron aplicadas a la encuesta, cat_design donde se obtiene el diseño muestral, entre otros.\nAquí se hace un breve ejemplo de cómo se carga una encuesta y se obtiene la información de la misma:\n\n\nCódigo\nlibrary(metasurvey)\n\n# Cargar encuesta\n\n## Encuesta ECH 2022\n## Se fija el ponderador de la encuesta\n## Se obtienen las recetas de la encuesta\n\nech_2022 &lt;- load_survey(\n  metasurvey::load_survey_example(\n    \"ech\",\n    \"ech_2022\"\n  ),\n  svy_edition = \"2022\",\n  svy_type = \"ech\",\n  svy_weight = add_weight(annual = \"w_ano\"),\n  recipes = get_recipe(\n    \"ech\",\n    \"2022\"\n  )\n)\n\n\nEn el ejemplo anterior se carga la encuesta ECH 2022, se fija el ponderador de la encuesta y se obtienen las recetas de la encuesta del servidor en la sección referida a recetas se profundizará en este tópico, se obtiene la clase de la encuesta, las recetas, el primer elemento de las recetas y los pasos de la primera receta, por último se obtiene el tipo de diseño muestral de la encuesta.\n\n\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael Chirico, Toby Hocking, y Benjamin Schwendinger. 2024. data.table: Extension of ‘data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference Semantics.\n\n\nHenry, Lionel, y Hadley Wickham. 2024. rlang: Functions for Base Types and Core R and ’Tidyverse’ Features. https://rlang.r-lib.org.\n\n\nHester, Jim, y Jennifer Bryan. 2024. glue: Interpreted String Literals. https://CRAN.R-project.org/package=glue.\n\n\nLumley, Thomas. 2004. «Analysis of Complex Survey Samples». Journal of Statistical Software 9 (abril): 1-19. https://doi.org/10.18637/jss.v009.i08.\n\n\n———. 2024. «survey: analysis of complex survey samples».\n\n\nOoms, Jeroen. 2014. «The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects». arXiv:1403.2805 [stat.CO]. https://arxiv.org/abs/1403.2805.\n\n\nR Core Team. 2023. foreign: Read Data Stored by ’Minitab’, ’S’, ’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\nSärndal, Carl-Erik, Bengt Swensson, y Jan Wretman. 2003. Model Assisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, y Alexander Walker. 2024. openxlsx: Read, Write and Edit xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nV., Almende B., Contributors, y Benoit Thieurmel. 2022. visNetwork: Network Visualization using ’vis.js’ Library. https://CRAN.R-project.org/package=visNetwork.\n\n\nWickham, Hadley. 2023. httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. «Welcome to the tidyverse». Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, y Davis Vaughan. 2023. dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org.\n\n\nWickham, Hadley, Evan Miller, y Danny Smith. 2023. haven: Import and Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Desarrollo y metodología</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html",
    "href": "chapters/chapter5.html",
    "title": "5  Casos de uso",
    "section": "",
    "text": "5.1 Encuesta Continua de Hogares\nLa Encuesta Continua de Hogares (ECH) es la principal fuente de información referida al mercado de trabajo en Uruguay. La encuesta se realiza en forma continua con periodicidad mensual desde el 1968. En sus primeros años la encuesta solo consideraba como universo de hogares a Montevideo sin embargo luego en 1980 se extendió a todo el país mediante un programa de las Naciones Unidas para el Desarrollo y el Fondo de las Naciones Unidad para Actividades de Población llegando a cubrir todo el territorio nacional.\nActualmente el INE tiene publicado en su página web microdatos de la encuesta desde el año 2006, en el portal ANDA se pueden encontrar junto a los microdatos los códigos de las variables y las definiciones de las mismas junto a la descripción del diseño de la encuesta.\nLa encuesta a lo largo de los años ha ido incorporando nuevas variables y modificando las existentes, por lo que es importante tener en cuenta la versión de la encuesta que se está utilizando para realizar los análisis y dependiendo del grupo de variables que se quiera analizar puede que sea mas o menos tedioso el proceso de re-codificación de variables y cálculo de indicadores. Con la ayuda de recetas y el paquete metasurvey se puede automatizar el proceso de re-codificación de variables y cálculo de indicadores para poder calcular los indicadores de interés.\nEn lo que sigue se van a utilizar los microdatos de la ECH del año 2024 Abril, para replicar los resultados presentados en el Boletin Técnico, Actividad, Empleo y Desempleo. Abril 2024 y Informe diferencial de mercado de trabajo referidos a variables de mercado de trabajo a nivel mensual. A continuación se hara lo mismo con el informe Mercado de trabajo por área geográfica de residencia y Boletín Técnico Ingresos de los Hogares y de las Personas",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#encuesta-continua-de-hogares",
    "href": "chapters/chapter5.html#encuesta-continua-de-hogares",
    "title": "5  Casos de uso",
    "section": "",
    "text": "5.1.1 Actividad, empleo y desempleo (Mensual)\nEn este boletín se encuentran las tres variables principales del mercado de trabajo, la tasa de actividad, la tasa de empleo y la tasa de desempleo. La tasa de actividad se calcula como el cociente entre la población económicamente activa y la población en edad de trabajar, la tasa de empleo se calcula como el cociente entre la población ocupada y la población en edad de trabajar y la tasa de desempleo se calcula como el cociente entre la población desocupada y la población económicamente activa.\nPara calcular estas tasas se necesita re-codificar las variables de la encuesta para poder calcular las tasas de interés. A continuación se muestra el código para re-codificar las variables y calcular las tasas de interés.\n\n#&gt; Loading required package: data.table\n\n\n5.1.1.1 Re-codificación de variables\n\n\n5.1.1.2 Estimación\n\n#&gt; $monthly\n#&gt; $monthly[[1]]\n#&gt;                         stat      value          se          cv\n#&gt;                       &lt;char&gt;      &lt;num&gt;       &lt;num&gt;       &lt;num&gt;\n#&gt; 1: survey::svyratio: pea/pet 0.63844605 0.003650599 0.005717945\n#&gt; 2:  survey::svyratio: pd/pea 0.07807569 0.002709077 0.034698084\n#&gt; 3:  survey::svyratio: po/pet 0.58859894 0.003776409 0.006415930\n\nAcá va la viñeta Use recipes",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#ech",
    "href": "chapters/chapter5.html#ech",
    "title": "5  Casos de uso",
    "section": "5.2 ECH",
    "text": "5.2 ECH\n\nmetasurvey::set_engine(\"data.table\")\n#&gt; Engine: data.table\n\nech_meta &lt;- metasurvey::load_survey(\n  path = metasurvey::load_survey_example(\n    \"ech\",\n    \"ech_2018\"\n  ),\n  svy_type = \"ech\",\n  svy_edition = \"ech_2018\",\n  svy_weight = add_weight(\n    monthly = \"pesoano\"\n  )\n)\n\nech_meta_steps &lt;- ech_meta |&gt;\n  metasurvey::step_recode(\n    \"pea\",\n    pobpcoac %in% 2:5 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pet\",\n    pobpcoac != 1 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"po\",\n    pobpcoac == 2 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pd\",\n    pobpcoac %in% 3:5 ~ 1,\n    .default = 0\n  )\n\n\nmetasurvey::view_graph(ech_meta_steps)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eph",
    "href": "chapters/chapter5.html#eph",
    "title": "5  Casos de uso",
    "section": "5.3 EPH",
    "text": "5.3 EPH\n\neph2022_3 &lt;- metasurvey::load_survey(\n  path = metasurvey::load_survey_example(\n    \"eph\",\n    \"eph2022_3\"\n  ),\n  svy_type = \"eph\",\n  svy_edition = \"eph_202302\",\n  svy_weight = add_weight(\n    monthly = \"PONDERA\"\n  )\n) |&gt;\n  metasurvey::step_recode(\n    \"pea\",\n    ESTADO %in% 1:2 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pet\",\n    ESTADO != 4 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"po\",\n    ESTADO == 1 ~ 1,\n    .default = 0\n  ) |&gt;\n  metasurvey::step_recode(\n    \"pd\",\n    ESTADO == 2 ~ 1,\n    .default = 0\n  )\n\n\nmetasurvey::view_graph(eph2022_3)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#ech-1",
    "href": "chapters/chapter5.html#ech-1",
    "title": "5  Casos de uso",
    "section": "5.4 ECH",
    "text": "5.4 ECH\n\n5.4.1 Actividad, empleo y desempleo (Mensual)\n\n\n5.4.2 Mercado de trabajo (Trimestral)\n\n\n5.4.3 Ingreso de los hogares, pobreza y desigualdad",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/chapter5.html#eaii",
    "href": "chapters/chapter5.html#eaii",
    "title": "5  Casos de uso",
    "section": "5.5 EAII",
    "text": "5.5 EAII\n\n5.5.1 Dominios\n\n\n5.5.2 Replicar resultados de la sección actual\n\n\n5.5.3 Medio ambiente",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Casos de uso</span>"
    ]
  },
  {
    "objectID": "chapters/bibliography.html",
    "href": "chapters/bibliography.html",
    "title": "6  Bibliografía",
    "section": "",
    "text": "Allaire, JJ, Yihui Xie, Jade McPherson, Joseph Luraschi, Kevin Ushey,\nand Amber Atkins. 2024. RMarkdown. https://rmarkdown.rstudio.com/.\n\n\nAnaconda, Inc. 2024. Anaconda Distribution. https://www.anaconda.com/.\n\n\n“Apache Airflow Documentation.” n.d. https://airflow.apache.org/docs/latest/.\n\n\nBarrett, Tyson, Matt Dowle, Arun Srinivasan, Jan Gorecki, Michael\nChirico, Toby Hocking, and Benjamin Schwendinger. 2024. Data.table:\nExtension of ‘Data.frame‘. https://CRAN.R-project.org/package=data.table.\n\n\nBechhofer, Sean, Iain Buchan, David De Roure, Paolo Missier, John\nAinsworth, Jiten Bhagat, Philip Couch, et al. 2013. “Why Linked\nData Is Not Enough for Scientists.” Future Generation\nComputer Systems, Special section: Recent advances in e-science, 29\n(2): 599–611. https://doi.org/10.1016/j.future.2011.08.004.\n\n\nBinder, Martin, Florian Pfisterer, Michel Lang, Lennart Schneider, Lars\nKotthoff, and Bernd Bischl. 2021. “Mlr3pipelines - Flexible\nMachine Learning Pipelines in r.” Journal of Machine Learning\nResearch 22 (184): 1–7. https://jmlr.org/papers/v22/21-0281.html.\n\n\nBreidaks, Juris, Martins Liberts, and Santa Ivanova. 2020. Vardpoor:\nEstimation of Indicators on Social Exclusion and Poverty and Its\nLinearization, Variance Estimation. Riga, Latvia: Central\nStatistical Bureau of Latvia. https://csblatvia.github.io/vardpoor/.\n\n\nChambers, John M. 2014. “Object-Oriented Programming, Functional\nProgramming and r.” Statistical Science 29 (2). https://doi.org/10.1214/13-STS452.\n\n\nChang, Winston. 2022. R6: Encapsulated Classes with Reference\nSemantics.\n\n\nChevalier, Martin. 2023. Gustave: A User-Oriented Statistical\nToolkit for Analytical Variance Estimation. https://CRAN.R-project.org/package=gustave.\n\n\nCook, Di. 2014. “Statistical Computing Research |.” http://dicook.org/2014/10/05/content/post/2014-10-5-statistical-computing/.\n\n\nDavison, Andrew P, and John E Huth. 2012. “Sumatra: A Toolkit for\nReproducible Research.” arXiv Preprint arXiv:1207.5548.\n\n\nDetomasi, Gabriela Mathieu & Richard. 2020. “Ech: Caja de\nHerramientas Para Procesar La Encuesta Continua de Hogares.” https://github.com/calcita/ech.\n\n\nDeville, Jean-Claude, and Yves Tille. 1998. “Unequal Probability\nSampling Without Replacement Through a Splitting Method.”\nBiometrika 85 (1): 89–101. https://www.jstor.org/stable/2337311.\n\n\nDeville, Jean-Claude, and Yves Tillé. 2005. “Variance\nApproximation Under Balanced Sampling.” Journal of\nStatistical Planning and Inference 128 (2): 569–91. https://doi.org/10.1016/j.jspi.2003.11.011.\n\n\nEllis, Greg Freedman, and Ben Schneider. 2023. Srvyr: ’Dplyr’-Like\nSyntax for Summary Statistics of Survey Data. https://CRAN.R-project.org/package=srvyr.\n\n\nEscobar, Emilio L., and Yves G. Berger. 2013. “A New Replicate\nVariance Estimator for Unequal Probability Sampling Without\nReplacement.” The Canadian Journal of Statistics / La Revue\nCanadienne de Statistique 41 (3): 508–24. https://www.jstor.org/stable/43186201.\n\n\nEscobar, Emilio Lopez, Ernesto Barrios Zamudio, and Juan Francisco Munoz\nRosas. 2023. samplingVarEst: Sampling Variance Estimation.\n\n\nExpectations, Great. 2024. Great Expectations Documentation.\nSuperconductive. https://docs.greatexpectations.io.\n\n\nHajek, Jaroslav. 1964. “Asymptotic Theory of Rejective Sampling\nwith Varying Probabilities from a Finite Population.” The\nAnnals of Mathematical Statistics 35 (4): 1491–1523. https://doi.org/10.1214/aoms/1177700375.\n\n\nHenry, Lionel, and Hadley Wickham. 2024. Rlang: Functions for Base\nTypes and Core r and ’Tidyverse’ Features. https://rlang.r-lib.org.\n\n\nHester, Jim, and Jennifer Bryan. 2024. Glue: Interpreted String\nLiterals. https://CRAN.R-project.org/package=glue.\n\n\nHorvitz, D. G., and D. J. Thompson. 1952. “A Generalization of\nSampling Without Replacement from a Finite Universe.” Journal\nof the American Statistical Association 47 (260): 663–85. https://doi.org/10.2307/2280784.\n\n\nKluyver, Thomas, Benjamin Ragan-Kelley, Fernando Pérez, Brian Granger,\nMatthias Bussonnier, Jonathan Frederic, Kyle Kelley, et al. 2024.\nJupyter Notebook. https://jupyter.org/.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” The\nComputer Journal 27 (2): 97111.\n\n\nKozlowski, Diego, Pablo Tiscornia, Guido Weksler, German Rosati, and\nNatsumi Shokida. 2020. Eph: Argentina’s Permanent Household Survey\nData and Manipulation Utilities. https://holatam.github.io/eph/.\n\n\nKuhn, Max, Hadley Wickham, and Emil Hvitfeldt. 2024. Recipes:\nPreprocessing and Feature Engineering Steps for Modeling. https://github.com/tidymodels/recipes.\n\n\nLandau, William Michael. 2018. “The Drake r Package: A Pipeline\nToolkit for Reproducibility and High-Performance Computing.”\nJournal of Open Source Software 3 (21). https://doi.org/10.21105/joss.00550.\n\n\n———. 2021. “The Targets r Package: A Dynamic Make-Like\nFunction-Oriented Pipeline Toolkit for Reproducibility and\nHigh-Performance Computing.” Journal of Open Source\nSoftware 6 (57): 2959. https://doi.org/10.21105/joss.02959.\n\n\nLumley, Thomas. 2004. “Analysis of Complex Survey Samples.”\nJournal of Statistical Software 9 (April): 1–19. https://doi.org/10.18637/jss.v009.i08.\n\n\n———. 2011. Complex Surveys: A Guide to Analysis Using R. John\nWiley & Sons.\n\n\n———. 2024a. “Survey: Analysis of Complex Survey Samples.”\n\n\n———. 2024b. “Survey: Analysis of Complex Survey Samples.”\n\n\nMailund, Thomas. 2017. Advanced Object-Oriented Programming in r:\nStatistical Programming for Data Science, Analysis and Finance.\nSPRINGER.\n\n\nMerkel, Dirk. 2014. “Docker: Lightweight Linux Containers for\nConsistent Development and Deployment.” Linux Journal\n2014 (239): 2.\n\n\nMitchell, Margaret, Simone Wu, Andrew Zaldivar, Parker Barnes, Lucy\nVasserman, Ben Hutchinson, Elena Spitzer, Inioluwa Deborah Raji, and\nTimnit Gebru. 2019. “Model Cards for Model Reporting.” In,\n220–29. https://doi.org/10.1145/3287560.3287596.\n\n\nOoms, Jeroen. 2014. “The Jsonlite Package: A Practical and\nConsistent Mapping Between JSON Data and r Objects.”\narXiv:1403.2805 [Stat.CO]. https://arxiv.org/abs/1403.2805.\n\n\nPrabhu, Anirudh, and Peter Fox. 2020. “Reproducible\nWorkflow,” December. http://arxiv.org/abs/2012.13427.\n\n\nPublishing, Quarto. 2024. Quarto. https://www.quartoknows.com/.\n\n\nPython Software Foundation. 2024. Python 3 Documentation: Venv -\nCreation of Virtual Environments. Python Software Foundation. https://docs.python.org/3/library/venv.html.\n\n\nR Core Team. 2023a. Foreign: Read Data Stored by ’Minitab’, ’s’,\n’SAS’, ’SPSS’, ’Stata’, ’Systat’, ’Weka’, ’dBase’, ... https://CRAN.R-project.org/package=foreign.\n\n\n———. 2023b. R: A Language and Environment for Statistical\nComputing. Vienna, Austria: R Foundation for Statistical Computing.\nhttps://www.R-project.org/.\n\n\nSandve, Geir Kjetil, Anton Nekrutenko, James Taylor, and Eivind Hovig.\n2013. “Ten Simple Rules for Reproducible Computational\nResearch.” PLOS Computational Biology 9 (10): e1003285.\nhttps://doi.org/10.1371/journal.pcbi.1003285.\n\n\nSärndal, Carl-Erik, Bengt Swensson, and Jan Wretman. 2003. Model\nAssisted Survey Sampling. Springer Science & Business Media.\n\n\nSchauberger, Philipp, and Alexander Walker. 2024. Openxlsx: Read,\nWrite and Edit Xlsx Files. https://CRAN.R-project.org/package=openxlsx.\n\n\nSchneider, Benjamin. 2023. “Svrep: Tools for Creating, Updating,\nand Analyzing Survey Replicate Weights.” https://CRAN.R-project.org/package=svrep.\n\n\nStodden, Victoria, Friedrich Leisch, and Roger D. Peng. 2014.\nImplementing Reproducible Research. CRC Press.\n\n\nThomas Mailund. 2017. Metaprogramming in r. 1st ed. Apress. https://www.amazon.com/Metaprogramming-Advanced-Statistical-Programming-Analysis/dp/1484228804.\n\n\nUshey, Kevin, and Hadley Wickham. 2023. Renv: Project\nEnvironments. https://CRAN.R-project.org/package=renv.\n\n\nV., Almende B., Contributors, and Benoit Thieurmel. 2022.\nvisNetwork: Network Visualization Using ’Vis.js’ Library. https://CRAN.R-project.org/package=visNetwork.\n\n\nVargas, Mauricio. 2024. Casen: Metodos de Estimacion Con Disenio\nProbabilistico y Estratificado En Encuesta CASEN (Estimation Methods\nwith Probabilistic Stratified Sampling in CASEN Survey). https://pacha.dev/casen/.\n\n\nVilhuber, Lars. 2020. “Reproducibility and Replicability in\nEconomics.” Harvard Data Science Review 2 (4). https://doi.org/10.1162/99608f92.4f6b9e67.\n\n\nWalker, Kyle, and Matt Herman. 2024. Tidycensus: Load US Census\nBoundary and Attribute Data as ’Tidyverse’ and ’Sf’-Ready Data\nFrames. https://walker-data.com/tidycensus/.\n\n\nWickham, Hadley. 2011. “Testthat: Get Started with\nTesting.” The R Journal 3: 510. https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf.\n\n\n———. 2019. Advanced r, Second Edition. CRC Press.\n\n\n———. 2023. Httr: Tools for Working with URLs and HTTP. https://CRAN.R-project.org/package=httr.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the Tidyverse.” Journal of Open Source\nSoftware 4 (43): 1686. https://doi.org/10.21105/joss.01686.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster.\n2024. Roxygen2: In-Line\nDocumentation for R. https://roxygen2.r-lib.org/.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://dplyr.tidyverse.org.\n\n\nWickham, Hadley, Evan Miller, and Danny Smith. 2023. Haven: Import\nand Export ’SPSS’, ’Stata’ and ’SAS’ Files. https://CRAN.R-project.org/package=haven.\n\n\nWickham, Hadley, Davis Vaughan, and Maximilian Girlich. 2024. Tidyr:\nTidy Messy Data. https://tidyr.tidyverse.org.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Bibliografía</span>"
    ]
  },
  {
    "objectID": "Appendices/AppendixA.html",
    "href": "Appendices/AppendixA.html",
    "title": "Apéndice A — Frequently Asked Questions",
    "section": "",
    "text": "A.1 How do I change the colors of links?\nPass in urlcolor: in yaml. Or set these in the include-in-header file.\nIf you want to completely hide the links, you can use:\n{}, or even better:\n{}.\nIf you want to have obvious links in the PDF but not the printed text, use:\n{}.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Frequently Asked Questions</span>"
    ]
  }
]